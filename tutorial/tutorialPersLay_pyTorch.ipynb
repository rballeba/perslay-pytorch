{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A tutorial and template for *PersLay: a neural network layer for persistence diagrams and new graph topological signatures*.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ Théo Lacombe, Mathieu Carrière"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ This is an alpha version of PersLay. Do not hesitate to contact the authors for any comment, suggestion, bug, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Outline:__\n",
    "In this notebook:\n",
    "- First, we select a dataset. Two types of datasets are provided by default, either synthetic orbits from dynamical systems, or real-life graph dataset (we also explain how you could use PersLay with your own persistence diagrams).\n",
    "- Then, we generate the persistence diagrams (and other useful informations such as labels, etc.) for the chosen dataset, and optionally visualize them.\n",
    "- We either load a predefined PersLay neural net, or define a neural net that uses some PersLay channels as first layers to handle persistence diagrams. This can be used as a guideline to use PersLay in your own experiments.\n",
    "- We show how to train this neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required Python libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Numpy, Scikit-learn, TensorFlow, PersLay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.svm import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, KFold, ShuffleSplit\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 12:33:09.662853: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 12:33:09.790342: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-03-21 12:33:10.232610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 12:33:10.232658: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-03-21 12:33:10.232664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from experiments import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from perslay.perslay_pytorch import PerslayModel"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Generate predefined persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Skip this section and go to Section 3 if you already have your own persistence diagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by choosing the dataset we want to run the experiments on. We suggest the user to start with `\"MUTAG\"` as this dataset is reasonably small (188 graphs with 18 nodes on average). Note that its small size implies a large variability in test accuracies.\n",
    "\n",
    "Available options are:\n",
    "\n",
    "- Orbit datasets: `\"ORBIT5K\"`, `\"ORBIT100K\"`.\n",
    "\n",
    "- Graphs datasets: `\"MUTAG\"`,`\"COX2\"`, `\"DHFR\"`, `\"PROTEINS\"`, `\"NCI1\"`, `\"NCI109\"`,`\"IMDB-BINARY\"`, `\"IMDB-MULTI\"`.\n",
    "\n",
    "__Important note:__ `\"COLLAB\"`,`\"REDDIT5K\"` and `\"REDDIT12K\"` are not available yet (see README.md). Contact the authors for more information.\n",
    "\n",
    "Beware that for the datasets (`\"COLLAB\"`,`\"REDDIT5K\", \"REDDIT12K\", \"ORBIT100K\"`), the files can be quite large (e.g. 3Gb for for `\"ORBIT100K\"`), so that RAM can be limiting, and the time needed to generate the persistence diagrams and run the experiments can be quite long depending on the hardware available. Dataset descriptions are available in Section B of the supplementary material of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MUTAG\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we implicitely load our data (saved as `.mat` files for graphs datasets, and generated on-the-fly for orbits datasets---which can take some time for `\"ORBIT100K\"` especially), and then compute the persistence diagrams that will be used in the classification experiment (requires to have `gudhi` installed). For graph datasets, we also generate a series of additional features (see [1]).\n",
    "\n",
    "Running `generate_diag_and_features` will store diagrams, features and labels. Therefore, it is sufficient to run it just once (for each different dataset). Note that for bigger datasets, the computations of these persistence diagrams can be quite long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_diagrams_and_features(dataset, path_dataset=\"./data/MUTAG/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load and preprocess persistence diagrams (to make them PersLay-compatible) and other useful items using the files that we have generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diags_dict, F, L = load_data(dataset, path_dataset=\"./data/MUTAG/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = np.array(F, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualize persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to visualise some example of diagrams generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x1200 with 24 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_diagrams(diags_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# (Optional) Use your own persistence diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "__Note:__ Skip this section and make sure to go through Section 2 if you want to use the predefined persistence diagrams that we provide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We provide a (hopefully) convenient way to use your own persistence diagrams for a classification task (with some eventual features).\n",
    "\n",
    "Persistence diagrams must be given in the following format:\n",
    "assume you have $N$ observations. For each of them, you build $K$ different persistence diagrams (e.g. persistence diagrams in different homology dimensions, and/or for different filtrations, etc.). \n",
    "\n",
    "Then, you must provide a `diags_dict` variable that is a `dictionary`, whose $K$ keys are the persistence diagram type names (e.g. `\"Rips_dim_0\"`, `\"Cech_dim_1\"`). For each key $k_i$, $1 \\leq i \\leq K$, the corresponding value is a `list` of `np.arrays`, each array encoding a persistence diagram. \n",
    "\n",
    "Note that each list must have the same length $N$ (you need to have the same number of persistence diagrams generated for each list). Note also that you must keep the order (i.e. the first element of each list must correspond to the persistence diagram generated with the first observation, and so on).\n",
    "\n",
    "Below is an example of such a (very simple) dictionary, with two filtrations and two persistence diagrams in each:\n",
    "\n",
    "`diags_tmp = {\"Alpha0\":[np.array([[0.1, 0.2], [0.2, 0.5], [0.3, 0.9]]), np.array([[0.1, 0.4], [0.3, 0.5]]),], \"Alpha1\":[np.array([[0.1, 0.4], [0.2, 0.6], [0.4, 0.9]]), np.array([[0.1, 0.2], [0.5, 0.7], [0.8, 0.9]])]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### To use your own diagrams, uncomment and complete the following\n",
    "#diags_dict = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now, you must (obviously) provide the labels corresponding to each persistence diagram (be careful to keep the same order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### To use your own labels, uncomment and complete the following\n",
    "#L = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can use some additional \"standard\" features in your network. These features must be provided as a $N \\times d$ `np.array`, where $N$ is your number of observations (as before) and $d$ is the dimension of your features.\n",
    "\n",
    "If you do not want to use additional features, you must use an empty array of size $(N,0)$, where $N$ is the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Uncomment and complete the following line to not include additional features with PersLay.\n",
    "#N = # number of observations\n",
    "#F = np.array([[]]*N)\n",
    "\n",
    "### To use your own features instead, uncomment and complete the following\n",
    "#F = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If your persistence diagrams have not been preprocessed already, we now apply a preprocessing that makes our sets of persistence diagrams compatible with PersLay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Preprocess persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gudhi.representations as tda\n",
    "\n",
    "### Uncomment the following to process your diagrams (necessary)\n",
    "thresh = 500\n",
    "\n",
    "# Whole pipeline\n",
    "tmp = Pipeline([\n",
    "        (\"Selector\",      tda.DiagramSelector(use=True, point_type=\"finite\")),\n",
    "        (\"ProminentPts\",  tda.ProminentPoints(use=True, num_pts=thresh)),\n",
    "        (\"Scaler\",        tda.DiagramScaler(use=True, scalers=[([0,1], MinMaxScaler())])),\n",
    "        (\"Padding\",       tda.Padding(use=True)),\n",
    "                ])\n",
    "\n",
    "prm = {filt: {\"ProminentPts__num_pts\": min(thresh, max([len(dgm) for dgm in diags_dict[filt]]))} \n",
    "       for filt in diags_dict.keys() if max([len(dgm) for dgm in diags_dict[filt]]) > 0}\n",
    "\n",
    "# Apply the previous pipeline on the different filtrations.\n",
    "diags = []\n",
    "for dt in prm.keys():\n",
    "    param = prm[dt]\n",
    "    tmp.set_params(**param)\n",
    "    diags.append(tmp.fit_transform(diags_dict[dt]))\n",
    "\n",
    "# For each filtration, concatenate all diagrams in a single array.\n",
    "D, npts = [], len(diags[0])\n",
    "for dt in range(len(prm.keys())):\n",
    "    D.append(np.array(np.concatenate([diags[dt][i][np.newaxis,:] for i in range(npts)],axis=0),dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using PersLay in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Load network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 12:33:14.903219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:14.920105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:14.920239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:14.920763: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-21 12:33:14.921291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:14.921398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:14.921485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:16.041177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:16.041316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:16.041542: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-21 12:33:16.041666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, loss, metrics = get_model(dataset, F.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## (Optional) Define your own network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You might want to define your own PersLay architecture and to use your own optimizers, losses and/or metrics. To help you with it, we now show the different options regarding the parameters of PersLay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Initialize list of parameters for PersLay. This list will contain the different PersLay channel parameters (there is one channel per filtration/diagram type)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"final_model\"]   = \"identity\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Layer type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Choice of layer type, must be one of (see README.md and [1] for details):\n",
    "- `\"Image\"` for a persistence image layer.\n",
    "- `\"PermutationEquivariant\"` for a permutation equivariant layer (as in [2]).\n",
    "- `\"Exponential\"` for an exponential structure element layer (as in [3]).\n",
    "- `\"Rational\"` for a rational structure element layer (as in [3]).\n",
    "- `\"RationalHat\"` for a rational hat structure element layer (as in [3]).\n",
    "- `\"Landscape\"` for a persistence landscape layer.\n",
    "- `\"BettiCurve\"` for a Betti curve layer.\n",
    "- `\"Entropy\"` for a persistence entropy layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def rui(min, max):\n",
    "    return partial(torch.nn.init.uniform_, a=min, b=max)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"Image\"\n",
    "perslay_channel[\"image_size\"]      = (20, 20)\n",
    "perslay_channel[\"image_bnds\"]      = ((-.001, 1.001), (-.001, 1.001))\n",
    "perslay_channel[\"lvariance_init\"]  = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"PermutationEquivariant\"\n",
    "perslay_channel[\"lpeq\"]            = [(5, \"max\")]\n",
    "perslay_channel[\"lweight_init\"]    = rui(0.0, 1.0)\n",
    "perslay_channel[\"lbias_init\"]      = rui(0.0, 1.0)\n",
    "perslay_channel[\"lgamma_init\"]     = rui(0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"Exponential\"\n",
    "perslay_channel[\"lnum\"]            = 25\n",
    "perslay_channel[\"lmean_init\"]      = rui(0.0, 1.0)\n",
    "perslay_channel[\"lvariance_init\"]  = rui(3.0, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"Rational\"\n",
    "perslay_channel[\"lnum\"]            = 25\n",
    "perslay_channel[\"lmean_init\"]      = rui(0.0, 1.0)\n",
    "perslay_channel[\"lvariance_init\"]  = rui(3.0, 3.0) \n",
    "perslay_channel[\"lalpha_init\"]     = rui(3.0, 3.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"RationalHat\"\n",
    "perslay_channel[\"lnum\"]            = 25\n",
    "perslay_channel[\"lmean_init\"]      = rui(0.0, 1.0)\n",
    "perslay_channel[\"lr_init\"]         = rui(3.0, 3.0) \n",
    "perslay_channel[\"q\"]               = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"Landscape\"\n",
    "perslay_channel[\"lsample_num\"]     = 100\n",
    "perslay_channel[\"lsample_init\"]    = rui(0.0, 1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"BettiCurve\"\n",
    "perslay_channel[\"theta\"]           = 10\n",
    "perslay_channel[\"lsample_num\"]     = 100\n",
    "perslay_channel[\"lsample_init\"]    = rui(0.0, 1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"layer\"]           = \"Entropy\"\n",
    "perslay_channel[\"theta\"]           = 10\n",
    "perslay_channel[\"lsample_num\"]     = 100\n",
    "perslay_channel[\"lsample_init\"]    = rui(0.0, 1.0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Weight function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Choice of the weight function, must be one of:\n",
    "- `\"power\"`, for the distance to the diagonal with some exponent.\n",
    "- `\"grid\"`, for a piecewise-constant function defined with pixel values.\n",
    "- `\"gmix\"`, for a weight function defined as a mixture of Gaussians.\n",
    "- `None`, for a constant weight function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"pweight\"]       = \"power\"\n",
    "perslay_channel[\"pweight_init\"]  = 1.\n",
    "perslay_channel[\"pweight_power\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"pweight\"]       = \"grid\"\n",
    "perslay_channel[\"pweight_size\"]  = [20,20]\n",
    "perslay_channel[\"pweight_bnds\"]  = ((-.001, 1.001), (-.001, 1.001))\n",
    "perslay_channel[\"pweight_init\"]  = rui(1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"pweight\"]       = \"gmix\"\n",
    "perslay_channel[\"pweight_num\"]   = 3\n",
    "perslay_channel[\"pweight_init\"]  = np.array(np.vstack([np.random.uniform(0.,1.,[2,3]), \n",
    "                                                        5.*np.ones([2,3])]), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"pweight\"]       = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Permutation-invariant operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Choice of permutation invariant operator, must be one of:\n",
    "- `\"sum\"`.\n",
    "- `\"topk\"`, will select the $k$ highest values, specified in `keep`.\n",
    "- `\"max\"`.\n",
    "- `\"mean\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"perm_op\"] = \"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"perm_op\"] = \"topk\"\n",
    "perslay_channel[\"keep\"]    = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"perm_op\"] = \"max\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_channel[\"perm_op\"] = \"mean\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Definition of model and choice of optimizer, loss and metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use the same channel type for all filtrations and diagram types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "perslay_parameters = [perslay_channel for _ in range(len(D))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Final rho network is a simple dense layer to the number of labels\n",
    "rho = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(1600, L.shape[1]), torch.nn.Sigmoid())\n",
    "model = PerslayModel(diagdim=2, perslay_parameters=perslay_parameters, rho=rho)\n",
    "\n",
    "# Optimizer is Adam with exponential decay of learning rate and moving average of variables\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, eps=1e-4)\n",
    "\n",
    "# Loss is cross-entropy\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pts = len(D[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single run means using the `evaluate_model` function for training the PersLay architecture once and observing the performance (classification accuracy) on the test set.\n",
    "- For orbit datasets, we suggest to use a 70-30 train-test split, i.e. `test_size = 0.3`.\n",
    "- For graph datasets, we suggest to use a 90-10 train-test split, i.e. `test_size = 0.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = .3\n",
    "epochs    = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_perm = np.random.permutation(num_pts)\n",
    "train, test = random_perm[:int((1-test_size)*num_pts)], random_perm[int((1-test_size)*num_pts):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3873,  0.3471,  0.3687,  ..., -0.4881, -0.4635, -0.4755],\n",
      "        [-0.3942, -0.3496, -0.3523,  ...,  0.4731,  0.5038,  0.4801]])\n",
      "rho.1.bias tensor([ 0.3815, -0.3781])\n",
      "train_vars.0 tensor(1.6435)\n",
      "train_vars.1 tensor(2.3200)\n",
      "train_vars.2 tensor(1.7560)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5102)\n",
      "train_vars.5 tensor(2.4572)\n",
      "train_vars.6 tensor(1.9381)\n",
      "train_vars.7 tensor(2.1211)\n",
      "=====================================\n",
      "[1,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3882,  0.3480,  0.3696,  ..., -0.4872, -0.4625, -0.4746],\n",
      "        [-0.3950, -0.3504, -0.3531,  ...,  0.4722,  0.5028,  0.4791]])\n",
      "rho.1.bias tensor([ 0.3821, -0.3787])\n",
      "train_vars.0 tensor(1.6448)\n",
      "train_vars.1 tensor(2.3187)\n",
      "train_vars.2 tensor(1.7546)\n",
      "train_vars.3 tensor(2.2816)\n",
      "train_vars.4 tensor(1.5123)\n",
      "train_vars.5 tensor(2.4549)\n",
      "train_vars.6 tensor(1.9367)\n",
      "train_vars.7 tensor(2.1228)\n",
      "=====================================\n",
      "[1,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3876,  0.3474,  0.3690,  ..., -0.4881, -0.4635, -0.4755],\n",
      "        [-0.3944, -0.3498, -0.3525,  ...,  0.4732,  0.5038,  0.4801]])\n",
      "rho.1.bias tensor([ 0.3811, -0.3777])\n",
      "train_vars.0 tensor(1.6438)\n",
      "train_vars.1 tensor(2.3197)\n",
      "train_vars.2 tensor(1.7557)\n",
      "train_vars.3 tensor(2.2806)\n",
      "train_vars.4 tensor(1.5113)\n",
      "train_vars.5 tensor(2.4560)\n",
      "train_vars.6 tensor(1.9381)\n",
      "train_vars.7 tensor(2.1215)\n",
      "=====================================\n",
      "[1,     4] loss: 0.482\n",
      "rho.1.weight tensor([[ 0.3874,  0.3472,  0.3687,  ..., -0.4888, -0.4642, -0.4762],\n",
      "        [-0.3942, -0.3496, -0.3523,  ...,  0.4738,  0.5045,  0.4808]])\n",
      "rho.1.bias tensor([ 0.3805, -0.3771])\n",
      "train_vars.0 tensor(1.6435)\n",
      "train_vars.1 tensor(2.3201)\n",
      "train_vars.2 tensor(1.7562)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5109)\n",
      "train_vars.5 tensor(2.4564)\n",
      "train_vars.6 tensor(1.9391)\n",
      "train_vars.7 tensor(2.1206)\n",
      "=====================================\n",
      "[1,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3873,  0.3471,  0.3687,  ..., -0.4894, -0.4648, -0.4769],\n",
      "        [-0.3941, -0.3496, -0.3523,  ...,  0.4745,  0.5052,  0.4815]])\n",
      "rho.1.bias tensor([ 0.3801, -0.3767])\n",
      "train_vars.0 tensor(1.6434)\n",
      "train_vars.1 tensor(2.3202)\n",
      "train_vars.2 tensor(1.7564)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5107)\n",
      "train_vars.5 tensor(2.4566)\n",
      "train_vars.6 tensor(1.9400)\n",
      "train_vars.7 tensor(2.1197)\n",
      "=====================================\n",
      "[1,     6] loss: 0.548\n",
      "rho.1.weight tensor([[ 0.3870,  0.3468,  0.3684,  ..., -0.4895, -0.4649, -0.4769],\n",
      "        [-0.3938, -0.3492, -0.3519,  ...,  0.4746,  0.5053,  0.4816]])\n",
      "rho.1.bias tensor([ 0.3792, -0.3758])\n",
      "train_vars.0 tensor(1.6429)\n",
      "train_vars.1 tensor(2.3208)\n",
      "train_vars.2 tensor(1.7568)\n",
      "train_vars.3 tensor(2.2797)\n",
      "train_vars.4 tensor(1.5111)\n",
      "train_vars.5 tensor(2.4562)\n",
      "train_vars.6 tensor(1.9401)\n",
      "train_vars.7 tensor(2.1198)\n",
      "=====================================\n",
      "[2,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3871,  0.3469,  0.3685,  ..., -0.4895, -0.4649, -0.4769],\n",
      "        [-0.3939, -0.3493, -0.3520,  ...,  0.4745,  0.5052,  0.4815]])\n",
      "rho.1.bias tensor([ 0.3790, -0.3756])\n",
      "train_vars.0 tensor(1.6430)\n",
      "train_vars.1 tensor(2.3207)\n",
      "train_vars.2 tensor(1.7565)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5118)\n",
      "train_vars.5 tensor(2.4555)\n",
      "train_vars.6 tensor(1.9401)\n",
      "train_vars.7 tensor(2.1200)\n",
      "=====================================\n",
      "[2,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3879,  0.3477,  0.3693,  ..., -0.4885, -0.4639, -0.4760],\n",
      "        [-0.3947, -0.3502, -0.3529,  ...,  0.4736,  0.5043,  0.4806]])\n",
      "rho.1.bias tensor([ 0.3796, -0.3763])\n",
      "train_vars.0 tensor(1.6443)\n",
      "train_vars.1 tensor(2.3194)\n",
      "train_vars.2 tensor(1.7551)\n",
      "train_vars.3 tensor(2.2817)\n",
      "train_vars.4 tensor(1.5139)\n",
      "train_vars.5 tensor(2.4533)\n",
      "train_vars.6 tensor(1.9386)\n",
      "train_vars.7 tensor(2.1217)\n",
      "=====================================\n",
      "[2,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3873,  0.3471,  0.3687,  ..., -0.4895, -0.4649, -0.4770],\n",
      "        [-0.3941, -0.3495, -0.3522,  ...,  0.4746,  0.5053,  0.4816]])\n",
      "rho.1.bias tensor([ 0.3786, -0.3753])\n",
      "train_vars.0 tensor(1.6433)\n",
      "train_vars.1 tensor(2.3204)\n",
      "train_vars.2 tensor(1.7562)\n",
      "train_vars.3 tensor(2.2806)\n",
      "train_vars.4 tensor(1.5129)\n",
      "train_vars.5 tensor(2.4544)\n",
      "train_vars.6 tensor(1.9400)\n",
      "train_vars.7 tensor(2.1203)\n",
      "=====================================\n",
      "[2,     4] loss: 0.482\n",
      "rho.1.weight tensor([[ 0.3871,  0.3469,  0.3685,  ..., -0.4902, -0.4656, -0.4776],\n",
      "        [-0.3939, -0.3493, -0.3520,  ...,  0.4753,  0.5060,  0.4823]])\n",
      "rho.1.bias tensor([ 0.3780, -0.3746])\n",
      "train_vars.0 tensor(1.6429)\n",
      "train_vars.1 tensor(2.3208)\n",
      "train_vars.2 tensor(1.7568)\n",
      "train_vars.3 tensor(2.2802)\n",
      "train_vars.4 tensor(1.5125)\n",
      "train_vars.5 tensor(2.4548)\n",
      "train_vars.6 tensor(1.9410)\n",
      "train_vars.7 tensor(2.1194)\n",
      "=====================================\n",
      "[2,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3870,  0.3469,  0.3684,  ..., -0.4908, -0.4662, -0.4783],\n",
      "        [-0.3938, -0.3493, -0.3520,  ...,  0.4759,  0.5066,  0.4829]])\n",
      "rho.1.bias tensor([ 0.3776, -0.3742])\n",
      "train_vars.0 tensor(1.6429)\n",
      "train_vars.1 tensor(2.3209)\n",
      "train_vars.2 tensor(1.7569)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5123)\n",
      "train_vars.5 tensor(2.4550)\n",
      "train_vars.6 tensor(1.9419)\n",
      "train_vars.7 tensor(2.1186)\n",
      "=====================================\n",
      "[2,     6] loss: 0.548\n",
      "rho.1.weight tensor([[ 0.3867,  0.3465,  0.3681,  ..., -0.4909, -0.4663, -0.4783],\n",
      "        [-0.3935, -0.3489, -0.3517,  ...,  0.4760,  0.5067,  0.4830]])\n",
      "rho.1.bias tensor([ 0.3767, -0.3734])\n",
      "train_vars.0 tensor(1.6424)\n",
      "train_vars.1 tensor(2.3215)\n",
      "train_vars.2 tensor(1.7574)\n",
      "train_vars.3 tensor(2.2797)\n",
      "train_vars.4 tensor(1.5127)\n",
      "train_vars.5 tensor(2.4546)\n",
      "train_vars.6 tensor(1.9420)\n",
      "train_vars.7 tensor(2.1186)\n",
      "=====================================\n",
      "[3,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3868,  0.3466,  0.3682,  ..., -0.4909, -0.4663, -0.4783],\n",
      "        [-0.3936, -0.3490, -0.3517,  ...,  0.4759,  0.5066,  0.4830]])\n",
      "rho.1.bias tensor([ 0.3765, -0.3732])\n",
      "train_vars.0 tensor(1.6424)\n",
      "train_vars.1 tensor(2.3214)\n",
      "train_vars.2 tensor(1.7571)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5134)\n",
      "train_vars.5 tensor(2.4539)\n",
      "train_vars.6 tensor(1.9420)\n",
      "train_vars.7 tensor(2.1188)\n",
      "=====================================\n",
      "[3,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3876,  0.3474,  0.3690,  ..., -0.4899, -0.4653, -0.4774],\n",
      "        [-0.3944, -0.3499, -0.3526,  ...,  0.4750,  0.5057,  0.4820]])\n",
      "rho.1.bias tensor([ 0.3771, -0.3738])\n",
      "train_vars.0 tensor(1.6437)\n",
      "train_vars.1 tensor(2.3201)\n",
      "train_vars.2 tensor(1.7557)\n",
      "train_vars.3 tensor(2.2817)\n",
      "train_vars.4 tensor(1.5155)\n",
      "train_vars.5 tensor(2.4517)\n",
      "train_vars.6 tensor(1.9405)\n",
      "train_vars.7 tensor(2.1206)\n",
      "=====================================\n",
      "[3,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3870,  0.3468,  0.3684,  ..., -0.4909, -0.4663, -0.4784],\n",
      "        [-0.3938, -0.3492, -0.3519,  ...,  0.4760,  0.5067,  0.4830]])\n",
      "rho.1.bias tensor([ 0.3761, -0.3728])\n",
      "train_vars.0 tensor(1.6427)\n",
      "train_vars.1 tensor(2.3211)\n",
      "train_vars.2 tensor(1.7567)\n",
      "train_vars.3 tensor(2.2807)\n",
      "train_vars.4 tensor(1.5145)\n",
      "train_vars.5 tensor(2.4528)\n",
      "train_vars.6 tensor(1.9419)\n",
      "train_vars.7 tensor(2.1192)\n",
      "=====================================\n",
      "[3,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3868,  0.3466,  0.3682,  ..., -0.4915, -0.4670, -0.4790],\n",
      "        [-0.3936, -0.3490, -0.3517,  ...,  0.4767,  0.5074,  0.4837]])\n",
      "rho.1.bias tensor([ 0.3755, -0.3722])\n",
      "train_vars.0 tensor(1.6424)\n",
      "train_vars.1 tensor(2.3215)\n",
      "train_vars.2 tensor(1.7573)\n",
      "train_vars.3 tensor(2.2802)\n",
      "train_vars.4 tensor(1.5141)\n",
      "train_vars.5 tensor(2.4532)\n",
      "train_vars.6 tensor(1.9429)\n",
      "train_vars.7 tensor(2.1183)\n",
      "=====================================\n",
      "[3,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3867,  0.3466,  0.3682,  ..., -0.4922, -0.4676, -0.4797],\n",
      "        [-0.3935, -0.3490, -0.3517,  ...,  0.4773,  0.5080,  0.4844]])\n",
      "rho.1.bias tensor([ 0.3751, -0.3717])\n",
      "train_vars.0 tensor(1.6423)\n",
      "train_vars.1 tensor(2.3216)\n",
      "train_vars.2 tensor(1.7575)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5139)\n",
      "train_vars.5 tensor(2.4534)\n",
      "train_vars.6 tensor(1.9438)\n",
      "train_vars.7 tensor(2.1175)\n",
      "=====================================\n",
      "[3,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3864,  0.3462,  0.3678,  ..., -0.4922, -0.4677, -0.4797],\n",
      "        [-0.3932, -0.3486, -0.3514,  ...,  0.4774,  0.5081,  0.4844]])\n",
      "rho.1.bias tensor([ 0.3742, -0.3709])\n",
      "train_vars.0 tensor(1.6418)\n",
      "train_vars.1 tensor(2.3222)\n",
      "train_vars.2 tensor(1.7579)\n",
      "train_vars.3 tensor(2.2798)\n",
      "train_vars.4 tensor(1.5143)\n",
      "train_vars.5 tensor(2.4530)\n",
      "train_vars.6 tensor(1.9439)\n",
      "train_vars.7 tensor(2.1175)\n",
      "=====================================\n",
      "[4,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3865,  0.3463,  0.3679,  ..., -0.4922, -0.4676, -0.4797],\n",
      "        [-0.3933, -0.3487, -0.3514,  ...,  0.4773,  0.5081,  0.4844]])\n",
      "rho.1.bias tensor([ 0.3740, -0.3707])\n",
      "train_vars.0 tensor(1.6419)\n",
      "train_vars.1 tensor(2.3221)\n",
      "train_vars.2 tensor(1.7576)\n",
      "train_vars.3 tensor(2.2802)\n",
      "train_vars.4 tensor(1.5150)\n",
      "train_vars.5 tensor(2.4523)\n",
      "train_vars.6 tensor(1.9438)\n",
      "train_vars.7 tensor(2.1177)\n",
      "=====================================\n",
      "[4,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3873,  0.3471,  0.3687,  ..., -0.4912, -0.4667, -0.4788],\n",
      "        [-0.3941, -0.3496, -0.3523,  ...,  0.4764,  0.5071,  0.4835]])\n",
      "rho.1.bias tensor([ 0.3747, -0.3713])\n",
      "train_vars.0 tensor(1.6431)\n",
      "train_vars.1 tensor(2.3209)\n",
      "train_vars.2 tensor(1.7562)\n",
      "train_vars.3 tensor(2.2817)\n",
      "train_vars.4 tensor(1.5170)\n",
      "train_vars.5 tensor(2.4501)\n",
      "train_vars.6 tensor(1.9424)\n",
      "train_vars.7 tensor(2.1194)\n",
      "=====================================\n",
      "[4,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3867,  0.3465,  0.3681,  ..., -0.4922, -0.4677, -0.4797],\n",
      "        [-0.3935, -0.3489, -0.3516,  ...,  0.4774,  0.5081,  0.4845]])\n",
      "rho.1.bias tensor([ 0.3736, -0.3703])\n",
      "train_vars.0 tensor(1.6422)\n",
      "train_vars.1 tensor(2.3219)\n",
      "train_vars.2 tensor(1.7573)\n",
      "train_vars.3 tensor(2.2807)\n",
      "train_vars.4 tensor(1.5161)\n",
      "train_vars.5 tensor(2.4512)\n",
      "train_vars.6 tensor(1.9438)\n",
      "train_vars.7 tensor(2.1181)\n",
      "=====================================\n",
      "[4,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3865,  0.3463,  0.3679,  ..., -0.4929, -0.4683, -0.4804],\n",
      "        [-0.3933, -0.3487, -0.3514,  ...,  0.4780,  0.5088,  0.4852]])\n",
      "rho.1.bias tensor([ 0.3730, -0.3697])\n",
      "train_vars.0 tensor(1.6418)\n",
      "train_vars.1 tensor(2.3223)\n",
      "train_vars.2 tensor(1.7578)\n",
      "train_vars.3 tensor(2.2802)\n",
      "train_vars.4 tensor(1.5157)\n",
      "train_vars.5 tensor(2.4516)\n",
      "train_vars.6 tensor(1.9448)\n",
      "train_vars.7 tensor(2.1172)\n",
      "=====================================\n",
      "[4,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3864,  0.3463,  0.3679,  ..., -0.4935, -0.4690, -0.4811],\n",
      "        [-0.3932, -0.3487, -0.3514,  ...,  0.4787,  0.5094,  0.4858]])\n",
      "rho.1.bias tensor([ 0.3726, -0.3693])\n",
      "train_vars.0 tensor(1.6417)\n",
      "train_vars.1 tensor(2.3224)\n",
      "train_vars.2 tensor(1.7580)\n",
      "train_vars.3 tensor(2.2802)\n",
      "train_vars.4 tensor(1.5155)\n",
      "train_vars.5 tensor(2.4519)\n",
      "train_vars.6 tensor(1.9457)\n",
      "train_vars.7 tensor(2.1163)\n",
      "=====================================\n",
      "[4,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3861,  0.3459,  0.3675,  ..., -0.4936, -0.4690, -0.4811],\n",
      "        [-0.3929, -0.3483, -0.3510,  ...,  0.4787,  0.5095,  0.4859]])\n",
      "rho.1.bias tensor([ 0.3717, -0.3684])\n",
      "train_vars.0 tensor(1.6412)\n",
      "train_vars.1 tensor(2.3229)\n",
      "train_vars.2 tensor(1.7584)\n",
      "train_vars.3 tensor(2.2798)\n",
      "train_vars.4 tensor(1.5158)\n",
      "train_vars.5 tensor(2.4515)\n",
      "train_vars.6 tensor(1.9458)\n",
      "train_vars.7 tensor(2.1164)\n",
      "=====================================\n",
      "[5,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3862,  0.3460,  0.3676,  ..., -0.4935, -0.4690, -0.4811],\n",
      "        [-0.3930, -0.3484, -0.3511,  ...,  0.4787,  0.5095,  0.4858]])\n",
      "rho.1.bias tensor([ 0.3715, -0.3682])\n",
      "train_vars.0 tensor(1.6413)\n",
      "train_vars.1 tensor(2.3229)\n",
      "train_vars.2 tensor(1.7581)\n",
      "train_vars.3 tensor(2.2803)\n",
      "train_vars.4 tensor(1.5165)\n",
      "train_vars.5 tensor(2.4507)\n",
      "train_vars.6 tensor(1.9457)\n",
      "train_vars.7 tensor(2.1166)\n",
      "=====================================\n",
      "[5,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3870,  0.3468,  0.3684,  ..., -0.4926, -0.4680, -0.4801],\n",
      "        [-0.3938, -0.3492, -0.3520,  ...,  0.4777,  0.5085,  0.4849]])\n",
      "rho.1.bias tensor([ 0.3721, -0.3689])\n",
      "train_vars.0 tensor(1.6425)\n",
      "train_vars.1 tensor(2.3216)\n",
      "train_vars.2 tensor(1.7567)\n",
      "train_vars.3 tensor(2.2818)\n",
      "train_vars.4 tensor(1.5186)\n",
      "train_vars.5 tensor(2.4485)\n",
      "train_vars.6 tensor(1.9443)\n",
      "train_vars.7 tensor(2.1183)\n",
      "=====================================\n",
      "[5,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3864,  0.3462,  0.3678,  ..., -0.4936, -0.4690, -0.4811],\n",
      "        [-0.3932, -0.3486, -0.3513,  ...,  0.4787,  0.5095,  0.4859]])\n",
      "rho.1.bias tensor([ 0.3711, -0.3678])\n",
      "train_vars.0 tensor(1.6416)\n",
      "train_vars.1 tensor(2.3226)\n",
      "train_vars.2 tensor(1.7578)\n",
      "train_vars.3 tensor(2.2808)\n",
      "train_vars.4 tensor(1.5176)\n",
      "train_vars.5 tensor(2.4496)\n",
      "train_vars.6 tensor(1.9457)\n",
      "train_vars.7 tensor(2.1170)\n",
      "=====================================\n",
      "[5,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3861,  0.3460,  0.3676,  ..., -0.4942, -0.4697, -0.4818],\n",
      "        [-0.3929, -0.3484, -0.3511,  ...,  0.4794,  0.5102,  0.4866]])\n",
      "rho.1.bias tensor([ 0.3705, -0.3672])\n",
      "train_vars.0 tensor(1.6412)\n",
      "train_vars.1 tensor(2.3230)\n",
      "train_vars.2 tensor(1.7583)\n",
      "train_vars.3 tensor(2.2803)\n",
      "train_vars.4 tensor(1.5172)\n",
      "train_vars.5 tensor(2.4501)\n",
      "train_vars.6 tensor(1.9467)\n",
      "train_vars.7 tensor(2.1160)\n",
      "=====================================\n",
      "[5,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3861,  0.3459,  0.3675,  ..., -0.4949, -0.4703, -0.4825],\n",
      "        [-0.3929, -0.3483, -0.3510,  ...,  0.4801,  0.5108,  0.4872]])\n",
      "rho.1.bias tensor([ 0.3701, -0.3668])\n",
      "train_vars.0 tensor(1.6411)\n",
      "train_vars.1 tensor(2.3231)\n",
      "train_vars.2 tensor(1.7585)\n",
      "train_vars.3 tensor(2.2803)\n",
      "train_vars.4 tensor(1.5170)\n",
      "train_vars.5 tensor(2.4503)\n",
      "train_vars.6 tensor(1.9476)\n",
      "train_vars.7 tensor(2.1152)\n",
      "=====================================\n",
      "[5,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3858,  0.3456,  0.3672,  ..., -0.4949, -0.4704, -0.4825],\n",
      "        [-0.3926, -0.3480, -0.3507,  ...,  0.4801,  0.5109,  0.4873]])\n",
      "rho.1.bias tensor([ 0.3692, -0.3660])\n",
      "train_vars.0 tensor(1.6406)\n",
      "train_vars.1 tensor(2.3237)\n",
      "train_vars.2 tensor(1.7589)\n",
      "train_vars.3 tensor(2.2799)\n",
      "train_vars.4 tensor(1.5174)\n",
      "train_vars.5 tensor(2.4499)\n",
      "train_vars.6 tensor(1.9477)\n",
      "train_vars.7 tensor(2.1153)\n",
      "=====================================\n",
      "[6,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3858,  0.3457,  0.3673,  ..., -0.4949, -0.4704, -0.4825],\n",
      "        [-0.3926, -0.3481, -0.3508,  ...,  0.4801,  0.5109,  0.4873]])\n",
      "rho.1.bias tensor([ 0.3690, -0.3658])\n",
      "train_vars.0 tensor(1.6407)\n",
      "train_vars.1 tensor(2.3236)\n",
      "train_vars.2 tensor(1.7586)\n",
      "train_vars.3 tensor(2.2803)\n",
      "train_vars.4 tensor(1.5181)\n",
      "train_vars.5 tensor(2.4492)\n",
      "train_vars.6 tensor(1.9476)\n",
      "train_vars.7 tensor(2.1155)\n",
      "=====================================\n",
      "[6,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3867,  0.3465,  0.3681,  ..., -0.4939, -0.4694, -0.4815],\n",
      "        [-0.3935, -0.3489, -0.3516,  ...,  0.4791,  0.5099,  0.4863]])\n",
      "rho.1.bias tensor([ 0.3696, -0.3664])\n",
      "train_vars.0 tensor(1.6419)\n",
      "train_vars.1 tensor(2.3224)\n",
      "train_vars.2 tensor(1.7572)\n",
      "train_vars.3 tensor(2.2819)\n",
      "train_vars.4 tensor(1.5202)\n",
      "train_vars.5 tensor(2.4470)\n",
      "train_vars.6 tensor(1.9461)\n",
      "train_vars.7 tensor(2.1172)\n",
      "=====================================\n",
      "[6,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3860,  0.3459,  0.3675,  ..., -0.4949, -0.4704, -0.4825],\n",
      "        [-0.3928, -0.3483, -0.3510,  ...,  0.4801,  0.5109,  0.4873]])\n",
      "rho.1.bias tensor([ 0.3686, -0.3654])\n",
      "train_vars.0 tensor(1.6409)\n",
      "train_vars.1 tensor(2.3234)\n",
      "train_vars.2 tensor(1.7583)\n",
      "train_vars.3 tensor(2.2809)\n",
      "train_vars.4 tensor(1.5192)\n",
      "train_vars.5 tensor(2.4481)\n",
      "train_vars.6 tensor(1.9475)\n",
      "train_vars.7 tensor(2.1159)\n",
      "=====================================\n",
      "[6,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3858,  0.3457,  0.3673,  ..., -0.4956, -0.4711, -0.4832],\n",
      "        [-0.3926, -0.3480, -0.3508,  ...,  0.4808,  0.5116,  0.4880]])\n",
      "rho.1.bias tensor([ 0.3680, -0.3647])\n",
      "train_vars.0 tensor(1.6406)\n",
      "train_vars.1 tensor(2.3238)\n",
      "train_vars.2 tensor(1.7588)\n",
      "train_vars.3 tensor(2.2804)\n",
      "train_vars.4 tensor(1.5188)\n",
      "train_vars.5 tensor(2.4485)\n",
      "train_vars.6 tensor(1.9485)\n",
      "train_vars.7 tensor(2.1149)\n",
      "=====================================\n",
      "[6,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3858,  0.3456,  0.3672,  ..., -0.4962, -0.4717, -0.4838],\n",
      "        [-0.3925, -0.3480, -0.3507,  ...,  0.4815,  0.5123,  0.4887]])\n",
      "rho.1.bias tensor([ 0.3675, -0.3643])\n",
      "train_vars.0 tensor(1.6405)\n",
      "train_vars.1 tensor(2.3239)\n",
      "train_vars.2 tensor(1.7590)\n",
      "train_vars.3 tensor(2.2803)\n",
      "train_vars.4 tensor(1.5186)\n",
      "train_vars.5 tensor(2.4487)\n",
      "train_vars.6 tensor(1.9494)\n",
      "train_vars.7 tensor(2.1141)\n",
      "=====================================\n",
      "[6,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3854,  0.3453,  0.3669,  ..., -0.4963, -0.4718, -0.4839],\n",
      "        [-0.3922, -0.3477, -0.3504,  ...,  0.4815,  0.5123,  0.4887]])\n",
      "rho.1.bias tensor([ 0.3667, -0.3635])\n",
      "train_vars.0 tensor(1.6400)\n",
      "train_vars.1 tensor(2.3245)\n",
      "train_vars.2 tensor(1.7594)\n",
      "train_vars.3 tensor(2.2800)\n",
      "train_vars.4 tensor(1.5189)\n",
      "train_vars.5 tensor(2.4483)\n",
      "train_vars.6 tensor(1.9495)\n",
      "train_vars.7 tensor(2.1142)\n",
      "=====================================\n",
      "[7,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3855,  0.3453,  0.3669,  ..., -0.4962, -0.4717, -0.4839],\n",
      "        [-0.3923, -0.3477, -0.3505,  ...,  0.4815,  0.5123,  0.4887]])\n",
      "rho.1.bias tensor([ 0.3665, -0.3633])\n",
      "train_vars.0 tensor(1.6401)\n",
      "train_vars.1 tensor(2.3244)\n",
      "train_vars.2 tensor(1.7590)\n",
      "train_vars.3 tensor(2.2804)\n",
      "train_vars.4 tensor(1.5196)\n",
      "train_vars.5 tensor(2.4476)\n",
      "train_vars.6 tensor(1.9494)\n",
      "train_vars.7 tensor(2.1144)\n",
      "=====================================\n",
      "[7,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3863,  0.3462,  0.3678,  ..., -0.4952, -0.4707, -0.4829],\n",
      "        [-0.3931, -0.3485, -0.3513,  ...,  0.4805,  0.5113,  0.4877]])\n",
      "rho.1.bias tensor([ 0.3671, -0.3639])\n",
      "train_vars.0 tensor(1.6413)\n",
      "train_vars.1 tensor(2.3232)\n",
      "train_vars.2 tensor(1.7577)\n",
      "train_vars.3 tensor(2.2820)\n",
      "train_vars.4 tensor(1.5217)\n",
      "train_vars.5 tensor(2.4454)\n",
      "train_vars.6 tensor(1.9480)\n",
      "train_vars.7 tensor(2.1162)\n",
      "=====================================\n",
      "[7,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3857,  0.3455,  0.3671,  ..., -0.4962, -0.4717, -0.4839],\n",
      "        [-0.3925, -0.3479, -0.3506,  ...,  0.4815,  0.5123,  0.4887]])\n",
      "rho.1.bias tensor([ 0.3661, -0.3629])\n",
      "train_vars.0 tensor(1.6403)\n",
      "train_vars.1 tensor(2.3242)\n",
      "train_vars.2 tensor(1.7587)\n",
      "train_vars.3 tensor(2.2810)\n",
      "train_vars.4 tensor(1.5207)\n",
      "train_vars.5 tensor(2.4465)\n",
      "train_vars.6 tensor(1.9494)\n",
      "train_vars.7 tensor(2.1148)\n",
      "=====================================\n",
      "[7,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3855,  0.3453,  0.3669,  ..., -0.4969, -0.4724, -0.4846],\n",
      "        [-0.3922, -0.3477, -0.3504,  ...,  0.4822,  0.5130,  0.4895]])\n",
      "rho.1.bias tensor([ 0.3655, -0.3623])\n",
      "train_vars.0 tensor(1.6399)\n",
      "train_vars.1 tensor(2.3246)\n",
      "train_vars.2 tensor(1.7593)\n",
      "train_vars.3 tensor(2.2805)\n",
      "train_vars.4 tensor(1.5203)\n",
      "train_vars.5 tensor(2.4470)\n",
      "train_vars.6 tensor(1.9504)\n",
      "train_vars.7 tensor(2.1139)\n",
      "=====================================\n",
      "[7,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3854,  0.3453,  0.3669,  ..., -0.4975, -0.4730, -0.4852],\n",
      "        [-0.3922, -0.3476, -0.3504,  ...,  0.4828,  0.5137,  0.4901]])\n",
      "rho.1.bias tensor([ 0.3650, -0.3618])\n",
      "train_vars.0 tensor(1.6398)\n",
      "train_vars.1 tensor(2.3247)\n",
      "train_vars.2 tensor(1.7594)\n",
      "train_vars.3 tensor(2.2804)\n",
      "train_vars.4 tensor(1.5201)\n",
      "train_vars.5 tensor(2.4472)\n",
      "train_vars.6 tensor(1.9513)\n",
      "train_vars.7 tensor(2.1131)\n",
      "=====================================\n",
      "[7,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3851,  0.3449,  0.3665,  ..., -0.4976, -0.4731, -0.4853],\n",
      "        [-0.3918, -0.3473, -0.3500,  ...,  0.4829,  0.5137,  0.4901]])\n",
      "rho.1.bias tensor([ 0.3642, -0.3610])\n",
      "train_vars.0 tensor(1.6393)\n",
      "train_vars.1 tensor(2.3253)\n",
      "train_vars.2 tensor(1.7598)\n",
      "train_vars.3 tensor(2.2801)\n",
      "train_vars.4 tensor(1.5205)\n",
      "train_vars.5 tensor(2.4468)\n",
      "train_vars.6 tensor(1.9513)\n",
      "train_vars.7 tensor(2.1131)\n",
      "=====================================\n",
      "[8,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3851,  0.3450,  0.3666,  ..., -0.4975, -0.4731, -0.4852],\n",
      "        [-0.3919, -0.3474, -0.3501,  ...,  0.4828,  0.5137,  0.4901]])\n",
      "rho.1.bias tensor([ 0.3640, -0.3608])\n",
      "train_vars.0 tensor(1.6394)\n",
      "train_vars.1 tensor(2.3252)\n",
      "train_vars.2 tensor(1.7595)\n",
      "train_vars.3 tensor(2.2805)\n",
      "train_vars.4 tensor(1.5212)\n",
      "train_vars.5 tensor(2.4461)\n",
      "train_vars.6 tensor(1.9513)\n",
      "train_vars.7 tensor(2.1134)\n",
      "=====================================\n",
      "[8,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3859,  0.3458,  0.3674,  ..., -0.4966, -0.4721, -0.4843],\n",
      "        [-0.3927, -0.3482, -0.3509,  ...,  0.4819,  0.5127,  0.4892]])\n",
      "rho.1.bias tensor([ 0.3646, -0.3614])\n",
      "train_vars.0 tensor(1.6406)\n",
      "train_vars.1 tensor(2.3240)\n",
      "train_vars.2 tensor(1.7581)\n",
      "train_vars.3 tensor(2.2821)\n",
      "train_vars.4 tensor(1.5232)\n",
      "train_vars.5 tensor(2.4439)\n",
      "train_vars.6 tensor(1.9498)\n",
      "train_vars.7 tensor(2.1151)\n",
      "=====================================\n",
      "[8,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3853,  0.3452,  0.3668,  ..., -0.4976, -0.4731, -0.4853],\n",
      "        [-0.3921, -0.3475, -0.3503,  ...,  0.4829,  0.5137,  0.4902]])\n",
      "rho.1.bias tensor([ 0.3636, -0.3604])\n",
      "train_vars.0 tensor(1.6396)\n",
      "train_vars.1 tensor(2.3250)\n",
      "train_vars.2 tensor(1.7592)\n",
      "train_vars.3 tensor(2.2811)\n",
      "train_vars.4 tensor(1.5222)\n",
      "train_vars.5 tensor(2.4450)\n",
      "train_vars.6 tensor(1.9512)\n",
      "train_vars.7 tensor(2.1137)\n",
      "=====================================\n",
      "[8,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3851,  0.3449,  0.3666,  ..., -0.4982, -0.4738, -0.4860],\n",
      "        [-0.3918, -0.3473, -0.3500,  ...,  0.4836,  0.5144,  0.4909]])\n",
      "rho.1.bias tensor([ 0.3629, -0.3598])\n",
      "train_vars.0 tensor(1.6393)\n",
      "train_vars.1 tensor(2.3255)\n",
      "train_vars.2 tensor(1.7597)\n",
      "train_vars.3 tensor(2.2806)\n",
      "train_vars.4 tensor(1.5218)\n",
      "train_vars.5 tensor(2.4455)\n",
      "train_vars.6 tensor(1.9522)\n",
      "train_vars.7 tensor(2.1128)\n",
      "=====================================\n",
      "[8,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3850,  0.3449,  0.3665,  ..., -0.4989, -0.4744, -0.4866],\n",
      "        [-0.3918, -0.3472, -0.3500,  ...,  0.4842,  0.5150,  0.4915]])\n",
      "rho.1.bias tensor([ 0.3625, -0.3593])\n",
      "train_vars.0 tensor(1.6392)\n",
      "train_vars.1 tensor(2.3256)\n",
      "train_vars.2 tensor(1.7599)\n",
      "train_vars.3 tensor(2.2805)\n",
      "train_vars.4 tensor(1.5216)\n",
      "train_vars.5 tensor(2.4457)\n",
      "train_vars.6 tensor(1.9531)\n",
      "train_vars.7 tensor(2.1120)\n",
      "=====================================\n",
      "[8,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3847,  0.3446,  0.3662,  ..., -0.4989, -0.4744, -0.4866],\n",
      "        [-0.3915, -0.3469, -0.3497,  ...,  0.4842,  0.5151,  0.4916]])\n",
      "rho.1.bias tensor([ 0.3616, -0.3585])\n",
      "train_vars.0 tensor(1.6386)\n",
      "train_vars.1 tensor(2.3261)\n",
      "train_vars.2 tensor(1.7603)\n",
      "train_vars.3 tensor(2.2802)\n",
      "train_vars.4 tensor(1.5220)\n",
      "train_vars.5 tensor(2.4453)\n",
      "train_vars.6 tensor(1.9532)\n",
      "train_vars.7 tensor(2.1121)\n",
      "=====================================\n",
      "[9,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3848,  0.3446,  0.3662,  ..., -0.4989, -0.4744, -0.4866],\n",
      "        [-0.3915, -0.3470, -0.3497,  ...,  0.4842,  0.5151,  0.4915]])\n",
      "rho.1.bias tensor([ 0.3614, -0.3583])\n",
      "train_vars.0 tensor(1.6387)\n",
      "train_vars.1 tensor(2.3261)\n",
      "train_vars.2 tensor(1.7599)\n",
      "train_vars.3 tensor(2.2807)\n",
      "train_vars.4 tensor(1.5227)\n",
      "train_vars.5 tensor(2.4446)\n",
      "train_vars.6 tensor(1.9531)\n",
      "train_vars.7 tensor(2.1123)\n",
      "=====================================\n",
      "[9,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3856,  0.3454,  0.3671,  ..., -0.4979, -0.4734, -0.4856],\n",
      "        [-0.3923, -0.3478, -0.3505,  ...,  0.4832,  0.5141,  0.4906]])\n",
      "rho.1.bias tensor([ 0.3621, -0.3589])\n",
      "train_vars.0 tensor(1.6399)\n",
      "train_vars.1 tensor(2.3249)\n",
      "train_vars.2 tensor(1.7586)\n",
      "train_vars.3 tensor(2.2822)\n",
      "train_vars.4 tensor(1.5247)\n",
      "train_vars.5 tensor(2.4424)\n",
      "train_vars.6 tensor(1.9516)\n",
      "train_vars.7 tensor(2.1140)\n",
      "=====================================\n",
      "[9,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3849,  0.3448,  0.3664,  ..., -0.4989, -0.4744, -0.4866],\n",
      "        [-0.3917, -0.3472, -0.3499,  ...,  0.4842,  0.5151,  0.4916]])\n",
      "rho.1.bias tensor([ 0.3610, -0.3579])\n",
      "train_vars.0 tensor(1.6389)\n",
      "train_vars.1 tensor(2.3259)\n",
      "train_vars.2 tensor(1.7596)\n",
      "train_vars.3 tensor(2.2812)\n",
      "train_vars.4 tensor(1.5237)\n",
      "train_vars.5 tensor(2.4435)\n",
      "train_vars.6 tensor(1.9531)\n",
      "train_vars.7 tensor(2.1126)\n",
      "=====================================\n",
      "[9,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3847,  0.3446,  0.3662,  ..., -0.4996, -0.4751, -0.4873],\n",
      "        [-0.3915, -0.3469, -0.3497,  ...,  0.4849,  0.5158,  0.4923]])\n",
      "rho.1.bias tensor([ 0.3604, -0.3573])\n",
      "train_vars.0 tensor(1.6386)\n",
      "train_vars.1 tensor(2.3263)\n",
      "train_vars.2 tensor(1.7602)\n",
      "train_vars.3 tensor(2.2807)\n",
      "train_vars.4 tensor(1.5233)\n",
      "train_vars.5 tensor(2.4439)\n",
      "train_vars.6 tensor(1.9541)\n",
      "train_vars.7 tensor(2.1117)\n",
      "=====================================\n",
      "[9,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3846,  0.3445,  0.3661,  ..., -0.5002, -0.4757, -0.4879],\n",
      "        [-0.3914, -0.3469, -0.3496,  ...,  0.4856,  0.5164,  0.4929]])\n",
      "rho.1.bias tensor([ 0.3599, -0.3568])\n",
      "train_vars.0 tensor(1.6385)\n",
      "train_vars.1 tensor(2.3264)\n",
      "train_vars.2 tensor(1.7603)\n",
      "train_vars.3 tensor(2.2807)\n",
      "train_vars.4 tensor(1.5231)\n",
      "train_vars.5 tensor(2.4442)\n",
      "train_vars.6 tensor(1.9549)\n",
      "train_vars.7 tensor(2.1109)\n",
      "=====================================\n",
      "[9,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3843,  0.3442,  0.3658,  ..., -0.5002, -0.4758, -0.4880],\n",
      "        [-0.3911, -0.3465, -0.3493,  ...,  0.4856,  0.5165,  0.4930]])\n",
      "rho.1.bias tensor([ 0.3591, -0.3560])\n",
      "train_vars.0 tensor(1.6379)\n",
      "train_vars.1 tensor(2.3270)\n",
      "train_vars.2 tensor(1.7607)\n",
      "train_vars.3 tensor(2.2803)\n",
      "train_vars.4 tensor(1.5235)\n",
      "train_vars.5 tensor(2.4438)\n",
      "train_vars.6 tensor(1.9550)\n",
      "train_vars.7 tensor(2.1110)\n",
      "=====================================\n",
      "[10,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3844,  0.3442,  0.3659,  ..., -0.5002, -0.4757, -0.4880],\n",
      "        [-0.3911, -0.3466, -0.3493,  ...,  0.4856,  0.5164,  0.4929]])\n",
      "rho.1.bias tensor([ 0.3589, -0.3558])\n",
      "train_vars.0 tensor(1.6380)\n",
      "train_vars.1 tensor(2.3269)\n",
      "train_vars.2 tensor(1.7604)\n",
      "train_vars.3 tensor(2.2808)\n",
      "train_vars.4 tensor(1.5242)\n",
      "train_vars.5 tensor(2.4431)\n",
      "train_vars.6 tensor(1.9549)\n",
      "train_vars.7 tensor(2.1113)\n",
      "=====================================\n",
      "[10,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3852,  0.3451,  0.3667,  ..., -0.4992, -0.4748, -0.4870],\n",
      "        [-0.3919, -0.3474, -0.3502,  ...,  0.4846,  0.5155,  0.4920]])\n",
      "rho.1.bias tensor([ 0.3595, -0.3564])\n",
      "train_vars.0 tensor(1.6392)\n",
      "train_vars.1 tensor(2.3257)\n",
      "train_vars.2 tensor(1.7590)\n",
      "train_vars.3 tensor(2.2823)\n",
      "train_vars.4 tensor(1.5262)\n",
      "train_vars.5 tensor(2.4409)\n",
      "train_vars.6 tensor(1.9534)\n",
      "train_vars.7 tensor(2.1130)\n",
      "=====================================\n",
      "[10,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3845,  0.3444,  0.3660,  ..., -0.5002, -0.4758, -0.4880],\n",
      "        [-0.3913, -0.3468, -0.3495,  ...,  0.4856,  0.5165,  0.4930]])\n",
      "rho.1.bias tensor([ 0.3585, -0.3554])\n",
      "train_vars.0 tensor(1.6382)\n",
      "train_vars.1 tensor(2.3267)\n",
      "train_vars.2 tensor(1.7601)\n",
      "train_vars.3 tensor(2.2813)\n",
      "train_vars.4 tensor(1.5252)\n",
      "train_vars.5 tensor(2.4420)\n",
      "train_vars.6 tensor(1.9549)\n",
      "train_vars.7 tensor(2.1116)\n",
      "=====================================\n",
      "[10,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3843,  0.3442,  0.3658,  ..., -0.5009, -0.4765, -0.4887],\n",
      "        [-0.3911, -0.3465, -0.3493,  ...,  0.4863,  0.5172,  0.4937]])\n",
      "rho.1.bias tensor([ 0.3579, -0.3548])\n",
      "train_vars.0 tensor(1.6378)\n",
      "train_vars.1 tensor(2.3272)\n",
      "train_vars.2 tensor(1.7606)\n",
      "train_vars.3 tensor(2.2808)\n",
      "train_vars.4 tensor(1.5248)\n",
      "train_vars.5 tensor(2.4425)\n",
      "train_vars.6 tensor(1.9559)\n",
      "train_vars.7 tensor(2.1107)\n",
      "=====================================\n",
      "[10,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3842,  0.3441,  0.3658,  ..., -0.5015, -0.4771, -0.4893],\n",
      "        [-0.3910, -0.3465, -0.3492,  ...,  0.4869,  0.5178,  0.4943]])\n",
      "rho.1.bias tensor([ 0.3574, -0.3543])\n",
      "train_vars.0 tensor(1.6377)\n",
      "train_vars.1 tensor(2.3273)\n",
      "train_vars.2 tensor(1.7608)\n",
      "train_vars.3 tensor(2.2808)\n",
      "train_vars.4 tensor(1.5246)\n",
      "train_vars.5 tensor(2.4427)\n",
      "train_vars.6 tensor(1.9567)\n",
      "train_vars.7 tensor(2.1099)\n",
      "=====================================\n",
      "[10,     6] loss: 0.547\n",
      "rho.1.weight tensor([[ 0.3839,  0.3438,  0.3654,  ..., -0.5015, -0.4771, -0.4893],\n",
      "        [-0.3907, -0.3461, -0.3489,  ...,  0.4870,  0.5179,  0.4944]])\n",
      "rho.1.bias tensor([ 0.3566, -0.3535])\n",
      "train_vars.0 tensor(1.6372)\n",
      "train_vars.1 tensor(2.3278)\n",
      "train_vars.2 tensor(1.7611)\n",
      "train_vars.3 tensor(2.2805)\n",
      "train_vars.4 tensor(1.5250)\n",
      "train_vars.5 tensor(2.4423)\n",
      "train_vars.6 tensor(1.9568)\n",
      "train_vars.7 tensor(2.1100)\n",
      "=====================================\n",
      "[11,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3840,  0.3439,  0.3655,  ..., -0.5015, -0.4771, -0.4893],\n",
      "        [-0.3907, -0.3462, -0.3490,  ...,  0.4869,  0.5178,  0.4943]])\n",
      "rho.1.bias tensor([ 0.3564, -0.3533])\n",
      "train_vars.0 tensor(1.6373)\n",
      "train_vars.1 tensor(2.3278)\n",
      "train_vars.2 tensor(1.7608)\n",
      "train_vars.3 tensor(2.2809)\n",
      "train_vars.4 tensor(1.5257)\n",
      "train_vars.5 tensor(2.4416)\n",
      "train_vars.6 tensor(1.9567)\n",
      "train_vars.7 tensor(2.1102)\n",
      "=====================================\n",
      "[11,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3848,  0.3447,  0.3663,  ..., -0.5005, -0.4761, -0.4883],\n",
      "        [-0.3915, -0.3470, -0.3498,  ...,  0.4860,  0.5169,  0.4934]])\n",
      "rho.1.bias tensor([ 0.3570, -0.3539])\n",
      "train_vars.0 tensor(1.6385)\n",
      "train_vars.1 tensor(2.3266)\n",
      "train_vars.2 tensor(1.7594)\n",
      "train_vars.3 tensor(2.2825)\n",
      "train_vars.4 tensor(1.5277)\n",
      "train_vars.5 tensor(2.4394)\n",
      "train_vars.6 tensor(1.9552)\n",
      "train_vars.7 tensor(2.1119)\n",
      "=====================================\n",
      "[11,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3841,  0.3440,  0.3657,  ..., -0.5015, -0.4771, -0.4893],\n",
      "        [-0.3909, -0.3464, -0.3491,  ...,  0.4870,  0.5179,  0.4944]])\n",
      "rho.1.bias tensor([ 0.3559, -0.3529])\n",
      "train_vars.0 tensor(1.6375)\n",
      "train_vars.1 tensor(2.3276)\n",
      "train_vars.2 tensor(1.7605)\n",
      "train_vars.3 tensor(2.2815)\n",
      "train_vars.4 tensor(1.5267)\n",
      "train_vars.5 tensor(2.4405)\n",
      "train_vars.6 tensor(1.9567)\n",
      "train_vars.7 tensor(2.1105)\n",
      "=====================================\n",
      "[11,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3839,  0.3438,  0.3654,  ..., -0.5022, -0.4778, -0.4900],\n",
      "        [-0.3906, -0.3461, -0.3489,  ...,  0.4877,  0.5186,  0.4951]])\n",
      "rho.1.bias tensor([ 0.3553, -0.3522])\n",
      "train_vars.0 tensor(1.6371)\n",
      "train_vars.1 tensor(2.3281)\n",
      "train_vars.2 tensor(1.7610)\n",
      "train_vars.3 tensor(2.2810)\n",
      "train_vars.4 tensor(1.5263)\n",
      "train_vars.5 tensor(2.4410)\n",
      "train_vars.6 tensor(1.9577)\n",
      "train_vars.7 tensor(2.1096)\n",
      "=====================================\n",
      "[11,     5] loss: 0.562\n",
      "rho.1.weight tensor([[ 0.3838,  0.3437,  0.3654,  ..., -0.5028, -0.4784, -0.4907],\n",
      "        [-0.3906, -0.3460, -0.3488,  ...,  0.4883,  0.5192,  0.4957]])\n",
      "rho.1.bias tensor([ 0.3549, -0.3518])\n",
      "train_vars.0 tensor(1.6370)\n",
      "train_vars.1 tensor(2.3282)\n",
      "train_vars.2 tensor(1.7612)\n",
      "train_vars.3 tensor(2.2809)\n",
      "train_vars.4 tensor(1.5261)\n",
      "train_vars.5 tensor(2.4412)\n",
      "train_vars.6 tensor(1.9585)\n",
      "train_vars.7 tensor(2.1089)\n",
      "=====================================\n",
      "[11,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3835,  0.3434,  0.3650,  ..., -0.5028, -0.4784, -0.4907],\n",
      "        [-0.3902, -0.3457, -0.3485,  ...,  0.4883,  0.5192,  0.4958]])\n",
      "rho.1.bias tensor([ 0.3540, -0.3510])\n",
      "train_vars.0 tensor(1.6365)\n",
      "train_vars.1 tensor(2.3287)\n",
      "train_vars.2 tensor(1.7615)\n",
      "train_vars.3 tensor(2.2806)\n",
      "train_vars.4 tensor(1.5265)\n",
      "train_vars.5 tensor(2.4408)\n",
      "train_vars.6 tensor(1.9586)\n",
      "train_vars.7 tensor(2.1089)\n",
      "=====================================\n",
      "[12,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3836,  0.3434,  0.3651,  ..., -0.5028, -0.4784, -0.4907],\n",
      "        [-0.3903, -0.3458, -0.3485,  ...,  0.4883,  0.5192,  0.4957]])\n",
      "rho.1.bias tensor([ 0.3538, -0.3508])\n",
      "train_vars.0 tensor(1.6366)\n",
      "train_vars.1 tensor(2.3287)\n",
      "train_vars.2 tensor(1.7612)\n",
      "train_vars.3 tensor(2.2811)\n",
      "train_vars.4 tensor(1.5272)\n",
      "train_vars.5 tensor(2.4401)\n",
      "train_vars.6 tensor(1.9585)\n",
      "train_vars.7 tensor(2.1092)\n",
      "=====================================\n",
      "[12,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3844,  0.3442,  0.3659,  ..., -0.5018, -0.4774, -0.4897],\n",
      "        [-0.3911, -0.3466, -0.3493,  ...,  0.4873,  0.5182,  0.4948]])\n",
      "rho.1.bias tensor([ 0.3544, -0.3514])\n",
      "train_vars.0 tensor(1.6378)\n",
      "train_vars.1 tensor(2.3275)\n",
      "train_vars.2 tensor(1.7598)\n",
      "train_vars.3 tensor(2.2826)\n",
      "train_vars.4 tensor(1.5292)\n",
      "train_vars.5 tensor(2.4379)\n",
      "train_vars.6 tensor(1.9570)\n",
      "train_vars.7 tensor(2.1109)\n",
      "=====================================\n",
      "[12,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3837,  0.3436,  0.3652,  ..., -0.5028, -0.4784, -0.4907],\n",
      "        [-0.3905, -0.3459, -0.3487,  ...,  0.4883,  0.5192,  0.4958]])\n",
      "rho.1.bias tensor([ 0.3534, -0.3504])\n",
      "train_vars.0 tensor(1.6368)\n",
      "train_vars.1 tensor(2.3285)\n",
      "train_vars.2 tensor(1.7609)\n",
      "train_vars.3 tensor(2.2816)\n",
      "train_vars.4 tensor(1.5282)\n",
      "train_vars.5 tensor(2.4390)\n",
      "train_vars.6 tensor(1.9585)\n",
      "train_vars.7 tensor(2.1095)\n",
      "=====================================\n",
      "[12,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3835,  0.3434,  0.3650,  ..., -0.5035, -0.4791, -0.4914],\n",
      "        [-0.3902, -0.3457, -0.3484,  ...,  0.4890,  0.5199,  0.4965]])\n",
      "rho.1.bias tensor([ 0.3528, -0.3497])\n",
      "train_vars.0 tensor(1.6364)\n",
      "train_vars.1 tensor(2.3290)\n",
      "train_vars.2 tensor(1.7614)\n",
      "train_vars.3 tensor(2.2811)\n",
      "train_vars.4 tensor(1.5277)\n",
      "train_vars.5 tensor(2.4395)\n",
      "train_vars.6 tensor(1.9595)\n",
      "train_vars.7 tensor(2.1086)\n",
      "=====================================\n",
      "[12,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3834,  0.3433,  0.3649,  ..., -0.5041, -0.4797, -0.4920],\n",
      "        [-0.3901, -0.3456, -0.3484,  ...,  0.4896,  0.5206,  0.4971]])\n",
      "rho.1.bias tensor([ 0.3523, -0.3493])\n",
      "train_vars.0 tensor(1.6362)\n",
      "train_vars.1 tensor(2.3291)\n",
      "train_vars.2 tensor(1.7616)\n",
      "train_vars.3 tensor(2.2811)\n",
      "train_vars.4 tensor(1.5275)\n",
      "train_vars.5 tensor(2.4397)\n",
      "train_vars.6 tensor(1.9603)\n",
      "train_vars.7 tensor(2.1078)\n",
      "=====================================\n",
      "[12,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3831,  0.3430,  0.3646,  ..., -0.5041, -0.4798, -0.4920],\n",
      "        [-0.3898, -0.3453, -0.3480,  ...,  0.4897,  0.5206,  0.4972]])\n",
      "rho.1.bias tensor([ 0.3515, -0.3485])\n",
      "train_vars.0 tensor(1.6357)\n",
      "train_vars.1 tensor(2.3296)\n",
      "train_vars.2 tensor(1.7619)\n",
      "train_vars.3 tensor(2.2808)\n",
      "train_vars.4 tensor(1.5279)\n",
      "train_vars.5 tensor(2.4393)\n",
      "train_vars.6 tensor(1.9604)\n",
      "train_vars.7 tensor(2.1079)\n",
      "=====================================\n",
      "[13,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3831,  0.3430,  0.3647,  ..., -0.5041, -0.4797, -0.4920],\n",
      "        [-0.3899, -0.3454, -0.3481,  ...,  0.4896,  0.5205,  0.4971]])\n",
      "rho.1.bias tensor([ 0.3513, -0.3483])\n",
      "train_vars.0 tensor(1.6358)\n",
      "train_vars.1 tensor(2.3296)\n",
      "train_vars.2 tensor(1.7616)\n",
      "train_vars.3 tensor(2.2812)\n",
      "train_vars.4 tensor(1.5286)\n",
      "train_vars.5 tensor(2.4386)\n",
      "train_vars.6 tensor(1.9603)\n",
      "train_vars.7 tensor(2.1082)\n",
      "=====================================\n",
      "[13,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3839,  0.3438,  0.3655,  ..., -0.5031, -0.4788, -0.4910],\n",
      "        [-0.3907, -0.3462, -0.3489,  ...,  0.4886,  0.5196,  0.4962]])\n",
      "rho.1.bias tensor([ 0.3519, -0.3489])\n",
      "train_vars.0 tensor(1.6370)\n",
      "train_vars.1 tensor(2.3284)\n",
      "train_vars.2 tensor(1.7602)\n",
      "train_vars.3 tensor(2.2828)\n",
      "train_vars.4 tensor(1.5307)\n",
      "train_vars.5 tensor(2.4364)\n",
      "train_vars.6 tensor(1.9588)\n",
      "train_vars.7 tensor(2.1099)\n",
      "=====================================\n",
      "[13,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3833,  0.3432,  0.3648,  ..., -0.5041, -0.4798, -0.4920],\n",
      "        [-0.3900, -0.3455, -0.3483,  ...,  0.4897,  0.5206,  0.4972]])\n",
      "rho.1.bias tensor([ 0.3508, -0.3479])\n",
      "train_vars.0 tensor(1.6360)\n",
      "train_vars.1 tensor(2.3294)\n",
      "train_vars.2 tensor(1.7613)\n",
      "train_vars.3 tensor(2.2818)\n",
      "train_vars.4 tensor(1.5296)\n",
      "train_vars.5 tensor(2.4375)\n",
      "train_vars.6 tensor(1.9602)\n",
      "train_vars.7 tensor(2.1085)\n",
      "=====================================\n",
      "[13,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3830,  0.3429,  0.3646,  ..., -0.5048, -0.4804, -0.4927],\n",
      "        [-0.3898, -0.3452, -0.3480,  ...,  0.4904,  0.5213,  0.4979]])\n",
      "rho.1.bias tensor([ 0.3502, -0.3472])\n",
      "train_vars.0 tensor(1.6356)\n",
      "train_vars.1 tensor(2.3299)\n",
      "train_vars.2 tensor(1.7618)\n",
      "train_vars.3 tensor(2.2813)\n",
      "train_vars.4 tensor(1.5292)\n",
      "train_vars.5 tensor(2.4380)\n",
      "train_vars.6 tensor(1.9612)\n",
      "train_vars.7 tensor(2.1076)\n",
      "=====================================\n",
      "[13,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3830,  0.3429,  0.3645,  ..., -0.5054, -0.4811, -0.4934],\n",
      "        [-0.3897, -0.3452, -0.3479,  ...,  0.4910,  0.5219,  0.4985]])\n",
      "rho.1.bias tensor([ 0.3498, -0.3468])\n",
      "train_vars.0 tensor(1.6355)\n",
      "train_vars.1 tensor(2.3300)\n",
      "train_vars.2 tensor(1.7620)\n",
      "train_vars.3 tensor(2.2812)\n",
      "train_vars.4 tensor(1.5290)\n",
      "train_vars.5 tensor(2.4383)\n",
      "train_vars.6 tensor(1.9621)\n",
      "train_vars.7 tensor(2.1068)\n",
      "=====================================\n",
      "[13,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3827,  0.3425,  0.3642,  ..., -0.5054, -0.4811, -0.4934],\n",
      "        [-0.3894, -0.3448, -0.3476,  ...,  0.4910,  0.5220,  0.4985]])\n",
      "rho.1.bias tensor([ 0.3489, -0.3459])\n",
      "train_vars.0 tensor(1.6350)\n",
      "train_vars.1 tensor(2.3306)\n",
      "train_vars.2 tensor(1.7623)\n",
      "train_vars.3 tensor(2.2809)\n",
      "train_vars.4 tensor(1.5294)\n",
      "train_vars.5 tensor(2.4379)\n",
      "train_vars.6 tensor(1.9621)\n",
      "train_vars.7 tensor(2.1069)\n",
      "=====================================\n",
      "[14,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3827,  0.3426,  0.3642,  ..., -0.5054, -0.4810, -0.4933],\n",
      "        [-0.3894, -0.3449, -0.3477,  ...,  0.4909,  0.5219,  0.4985]])\n",
      "rho.1.bias tensor([ 0.3487, -0.3458])\n",
      "train_vars.0 tensor(1.6350)\n",
      "train_vars.1 tensor(2.3305)\n",
      "train_vars.2 tensor(1.7620)\n",
      "train_vars.3 tensor(2.2814)\n",
      "train_vars.4 tensor(1.5301)\n",
      "train_vars.5 tensor(2.4371)\n",
      "train_vars.6 tensor(1.9620)\n",
      "train_vars.7 tensor(2.1072)\n",
      "=====================================\n",
      "[14,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3835,  0.3434,  0.3650,  ..., -0.5044, -0.4801, -0.4924],\n",
      "        [-0.3902, -0.3457, -0.3485,  ...,  0.4900,  0.5210,  0.4975]])\n",
      "rho.1.bias tensor([ 0.3493, -0.3464])\n",
      "train_vars.0 tensor(1.6362)\n",
      "train_vars.1 tensor(2.3293)\n",
      "train_vars.2 tensor(1.7606)\n",
      "train_vars.3 tensor(2.2829)\n",
      "train_vars.4 tensor(1.5321)\n",
      "train_vars.5 tensor(2.4350)\n",
      "train_vars.6 tensor(1.9606)\n",
      "train_vars.7 tensor(2.1089)\n",
      "=====================================\n",
      "[14,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3829,  0.3427,  0.3644,  ..., -0.5054, -0.4811, -0.4934],\n",
      "        [-0.3896, -0.3451, -0.3478,  ...,  0.4910,  0.5220,  0.4986]])\n",
      "rho.1.bias tensor([ 0.3483, -0.3453])\n",
      "train_vars.0 tensor(1.6352)\n",
      "train_vars.1 tensor(2.3304)\n",
      "train_vars.2 tensor(1.7616)\n",
      "train_vars.3 tensor(2.2819)\n",
      "train_vars.4 tensor(1.5311)\n",
      "train_vars.5 tensor(2.4361)\n",
      "train_vars.6 tensor(1.9620)\n",
      "train_vars.7 tensor(2.1075)\n",
      "=====================================\n",
      "[14,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3826,  0.3425,  0.3641,  ..., -0.5061, -0.4818, -0.4941],\n",
      "        [-0.3893, -0.3448, -0.3476,  ...,  0.4917,  0.5227,  0.4993]])\n",
      "rho.1.bias tensor([ 0.3477, -0.3447])\n",
      "train_vars.0 tensor(1.6348)\n",
      "train_vars.1 tensor(2.3308)\n",
      "train_vars.2 tensor(1.7622)\n",
      "train_vars.3 tensor(2.2814)\n",
      "train_vars.4 tensor(1.5306)\n",
      "train_vars.5 tensor(2.4366)\n",
      "train_vars.6 tensor(1.9630)\n",
      "train_vars.7 tensor(2.1066)\n",
      "=====================================\n",
      "[14,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3825,  0.3424,  0.3641,  ..., -0.5067, -0.4824, -0.4947],\n",
      "        [-0.3892, -0.3447, -0.3475,  ...,  0.4923,  0.5233,  0.4999]])\n",
      "rho.1.bias tensor([ 0.3472, -0.3442])\n",
      "train_vars.0 tensor(1.6347)\n",
      "train_vars.1 tensor(2.3310)\n",
      "train_vars.2 tensor(1.7623)\n",
      "train_vars.3 tensor(2.2814)\n",
      "train_vars.4 tensor(1.5304)\n",
      "train_vars.5 tensor(2.4368)\n",
      "train_vars.6 tensor(1.9639)\n",
      "train_vars.7 tensor(2.1058)\n",
      "=====================================\n",
      "[14,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3822,  0.3421,  0.3637,  ..., -0.5067, -0.4824, -0.4947],\n",
      "        [-0.3889, -0.3444, -0.3472,  ...,  0.4923,  0.5233,  0.4999]])\n",
      "rho.1.bias tensor([ 0.3464, -0.3434])\n",
      "train_vars.0 tensor(1.6342)\n",
      "train_vars.1 tensor(2.3315)\n",
      "train_vars.2 tensor(1.7627)\n",
      "train_vars.3 tensor(2.2811)\n",
      "train_vars.4 tensor(1.5308)\n",
      "train_vars.5 tensor(2.4364)\n",
      "train_vars.6 tensor(1.9639)\n",
      "train_vars.7 tensor(2.1059)\n",
      "=====================================\n",
      "[15,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3823,  0.3422,  0.3638,  ..., -0.5067, -0.4823, -0.4947],\n",
      "        [-0.3890, -0.3445, -0.3472,  ...,  0.4923,  0.5233,  0.4999]])\n",
      "rho.1.bias tensor([ 0.3462, -0.3432])\n",
      "train_vars.0 tensor(1.6342)\n",
      "train_vars.1 tensor(2.3314)\n",
      "train_vars.2 tensor(1.7623)\n",
      "train_vars.3 tensor(2.2816)\n",
      "train_vars.4 tensor(1.5315)\n",
      "train_vars.5 tensor(2.4357)\n",
      "train_vars.6 tensor(1.9638)\n",
      "train_vars.7 tensor(2.1062)\n",
      "=====================================\n",
      "[15,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3830,  0.3429,  0.3646,  ..., -0.5057, -0.4814, -0.4937],\n",
      "        [-0.3898, -0.3452, -0.3480,  ...,  0.4913,  0.5223,  0.4989]])\n",
      "rho.1.bias tensor([ 0.3468, -0.3439])\n",
      "train_vars.0 tensor(1.6354)\n",
      "train_vars.1 tensor(2.3303)\n",
      "train_vars.2 tensor(1.7610)\n",
      "train_vars.3 tensor(2.2831)\n",
      "train_vars.4 tensor(1.5336)\n",
      "train_vars.5 tensor(2.4335)\n",
      "train_vars.6 tensor(1.9623)\n",
      "train_vars.7 tensor(2.1079)\n",
      "=====================================\n",
      "[15,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3824,  0.3423,  0.3639,  ..., -0.5067, -0.4824, -0.4947],\n",
      "        [-0.3891, -0.3446, -0.3474,  ...,  0.4923,  0.5233,  0.4999]])\n",
      "rho.1.bias tensor([ 0.3457, -0.3428])\n",
      "train_vars.0 tensor(1.6344)\n",
      "train_vars.1 tensor(2.3313)\n",
      "train_vars.2 tensor(1.7620)\n",
      "train_vars.3 tensor(2.2821)\n",
      "train_vars.4 tensor(1.5325)\n",
      "train_vars.5 tensor(2.4347)\n",
      "train_vars.6 tensor(1.9638)\n",
      "train_vars.7 tensor(2.1065)\n",
      "=====================================\n",
      "[15,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3821,  0.3420,  0.3637,  ..., -0.5074, -0.4831, -0.4954],\n",
      "        [-0.3888, -0.3443, -0.3471,  ...,  0.4930,  0.5240,  0.5007]])\n",
      "rho.1.bias tensor([ 0.3451, -0.3422])\n",
      "train_vars.0 tensor(1.6340)\n",
      "train_vars.1 tensor(2.3318)\n",
      "train_vars.2 tensor(1.7626)\n",
      "train_vars.3 tensor(2.2816)\n",
      "train_vars.4 tensor(1.5321)\n",
      "train_vars.5 tensor(2.4352)\n",
      "train_vars.6 tensor(1.9648)\n",
      "train_vars.7 tensor(2.1056)\n",
      "=====================================\n",
      "[15,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3821,  0.3420,  0.3636,  ..., -0.5080, -0.4837, -0.4960],\n",
      "        [-0.3888, -0.3443, -0.3470,  ...,  0.4937,  0.5247,  0.5013]])\n",
      "rho.1.bias tensor([ 0.3446, -0.3417])\n",
      "train_vars.0 tensor(1.6339)\n",
      "train_vars.1 tensor(2.3319)\n",
      "train_vars.2 tensor(1.7627)\n",
      "train_vars.3 tensor(2.2816)\n",
      "train_vars.4 tensor(1.5319)\n",
      "train_vars.5 tensor(2.4354)\n",
      "train_vars.6 tensor(1.9656)\n",
      "train_vars.7 tensor(2.1048)\n",
      "=====================================\n",
      "[15,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3817,  0.3416,  0.3633,  ..., -0.5080, -0.4837, -0.4961],\n",
      "        [-0.3884, -0.3439, -0.3467,  ...,  0.4937,  0.5247,  0.5013]])\n",
      "rho.1.bias tensor([ 0.3438, -0.3409])\n",
      "train_vars.0 tensor(1.6334)\n",
      "train_vars.1 tensor(2.3324)\n",
      "train_vars.2 tensor(1.7631)\n",
      "train_vars.3 tensor(2.2813)\n",
      "train_vars.4 tensor(1.5323)\n",
      "train_vars.5 tensor(2.4350)\n",
      "train_vars.6 tensor(1.9656)\n",
      "train_vars.7 tensor(2.1049)\n",
      "=====================================\n",
      "[16,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3818,  0.3417,  0.3634,  ..., -0.5080, -0.4837, -0.4960],\n",
      "        [-0.3885, -0.3440, -0.3468,  ...,  0.4936,  0.5246,  0.5012]])\n",
      "rho.1.bias tensor([ 0.3436, -0.3407])\n",
      "train_vars.0 tensor(1.6334)\n",
      "train_vars.1 tensor(2.3324)\n",
      "train_vars.2 tensor(1.7627)\n",
      "train_vars.3 tensor(2.2818)\n",
      "train_vars.4 tensor(1.5330)\n",
      "train_vars.5 tensor(2.4342)\n",
      "train_vars.6 tensor(1.9655)\n",
      "train_vars.7 tensor(2.1052)\n",
      "=====================================\n",
      "[16,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3826,  0.3425,  0.3641,  ..., -0.5070, -0.4827, -0.4950],\n",
      "        [-0.3893, -0.3448, -0.3476,  ...,  0.4927,  0.5237,  0.5003]])\n",
      "rho.1.bias tensor([ 0.3442, -0.3414])\n",
      "train_vars.0 tensor(1.6346)\n",
      "train_vars.1 tensor(2.3313)\n",
      "train_vars.2 tensor(1.7613)\n",
      "train_vars.3 tensor(2.2833)\n",
      "train_vars.4 tensor(1.5350)\n",
      "train_vars.5 tensor(2.4321)\n",
      "train_vars.6 tensor(1.9641)\n",
      "train_vars.7 tensor(2.1069)\n",
      "=====================================\n",
      "[16,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3819,  0.3418,  0.3635,  ..., -0.5080, -0.4837, -0.4961],\n",
      "        [-0.3886, -0.3441, -0.3469,  ...,  0.4937,  0.5247,  0.5013]])\n",
      "rho.1.bias tensor([ 0.3432, -0.3403])\n",
      "train_vars.0 tensor(1.6336)\n",
      "train_vars.1 tensor(2.3323)\n",
      "train_vars.2 tensor(1.7624)\n",
      "train_vars.3 tensor(2.2823)\n",
      "train_vars.4 tensor(1.5340)\n",
      "train_vars.5 tensor(2.4332)\n",
      "train_vars.6 tensor(1.9655)\n",
      "train_vars.7 tensor(2.1055)\n",
      "=====================================\n",
      "[16,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3817,  0.3416,  0.3632,  ..., -0.5087, -0.4844, -0.4968],\n",
      "        [-0.3884, -0.3438, -0.3466,  ...,  0.4944,  0.5254,  0.5020]])\n",
      "rho.1.bias tensor([ 0.3425, -0.3397])\n",
      "train_vars.0 tensor(1.6332)\n",
      "train_vars.1 tensor(2.3327)\n",
      "train_vars.2 tensor(1.7629)\n",
      "train_vars.3 tensor(2.2818)\n",
      "train_vars.4 tensor(1.5335)\n",
      "train_vars.5 tensor(2.4337)\n",
      "train_vars.6 tensor(1.9665)\n",
      "train_vars.7 tensor(2.1046)\n",
      "=====================================\n",
      "[16,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3816,  0.3415,  0.3632,  ..., -0.5093, -0.4850, -0.4974],\n",
      "        [-0.3883, -0.3438, -0.3466,  ...,  0.4950,  0.5260,  0.5027]])\n",
      "rho.1.bias tensor([ 0.3421, -0.3392])\n",
      "train_vars.0 tensor(1.6330)\n",
      "train_vars.1 tensor(2.3329)\n",
      "train_vars.2 tensor(1.7631)\n",
      "train_vars.3 tensor(2.2818)\n",
      "train_vars.4 tensor(1.5333)\n",
      "train_vars.5 tensor(2.4340)\n",
      "train_vars.6 tensor(1.9674)\n",
      "train_vars.7 tensor(2.1038)\n",
      "=====================================\n",
      "[16,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3813,  0.3412,  0.3628,  ..., -0.5093, -0.4850, -0.4974],\n",
      "        [-0.3880, -0.3435, -0.3462,  ...,  0.4950,  0.5260,  0.5027]])\n",
      "rho.1.bias tensor([ 0.3412, -0.3384])\n",
      "train_vars.0 tensor(1.6325)\n",
      "train_vars.1 tensor(2.3334)\n",
      "train_vars.2 tensor(1.7634)\n",
      "train_vars.3 tensor(2.2815)\n",
      "train_vars.4 tensor(1.5337)\n",
      "train_vars.5 tensor(2.4335)\n",
      "train_vars.6 tensor(1.9674)\n",
      "train_vars.7 tensor(2.1039)\n",
      "=====================================\n",
      "[17,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3813,  0.3412,  0.3629,  ..., -0.5092, -0.4850, -0.4973],\n",
      "        [-0.3880, -0.3435, -0.3463,  ...,  0.4949,  0.5260,  0.5026]])\n",
      "rho.1.bias tensor([ 0.3410, -0.3382])\n",
      "train_vars.0 tensor(1.6326)\n",
      "train_vars.1 tensor(2.3334)\n",
      "train_vars.2 tensor(1.7630)\n",
      "train_vars.3 tensor(2.2820)\n",
      "train_vars.4 tensor(1.5344)\n",
      "train_vars.5 tensor(2.4328)\n",
      "train_vars.6 tensor(1.9672)\n",
      "train_vars.7 tensor(2.1042)\n",
      "=====================================\n",
      "[17,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3821,  0.3420,  0.3637,  ..., -0.5083, -0.4840, -0.4964],\n",
      "        [-0.3888, -0.3443, -0.3471,  ...,  0.4940,  0.5250,  0.5017]])\n",
      "rho.1.bias tensor([ 0.3417, -0.3388])\n",
      "train_vars.0 tensor(1.6338)\n",
      "train_vars.1 tensor(2.3322)\n",
      "train_vars.2 tensor(1.7617)\n",
      "train_vars.3 tensor(2.2835)\n",
      "train_vars.4 tensor(1.5364)\n",
      "train_vars.5 tensor(2.4307)\n",
      "train_vars.6 tensor(1.9658)\n",
      "train_vars.7 tensor(2.1059)\n",
      "=====================================\n",
      "[17,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3815,  0.3414,  0.3630,  ..., -0.5093, -0.4850, -0.4974],\n",
      "        [-0.3881, -0.3436, -0.3464,  ...,  0.4950,  0.5260,  0.5027]])\n",
      "rho.1.bias tensor([ 0.3406, -0.3378])\n",
      "train_vars.0 tensor(1.6327)\n",
      "train_vars.1 tensor(2.3333)\n",
      "train_vars.2 tensor(1.7627)\n",
      "train_vars.3 tensor(2.2825)\n",
      "train_vars.4 tensor(1.5354)\n",
      "train_vars.5 tensor(2.4318)\n",
      "train_vars.6 tensor(1.9672)\n",
      "train_vars.7 tensor(2.1045)\n",
      "=====================================\n",
      "[17,     4] loss: 0.481\n",
      "rho.1.weight tensor([[ 0.3812,  0.3411,  0.3628,  ..., -0.5100, -0.4857, -0.4981],\n",
      "        [-0.3879, -0.3434, -0.3461,  ...,  0.4957,  0.5268,  0.5034]])\n",
      "rho.1.bias tensor([ 0.3400, -0.3371])\n",
      "train_vars.0 tensor(1.6323)\n",
      "train_vars.1 tensor(2.3337)\n",
      "train_vars.2 tensor(1.7633)\n",
      "train_vars.3 tensor(2.2820)\n",
      "train_vars.4 tensor(1.5349)\n",
      "train_vars.5 tensor(2.4323)\n",
      "train_vars.6 tensor(1.9682)\n",
      "train_vars.7 tensor(2.1036)\n",
      "=====================================\n",
      "[17,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3811,  0.3410,  0.3627,  ..., -0.5106, -0.4863, -0.4987],\n",
      "        [-0.3878, -0.3433, -0.3461,  ...,  0.4963,  0.5274,  0.5040]])\n",
      "rho.1.bias tensor([ 0.3395, -0.3367])\n",
      "train_vars.0 tensor(1.6322)\n",
      "train_vars.1 tensor(2.3339)\n",
      "train_vars.2 tensor(1.7634)\n",
      "train_vars.3 tensor(2.2820)\n",
      "train_vars.4 tensor(1.5347)\n",
      "train_vars.5 tensor(2.4326)\n",
      "train_vars.6 tensor(1.9691)\n",
      "train_vars.7 tensor(2.1028)\n",
      "=====================================\n",
      "[17,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3808,  0.3407,  0.3624,  ..., -0.5106, -0.4863, -0.4987],\n",
      "        [-0.3875, -0.3430, -0.3457,  ...,  0.4963,  0.5274,  0.5040]])\n",
      "rho.1.bias tensor([ 0.3387, -0.3359])\n",
      "train_vars.0 tensor(1.6317)\n",
      "train_vars.1 tensor(2.3344)\n",
      "train_vars.2 tensor(1.7637)\n",
      "train_vars.3 tensor(2.2817)\n",
      "train_vars.4 tensor(1.5351)\n",
      "train_vars.5 tensor(2.4321)\n",
      "train_vars.6 tensor(1.9691)\n",
      "train_vars.7 tensor(2.1030)\n",
      "=====================================\n",
      "[18,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3808,  0.3408,  0.3624,  ..., -0.5105, -0.4862, -0.4986],\n",
      "        [-0.3875, -0.3430, -0.3458,  ...,  0.4963,  0.5273,  0.5040]])\n",
      "rho.1.bias tensor([ 0.3385, -0.3357])\n",
      "train_vars.0 tensor(1.6318)\n",
      "train_vars.1 tensor(2.3344)\n",
      "train_vars.2 tensor(1.7634)\n",
      "train_vars.3 tensor(2.2822)\n",
      "train_vars.4 tensor(1.5358)\n",
      "train_vars.5 tensor(2.4314)\n",
      "train_vars.6 tensor(1.9690)\n",
      "train_vars.7 tensor(2.1032)\n",
      "=====================================\n",
      "[18,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3816,  0.3415,  0.3632,  ..., -0.5095, -0.4853, -0.4977],\n",
      "        [-0.3883, -0.3438, -0.3466,  ...,  0.4953,  0.5264,  0.5030]])\n",
      "rho.1.bias tensor([ 0.3391, -0.3363])\n",
      "train_vars.0 tensor(1.6329)\n",
      "train_vars.1 tensor(2.3332)\n",
      "train_vars.2 tensor(1.7620)\n",
      "train_vars.3 tensor(2.2837)\n",
      "train_vars.4 tensor(1.5378)\n",
      "train_vars.5 tensor(2.4293)\n",
      "train_vars.6 tensor(1.9675)\n",
      "train_vars.7 tensor(2.1049)\n",
      "=====================================\n",
      "[18,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3810,  0.3409,  0.3625,  ..., -0.5105, -0.4863, -0.4987],\n",
      "        [-0.3876, -0.3431, -0.3459,  ...,  0.4963,  0.5274,  0.5041]])\n",
      "rho.1.bias tensor([ 0.3380, -0.3353])\n",
      "train_vars.0 tensor(1.6319)\n",
      "train_vars.1 tensor(2.3343)\n",
      "train_vars.2 tensor(1.7631)\n",
      "train_vars.3 tensor(2.2827)\n",
      "train_vars.4 tensor(1.5368)\n",
      "train_vars.5 tensor(2.4304)\n",
      "train_vars.6 tensor(1.9690)\n",
      "train_vars.7 tensor(2.1035)\n",
      "=====================================\n",
      "[18,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3807,  0.3406,  0.3623,  ..., -0.5112, -0.4870, -0.4994],\n",
      "        [-0.3874, -0.3429, -0.3456,  ...,  0.4970,  0.5281,  0.5048]])\n",
      "rho.1.bias tensor([ 0.3374, -0.3346])\n",
      "train_vars.0 tensor(1.6315)\n",
      "train_vars.1 tensor(2.3347)\n",
      "train_vars.2 tensor(1.7636)\n",
      "train_vars.3 tensor(2.2822)\n",
      "train_vars.4 tensor(1.5363)\n",
      "train_vars.5 tensor(2.4309)\n",
      "train_vars.6 tensor(1.9700)\n",
      "train_vars.7 tensor(2.1026)\n",
      "=====================================\n",
      "[18,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3806,  0.3405,  0.3622,  ..., -0.5118, -0.4876, -0.5000],\n",
      "        [-0.3873, -0.3428, -0.3456,  ...,  0.4976,  0.5287,  0.5054]])\n",
      "rho.1.bias tensor([ 0.3369, -0.3341])\n",
      "train_vars.0 tensor(1.6313)\n",
      "train_vars.1 tensor(2.3349)\n",
      "train_vars.2 tensor(1.7637)\n",
      "train_vars.3 tensor(2.2822)\n",
      "train_vars.4 tensor(1.5361)\n",
      "train_vars.5 tensor(2.4312)\n",
      "train_vars.6 tensor(1.9708)\n",
      "train_vars.7 tensor(2.1019)\n",
      "=====================================\n",
      "[18,     6] loss: 0.546\n",
      "rho.1.weight tensor([[ 0.3803,  0.3402,  0.3619,  ..., -0.5118, -0.4876, -0.5000],\n",
      "        [-0.3870, -0.3425, -0.3453,  ...,  0.4976,  0.5287,  0.5054]])\n",
      "rho.1.bias tensor([ 0.3361, -0.3333])\n",
      "train_vars.0 tensor(1.6308)\n",
      "train_vars.1 tensor(2.3354)\n",
      "train_vars.2 tensor(1.7641)\n",
      "train_vars.3 tensor(2.2819)\n",
      "train_vars.4 tensor(1.5365)\n",
      "train_vars.5 tensor(2.4307)\n",
      "train_vars.6 tensor(1.9708)\n",
      "train_vars.7 tensor(2.1020)\n",
      "=====================================\n",
      "[19,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3804,  0.3403,  0.3619,  ..., -0.5118, -0.4875, -0.5000],\n",
      "        [-0.3870, -0.3425, -0.3453,  ...,  0.4976,  0.5286,  0.5053]])\n",
      "rho.1.bias tensor([ 0.3359, -0.3332])\n",
      "train_vars.0 tensor(1.6309)\n",
      "train_vars.1 tensor(2.3354)\n",
      "train_vars.2 tensor(1.7637)\n",
      "train_vars.3 tensor(2.2824)\n",
      "train_vars.4 tensor(1.5372)\n",
      "train_vars.5 tensor(2.4300)\n",
      "train_vars.6 tensor(1.9707)\n",
      "train_vars.7 tensor(2.1023)\n",
      "=====================================\n",
      "[19,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3811,  0.3410,  0.3627,  ..., -0.5108, -0.4866, -0.4990],\n",
      "        [-0.3878, -0.3433, -0.3461,  ...,  0.4966,  0.5277,  0.5044]])\n",
      "rho.1.bias tensor([ 0.3365, -0.3338])\n",
      "train_vars.0 tensor(1.6320)\n",
      "train_vars.1 tensor(2.3342)\n",
      "train_vars.2 tensor(1.7623)\n",
      "train_vars.3 tensor(2.2839)\n",
      "train_vars.4 tensor(1.5392)\n",
      "train_vars.5 tensor(2.4279)\n",
      "train_vars.6 tensor(1.9692)\n",
      "train_vars.7 tensor(2.1040)\n",
      "=====================================\n",
      "[19,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3805,  0.3404,  0.3621,  ..., -0.5118, -0.4876, -0.5000],\n",
      "        [-0.3871, -0.3426, -0.3454,  ...,  0.4976,  0.5287,  0.5054]])\n",
      "rho.1.bias tensor([ 0.3355, -0.3327])\n",
      "train_vars.0 tensor(1.6310)\n",
      "train_vars.1 tensor(2.3353)\n",
      "train_vars.2 tensor(1.7634)\n",
      "train_vars.3 tensor(2.2829)\n",
      "train_vars.4 tensor(1.5382)\n",
      "train_vars.5 tensor(2.4290)\n",
      "train_vars.6 tensor(1.9707)\n",
      "train_vars.7 tensor(2.1026)\n",
      "=====================================\n",
      "[19,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3802,  0.3401,  0.3618,  ..., -0.5125, -0.4883, -0.5007],\n",
      "        [-0.3869, -0.3424, -0.3451,  ...,  0.4983,  0.5294,  0.5061]])\n",
      "rho.1.bias tensor([ 0.3348, -0.3321])\n",
      "train_vars.0 tensor(1.6306)\n",
      "train_vars.1 tensor(2.3357)\n",
      "train_vars.2 tensor(1.7639)\n",
      "train_vars.3 tensor(2.2824)\n",
      "train_vars.4 tensor(1.5377)\n",
      "train_vars.5 tensor(2.4295)\n",
      "train_vars.6 tensor(1.9717)\n",
      "train_vars.7 tensor(2.1017)\n",
      "=====================================\n",
      "[19,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3801,  0.3400,  0.3617,  ..., -0.5131, -0.4889, -0.5013],\n",
      "        [-0.3868, -0.3423, -0.3451,  ...,  0.4989,  0.5300,  0.5068]])\n",
      "rho.1.bias tensor([ 0.3344, -0.3316])\n",
      "train_vars.0 tensor(1.6305)\n",
      "train_vars.1 tensor(2.3359)\n",
      "train_vars.2 tensor(1.7641)\n",
      "train_vars.3 tensor(2.2824)\n",
      "train_vars.4 tensor(1.5375)\n",
      "train_vars.5 tensor(2.4298)\n",
      "train_vars.6 tensor(1.9725)\n",
      "train_vars.7 tensor(2.1009)\n",
      "=====================================\n",
      "[19,     6] loss: 0.545\n",
      "rho.1.weight tensor([[ 0.3798,  0.3397,  0.3614,  ..., -0.5131, -0.4889, -0.5013],\n",
      "        [-0.3865, -0.3420, -0.3447,  ...,  0.4990,  0.5301,  0.5068]])\n",
      "rho.1.bias tensor([ 0.3335, -0.3308])\n",
      "train_vars.0 tensor(1.6300)\n",
      "train_vars.1 tensor(2.3364)\n",
      "train_vars.2 tensor(1.7644)\n",
      "train_vars.3 tensor(2.2821)\n",
      "train_vars.4 tensor(1.5379)\n",
      "train_vars.5 tensor(2.4293)\n",
      "train_vars.6 tensor(1.9725)\n",
      "train_vars.7 tensor(2.1010)\n",
      "=====================================\n",
      "[20,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3799,  0.3398,  0.3614,  ..., -0.5130, -0.4888, -0.5013],\n",
      "        [-0.3865, -0.3420, -0.3448,  ...,  0.4989,  0.5300,  0.5067]])\n",
      "rho.1.bias tensor([ 0.3333, -0.3306])\n",
      "train_vars.0 tensor(1.6300)\n",
      "train_vars.1 tensor(2.3364)\n",
      "train_vars.2 tensor(1.7640)\n",
      "train_vars.3 tensor(2.2826)\n",
      "train_vars.4 tensor(1.5386)\n",
      "train_vars.5 tensor(2.4286)\n",
      "train_vars.6 tensor(1.9724)\n",
      "train_vars.7 tensor(2.1013)\n",
      "=====================================\n",
      "[20,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3806,  0.3405,  0.3622,  ..., -0.5121, -0.4879, -0.5003],\n",
      "        [-0.3873, -0.3428, -0.3456,  ...,  0.4979,  0.5290,  0.5058]])\n",
      "rho.1.bias tensor([ 0.3339, -0.3313])\n",
      "train_vars.0 tensor(1.6311)\n",
      "train_vars.1 tensor(2.3353)\n",
      "train_vars.2 tensor(1.7627)\n",
      "train_vars.3 tensor(2.2841)\n",
      "train_vars.4 tensor(1.5406)\n",
      "train_vars.5 tensor(2.4265)\n",
      "train_vars.6 tensor(1.9709)\n",
      "train_vars.7 tensor(2.1030)\n",
      "=====================================\n",
      "[20,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3800,  0.3399,  0.3615,  ..., -0.5131, -0.4889, -0.5013],\n",
      "        [-0.3866, -0.3421, -0.3449,  ...,  0.4989,  0.5300,  0.5068]])\n",
      "rho.1.bias tensor([ 0.3329, -0.3302])\n",
      "train_vars.0 tensor(1.6301)\n",
      "train_vars.1 tensor(2.3363)\n",
      "train_vars.2 tensor(1.7637)\n",
      "train_vars.3 tensor(2.2831)\n",
      "train_vars.4 tensor(1.5396)\n",
      "train_vars.5 tensor(2.4276)\n",
      "train_vars.6 tensor(1.9724)\n",
      "train_vars.7 tensor(2.1016)\n",
      "=====================================\n",
      "[20,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3797,  0.3396,  0.3613,  ..., -0.5138, -0.4896, -0.5020],\n",
      "        [-0.3863, -0.3418, -0.3446,  ...,  0.4997,  0.5308,  0.5075]])\n",
      "rho.1.bias tensor([ 0.3322, -0.3295])\n",
      "train_vars.0 tensor(1.6297)\n",
      "train_vars.1 tensor(2.3368)\n",
      "train_vars.2 tensor(1.7643)\n",
      "train_vars.3 tensor(2.2826)\n",
      "train_vars.4 tensor(1.5391)\n",
      "train_vars.5 tensor(2.4282)\n",
      "train_vars.6 tensor(1.9734)\n",
      "train_vars.7 tensor(2.1007)\n",
      "=====================================\n",
      "[20,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3796,  0.3395,  0.3612,  ..., -0.5144, -0.4902, -0.5026],\n",
      "        [-0.3862, -0.3418, -0.3445,  ...,  0.5003,  0.5314,  0.5081]])\n",
      "rho.1.bias tensor([ 0.3318, -0.3291])\n",
      "train_vars.0 tensor(1.6296)\n",
      "train_vars.1 tensor(2.3369)\n",
      "train_vars.2 tensor(1.7644)\n",
      "train_vars.3 tensor(2.2826)\n",
      "train_vars.4 tensor(1.5389)\n",
      "train_vars.5 tensor(2.4284)\n",
      "train_vars.6 tensor(1.9742)\n",
      "train_vars.7 tensor(2.1000)\n",
      "=====================================\n",
      "[20,     6] loss: 0.545\n",
      "rho.1.weight tensor([[ 0.3793,  0.3392,  0.3609,  ..., -0.5144, -0.4902, -0.5026],\n",
      "        [-0.3859, -0.3414, -0.3442,  ...,  0.5003,  0.5314,  0.5081]])\n",
      "rho.1.bias tensor([ 0.3309, -0.3283])\n",
      "train_vars.0 tensor(1.6291)\n",
      "train_vars.1 tensor(2.3374)\n",
      "train_vars.2 tensor(1.7647)\n",
      "train_vars.3 tensor(2.2823)\n",
      "train_vars.4 tensor(1.5393)\n",
      "train_vars.5 tensor(2.4280)\n",
      "train_vars.6 tensor(1.9742)\n",
      "train_vars.7 tensor(2.1001)\n",
      "=====================================\n",
      "[21,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3793,  0.3393,  0.3609,  ..., -0.5143, -0.4901, -0.5026],\n",
      "        [-0.3860, -0.3415, -0.3443,  ...,  0.5002,  0.5313,  0.5081]])\n",
      "rho.1.bias tensor([ 0.3308, -0.3281])\n",
      "train_vars.0 tensor(1.6291)\n",
      "train_vars.1 tensor(2.3374)\n",
      "train_vars.2 tensor(1.7643)\n",
      "train_vars.3 tensor(2.2828)\n",
      "train_vars.4 tensor(1.5400)\n",
      "train_vars.5 tensor(2.4272)\n",
      "train_vars.6 tensor(1.9741)\n",
      "train_vars.7 tensor(2.1004)\n",
      "=====================================\n",
      "[21,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3801,  0.3400,  0.3617,  ..., -0.5133, -0.4891, -0.5016],\n",
      "        [-0.3867, -0.3423, -0.3451,  ...,  0.4992,  0.5304,  0.5071]])\n",
      "rho.1.bias tensor([ 0.3314, -0.3287])\n",
      "train_vars.0 tensor(1.6302)\n",
      "train_vars.1 tensor(2.3363)\n",
      "train_vars.2 tensor(1.7630)\n",
      "train_vars.3 tensor(2.2843)\n",
      "train_vars.4 tensor(1.5420)\n",
      "train_vars.5 tensor(2.4251)\n",
      "train_vars.6 tensor(1.9726)\n",
      "train_vars.7 tensor(2.1021)\n",
      "=====================================\n",
      "[21,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3794,  0.3394,  0.3610,  ..., -0.5143, -0.4902, -0.5026],\n",
      "        [-0.3861, -0.3416, -0.3444,  ...,  0.5002,  0.5314,  0.5081]])\n",
      "rho.1.bias tensor([ 0.3303, -0.3277])\n",
      "train_vars.0 tensor(1.6292)\n",
      "train_vars.1 tensor(2.3373)\n",
      "train_vars.2 tensor(1.7640)\n",
      "train_vars.3 tensor(2.2833)\n",
      "train_vars.4 tensor(1.5409)\n",
      "train_vars.5 tensor(2.4263)\n",
      "train_vars.6 tensor(1.9741)\n",
      "train_vars.7 tensor(2.1007)\n",
      "=====================================\n",
      "[21,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3792,  0.3391,  0.3608,  ..., -0.5150, -0.4909, -0.5033],\n",
      "        [-0.3858, -0.3413, -0.3441,  ...,  0.5010,  0.5321,  0.5089]])\n",
      "rho.1.bias tensor([ 0.3297, -0.3270])\n",
      "train_vars.0 tensor(1.6288)\n",
      "train_vars.1 tensor(2.3378)\n",
      "train_vars.2 tensor(1.7646)\n",
      "train_vars.3 tensor(2.2828)\n",
      "train_vars.4 tensor(1.5405)\n",
      "train_vars.5 tensor(2.4268)\n",
      "train_vars.6 tensor(1.9751)\n",
      "train_vars.7 tensor(2.0998)\n",
      "=====================================\n",
      "[21,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3791,  0.3390,  0.3607,  ..., -0.5156, -0.4915, -0.5039],\n",
      "        [-0.3857, -0.3412, -0.3440,  ...,  0.5016,  0.5327,  0.5095]])\n",
      "rho.1.bias tensor([ 0.3292, -0.3266])\n",
      "train_vars.0 tensor(1.6287)\n",
      "train_vars.1 tensor(2.3380)\n",
      "train_vars.2 tensor(1.7647)\n",
      "train_vars.3 tensor(2.2828)\n",
      "train_vars.4 tensor(1.5402)\n",
      "train_vars.5 tensor(2.4270)\n",
      "train_vars.6 tensor(1.9759)\n",
      "train_vars.7 tensor(2.0990)\n",
      "=====================================\n",
      "[21,     6] loss: 0.545\n",
      "rho.1.weight tensor([[ 0.3788,  0.3387,  0.3604,  ..., -0.5156, -0.4915, -0.5039],\n",
      "        [-0.3854, -0.3409, -0.3437,  ...,  0.5016,  0.5327,  0.5095]])\n",
      "rho.1.bias tensor([ 0.3284, -0.3257])\n",
      "train_vars.0 tensor(1.6282)\n",
      "train_vars.1 tensor(2.3385)\n",
      "train_vars.2 tensor(1.7650)\n",
      "train_vars.3 tensor(2.2825)\n",
      "train_vars.4 tensor(1.5407)\n",
      "train_vars.5 tensor(2.4266)\n",
      "train_vars.6 tensor(1.9759)\n",
      "train_vars.7 tensor(2.0992)\n",
      "=====================================\n",
      "[22,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3788,  0.3387,  0.3604,  ..., -0.5155, -0.4914, -0.5039],\n",
      "        [-0.3855, -0.3410, -0.3438,  ...,  0.5015,  0.5326,  0.5094]])\n",
      "rho.1.bias tensor([ 0.3282, -0.3256])\n",
      "train_vars.0 tensor(1.6282)\n",
      "train_vars.1 tensor(2.3384)\n",
      "train_vars.2 tensor(1.7646)\n",
      "train_vars.3 tensor(2.2830)\n",
      "train_vars.4 tensor(1.5414)\n",
      "train_vars.5 tensor(2.4259)\n",
      "train_vars.6 tensor(1.9757)\n",
      "train_vars.7 tensor(2.0995)\n",
      "=====================================\n",
      "[22,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3796,  0.3395,  0.3612,  ..., -0.5146, -0.4904, -0.5029],\n",
      "        [-0.3862, -0.3417, -0.3445,  ...,  0.5005,  0.5317,  0.5085]])\n",
      "rho.1.bias tensor([ 0.3288, -0.3262])\n",
      "train_vars.0 tensor(1.6293)\n",
      "train_vars.1 tensor(2.3373)\n",
      "train_vars.2 tensor(1.7633)\n",
      "train_vars.3 tensor(2.2845)\n",
      "train_vars.4 tensor(1.5433)\n",
      "train_vars.5 tensor(2.4238)\n",
      "train_vars.6 tensor(1.9743)\n",
      "train_vars.7 tensor(2.1012)\n",
      "=====================================\n",
      "[22,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3789,  0.3388,  0.3605,  ..., -0.5156, -0.4914, -0.5039],\n",
      "        [-0.3855, -0.3410, -0.3438,  ...,  0.5015,  0.5327,  0.5095]])\n",
      "rho.1.bias tensor([ 0.3277, -0.3251])\n",
      "train_vars.0 tensor(1.6283)\n",
      "train_vars.1 tensor(2.3384)\n",
      "train_vars.2 tensor(1.7643)\n",
      "train_vars.3 tensor(2.2835)\n",
      "train_vars.4 tensor(1.5423)\n",
      "train_vars.5 tensor(2.4249)\n",
      "train_vars.6 tensor(1.9757)\n",
      "train_vars.7 tensor(2.0998)\n",
      "=====================================\n",
      "[22,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3786,  0.3386,  0.3602,  ..., -0.5163, -0.4921, -0.5046],\n",
      "        [-0.3852, -0.3408, -0.3436,  ...,  0.5023,  0.5334,  0.5102]])\n",
      "rho.1.bias tensor([ 0.3271, -0.3245])\n",
      "train_vars.0 tensor(1.6279)\n",
      "train_vars.1 tensor(2.3388)\n",
      "train_vars.2 tensor(1.7649)\n",
      "train_vars.3 tensor(2.2830)\n",
      "train_vars.4 tensor(1.5418)\n",
      "train_vars.5 tensor(2.4254)\n",
      "train_vars.6 tensor(1.9768)\n",
      "train_vars.7 tensor(2.0988)\n",
      "=====================================\n",
      "[22,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3786,  0.3385,  0.3602,  ..., -0.5169, -0.4927, -0.5052],\n",
      "        [-0.3852, -0.3407, -0.3435,  ...,  0.5029,  0.5340,  0.5108]])\n",
      "rho.1.bias tensor([ 0.3266, -0.3240])\n",
      "train_vars.0 tensor(1.6277)\n",
      "train_vars.1 tensor(2.3390)\n",
      "train_vars.2 tensor(1.7650)\n",
      "train_vars.3 tensor(2.2830)\n",
      "train_vars.4 tensor(1.5416)\n",
      "train_vars.5 tensor(2.4257)\n",
      "train_vars.6 tensor(1.9776)\n",
      "train_vars.7 tensor(2.0981)\n",
      "=====================================\n",
      "[22,     6] loss: 0.545\n",
      "rho.1.weight tensor([[ 0.3782,  0.3382,  0.3598,  ..., -0.5169, -0.4927, -0.5052],\n",
      "        [-0.3848, -0.3404, -0.3432,  ...,  0.5029,  0.5340,  0.5108]])\n",
      "rho.1.bias tensor([ 0.3258, -0.3232])\n",
      "train_vars.0 tensor(1.6272)\n",
      "train_vars.1 tensor(2.3395)\n",
      "train_vars.2 tensor(1.7653)\n",
      "train_vars.3 tensor(2.2828)\n",
      "train_vars.4 tensor(1.5420)\n",
      "train_vars.5 tensor(2.4252)\n",
      "train_vars.6 tensor(1.9776)\n",
      "train_vars.7 tensor(2.0983)\n",
      "=====================================\n",
      "[23,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3783,  0.3382,  0.3599,  ..., -0.5168, -0.4927, -0.5052],\n",
      "        [-0.3849, -0.3404, -0.3432,  ...,  0.5028,  0.5339,  0.5107]])\n",
      "rho.1.bias tensor([ 0.3256, -0.3230])\n",
      "train_vars.0 tensor(1.6273)\n",
      "train_vars.1 tensor(2.3395)\n",
      "train_vars.2 tensor(1.7649)\n",
      "train_vars.3 tensor(2.2833)\n",
      "train_vars.4 tensor(1.5427)\n",
      "train_vars.5 tensor(2.4245)\n",
      "train_vars.6 tensor(1.9774)\n",
      "train_vars.7 tensor(2.0986)\n",
      "=====================================\n",
      "[23,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3790,  0.3390,  0.3606,  ..., -0.5158, -0.4917, -0.5042],\n",
      "        [-0.3857, -0.3412, -0.3440,  ...,  0.5018,  0.5330,  0.5098]])\n",
      "rho.1.bias tensor([ 0.3262, -0.3237])\n",
      "train_vars.0 tensor(1.6284)\n",
      "train_vars.1 tensor(2.3384)\n",
      "train_vars.2 tensor(1.7636)\n",
      "train_vars.3 tensor(2.2848)\n",
      "train_vars.4 tensor(1.5447)\n",
      "train_vars.5 tensor(2.4224)\n",
      "train_vars.6 tensor(1.9760)\n",
      "train_vars.7 tensor(2.1002)\n",
      "=====================================\n",
      "[23,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3784,  0.3383,  0.3600,  ..., -0.5168, -0.4927, -0.5052],\n",
      "        [-0.3850, -0.3405, -0.3433,  ...,  0.5028,  0.5340,  0.5108]])\n",
      "rho.1.bias tensor([ 0.3252, -0.3226])\n",
      "train_vars.0 tensor(1.6274)\n",
      "train_vars.1 tensor(2.3395)\n",
      "train_vars.2 tensor(1.7646)\n",
      "train_vars.3 tensor(2.2838)\n",
      "train_vars.4 tensor(1.5437)\n",
      "train_vars.5 tensor(2.4236)\n",
      "train_vars.6 tensor(1.9774)\n",
      "train_vars.7 tensor(2.0988)\n",
      "=====================================\n",
      "[23,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3781,  0.3380,  0.3597,  ..., -0.5175, -0.4934, -0.5059],\n",
      "        [-0.3847, -0.3402, -0.3430,  ...,  0.5036,  0.5347,  0.5116]])\n",
      "rho.1.bias tensor([ 0.3245, -0.3219])\n",
      "train_vars.0 tensor(1.6269)\n",
      "train_vars.1 tensor(2.3399)\n",
      "train_vars.2 tensor(1.7652)\n",
      "train_vars.3 tensor(2.2833)\n",
      "train_vars.4 tensor(1.5432)\n",
      "train_vars.5 tensor(2.4241)\n",
      "train_vars.6 tensor(1.9784)\n",
      "train_vars.7 tensor(2.0979)\n",
      "=====================================\n",
      "[23,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3780,  0.3379,  0.3596,  ..., -0.5181, -0.4940, -0.5065],\n",
      "        [-0.3846, -0.3401, -0.3429,  ...,  0.5041,  0.5353,  0.5121]])\n",
      "rho.1.bias tensor([ 0.3240, -0.3215])\n",
      "train_vars.0 tensor(1.6268)\n",
      "train_vars.1 tensor(2.3401)\n",
      "train_vars.2 tensor(1.7653)\n",
      "train_vars.3 tensor(2.2833)\n",
      "train_vars.4 tensor(1.5430)\n",
      "train_vars.5 tensor(2.4243)\n",
      "train_vars.6 tensor(1.9792)\n",
      "train_vars.7 tensor(2.0972)\n",
      "=====================================\n",
      "[23,     6] loss: 0.545\n",
      "rho.1.weight tensor([[ 0.3777,  0.3376,  0.3593,  ..., -0.5181, -0.4940, -0.5065],\n",
      "        [-0.3843, -0.3398, -0.3426,  ...,  0.5041,  0.5353,  0.5122]])\n",
      "rho.1.bias tensor([ 0.3232, -0.3207])\n",
      "train_vars.0 tensor(1.6263)\n",
      "train_vars.1 tensor(2.3406)\n",
      "train_vars.2 tensor(1.7656)\n",
      "train_vars.3 tensor(2.2830)\n",
      "train_vars.4 tensor(1.5434)\n",
      "train_vars.5 tensor(2.4239)\n",
      "train_vars.6 tensor(1.9792)\n",
      "train_vars.7 tensor(2.0973)\n",
      "=====================================\n",
      "[24,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3777,  0.3377,  0.3594,  ..., -0.5180, -0.4939, -0.5065],\n",
      "        [-0.3844, -0.3399, -0.3427,  ...,  0.5041,  0.5353,  0.5121]])\n",
      "rho.1.bias tensor([ 0.3230, -0.3205])\n",
      "train_vars.0 tensor(1.6264)\n",
      "train_vars.1 tensor(2.3406)\n",
      "train_vars.2 tensor(1.7652)\n",
      "train_vars.3 tensor(2.2835)\n",
      "train_vars.4 tensor(1.5441)\n",
      "train_vars.5 tensor(2.4232)\n",
      "train_vars.6 tensor(1.9791)\n",
      "train_vars.7 tensor(2.0977)\n",
      "=====================================\n",
      "[24,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3785,  0.3384,  0.3601,  ..., -0.5171, -0.4930, -0.5055],\n",
      "        [-0.3851, -0.3406, -0.3434,  ...,  0.5031,  0.5343,  0.5111]])\n",
      "rho.1.bias tensor([ 0.3236, -0.3211])\n",
      "train_vars.0 tensor(1.6275)\n",
      "train_vars.1 tensor(2.3395)\n",
      "train_vars.2 tensor(1.7638)\n",
      "train_vars.3 tensor(2.2850)\n",
      "train_vars.4 tensor(1.5461)\n",
      "train_vars.5 tensor(2.4211)\n",
      "train_vars.6 tensor(1.9776)\n",
      "train_vars.7 tensor(2.0993)\n",
      "=====================================\n",
      "[24,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3778,  0.3377,  0.3594,  ..., -0.5181, -0.4940, -0.5065],\n",
      "        [-0.3844, -0.3399, -0.3427,  ...,  0.5041,  0.5353,  0.5122]])\n",
      "rho.1.bias tensor([ 0.3226, -0.3201])\n",
      "train_vars.0 tensor(1.6264)\n",
      "train_vars.1 tensor(2.3405)\n",
      "train_vars.2 tensor(1.7649)\n",
      "train_vars.3 tensor(2.2840)\n",
      "train_vars.4 tensor(1.5450)\n",
      "train_vars.5 tensor(2.4222)\n",
      "train_vars.6 tensor(1.9791)\n",
      "train_vars.7 tensor(2.0979)\n",
      "=====================================\n",
      "[24,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3775,  0.3375,  0.3592,  ..., -0.5188, -0.4947, -0.5072],\n",
      "        [-0.3841, -0.3396, -0.3425,  ...,  0.5048,  0.5361,  0.5129]])\n",
      "rho.1.bias tensor([ 0.3219, -0.3194])\n",
      "train_vars.0 tensor(1.6260)\n",
      "train_vars.1 tensor(2.3410)\n",
      "train_vars.2 tensor(1.7654)\n",
      "train_vars.3 tensor(2.2835)\n",
      "train_vars.4 tensor(1.5445)\n",
      "train_vars.5 tensor(2.4228)\n",
      "train_vars.6 tensor(1.9801)\n",
      "train_vars.7 tensor(2.0970)\n",
      "=====================================\n",
      "[24,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3775,  0.3374,  0.3591,  ..., -0.5194, -0.4953, -0.5078],\n",
      "        [-0.3840, -0.3396, -0.3424,  ...,  0.5054,  0.5366,  0.5135]])\n",
      "rho.1.bias tensor([ 0.3215, -0.3190])\n",
      "train_vars.0 tensor(1.6259)\n",
      "train_vars.1 tensor(2.3411)\n",
      "train_vars.2 tensor(1.7655)\n",
      "train_vars.3 tensor(2.2835)\n",
      "train_vars.4 tensor(1.5443)\n",
      "train_vars.5 tensor(2.4230)\n",
      "train_vars.6 tensor(1.9809)\n",
      "train_vars.7 tensor(2.0963)\n",
      "=====================================\n",
      "[24,     6] loss: 0.545\n",
      "rho.1.weight tensor([[ 0.3771,  0.3371,  0.3588,  ..., -0.5194, -0.4953, -0.5078],\n",
      "        [-0.3837, -0.3392, -0.3421,  ...,  0.5054,  0.5366,  0.5135]])\n",
      "rho.1.bias tensor([ 0.3206, -0.3181])\n",
      "train_vars.0 tensor(1.6254)\n",
      "train_vars.1 tensor(2.3417)\n",
      "train_vars.2 tensor(1.7658)\n",
      "train_vars.3 tensor(2.2832)\n",
      "train_vars.4 tensor(1.5447)\n",
      "train_vars.5 tensor(2.4226)\n",
      "train_vars.6 tensor(1.9809)\n",
      "train_vars.7 tensor(2.0964)\n",
      "=====================================\n",
      "[25,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3772,  0.3371,  0.3588,  ..., -0.5193, -0.4952, -0.5077],\n",
      "        [-0.3838, -0.3393, -0.3421,  ...,  0.5053,  0.5366,  0.5134]])\n",
      "rho.1.bias tensor([ 0.3204, -0.3180])\n",
      "train_vars.0 tensor(1.6254)\n",
      "train_vars.1 tensor(2.3416)\n",
      "train_vars.2 tensor(1.7654)\n",
      "train_vars.3 tensor(2.2838)\n",
      "train_vars.4 tensor(1.5454)\n",
      "train_vars.5 tensor(2.4218)\n",
      "train_vars.6 tensor(1.9807)\n",
      "train_vars.7 tensor(2.0968)\n",
      "=====================================\n",
      "[25,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3779,  0.3379,  0.3596,  ..., -0.5183, -0.4942, -0.5068],\n",
      "        [-0.3845, -0.3401, -0.3429,  ...,  0.5044,  0.5356,  0.5125]])\n",
      "rho.1.bias tensor([ 0.3211, -0.3186])\n",
      "train_vars.0 tensor(1.6265)\n",
      "train_vars.1 tensor(2.3406)\n",
      "train_vars.2 tensor(1.7641)\n",
      "train_vars.3 tensor(2.2852)\n",
      "train_vars.4 tensor(1.5474)\n",
      "train_vars.5 tensor(2.4198)\n",
      "train_vars.6 tensor(1.9793)\n",
      "train_vars.7 tensor(2.0984)\n",
      "=====================================\n",
      "[25,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3773,  0.3372,  0.3589,  ..., -0.5193, -0.4952, -0.5078],\n",
      "        [-0.3839, -0.3394, -0.3422,  ...,  0.5054,  0.5366,  0.5135]])\n",
      "rho.1.bias tensor([ 0.3200, -0.3175])\n",
      "train_vars.0 tensor(1.6255)\n",
      "train_vars.1 tensor(2.3416)\n",
      "train_vars.2 tensor(1.7651)\n",
      "train_vars.3 tensor(2.2842)\n",
      "train_vars.4 tensor(1.5463)\n",
      "train_vars.5 tensor(2.4209)\n",
      "train_vars.6 tensor(1.9807)\n",
      "train_vars.7 tensor(2.0970)\n",
      "=====================================\n",
      "[25,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3770,  0.3369,  0.3586,  ..., -0.5200, -0.4959, -0.5085],\n",
      "        [-0.3836, -0.3391, -0.3419,  ...,  0.5061,  0.5374,  0.5142]])\n",
      "rho.1.bias tensor([ 0.3193, -0.3169])\n",
      "train_vars.0 tensor(1.6250)\n",
      "train_vars.1 tensor(2.3421)\n",
      "train_vars.2 tensor(1.7657)\n",
      "train_vars.3 tensor(2.2837)\n",
      "train_vars.4 tensor(1.5458)\n",
      "train_vars.5 tensor(2.4215)\n",
      "train_vars.6 tensor(1.9817)\n",
      "train_vars.7 tensor(2.0961)\n",
      "=====================================\n",
      "[25,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3769,  0.3368,  0.3585,  ..., -0.5206, -0.4965, -0.5091],\n",
      "        [-0.3835, -0.3390, -0.3418,  ...,  0.5067,  0.5380,  0.5148]])\n",
      "rho.1.bias tensor([ 0.3189, -0.3164])\n",
      "train_vars.0 tensor(1.6249)\n",
      "train_vars.1 tensor(2.3422)\n",
      "train_vars.2 tensor(1.7658)\n",
      "train_vars.3 tensor(2.2837)\n",
      "train_vars.4 tensor(1.5456)\n",
      "train_vars.5 tensor(2.4217)\n",
      "train_vars.6 tensor(1.9825)\n",
      "train_vars.7 tensor(2.0954)\n",
      "=====================================\n",
      "[25,     6] loss: 0.545\n",
      "rho.1.weight tensor([[ 0.3766,  0.3365,  0.3582,  ..., -0.5206, -0.4965, -0.5091],\n",
      "        [-0.3832, -0.3387, -0.3415,  ...,  0.5067,  0.5379,  0.5148]])\n",
      "rho.1.bias tensor([ 0.3181, -0.3156])\n",
      "train_vars.0 tensor(1.6244)\n",
      "train_vars.1 tensor(2.3428)\n",
      "train_vars.2 tensor(1.7661)\n",
      "train_vars.3 tensor(2.2835)\n",
      "train_vars.4 tensor(1.5461)\n",
      "train_vars.5 tensor(2.4212)\n",
      "train_vars.6 tensor(1.9825)\n",
      "train_vars.7 tensor(2.0955)\n",
      "=====================================\n",
      "[26,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3766,  0.3366,  0.3583,  ..., -0.5205, -0.4964, -0.5090],\n",
      "        [-0.3832, -0.3387, -0.3415,  ...,  0.5066,  0.5379,  0.5147]])\n",
      "rho.1.bias tensor([ 0.3179, -0.3155])\n",
      "train_vars.0 tensor(1.6245)\n",
      "train_vars.1 tensor(2.3427)\n",
      "train_vars.2 tensor(1.7657)\n",
      "train_vars.3 tensor(2.2840)\n",
      "train_vars.4 tensor(1.5468)\n",
      "train_vars.5 tensor(2.4205)\n",
      "train_vars.6 tensor(1.9823)\n",
      "train_vars.7 tensor(2.0959)\n",
      "=====================================\n",
      "[26,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3774,  0.3373,  0.3590,  ..., -0.5195, -0.4955, -0.5081],\n",
      "        [-0.3840, -0.3395, -0.3423,  ...,  0.5057,  0.5369,  0.5138]])\n",
      "rho.1.bias tensor([ 0.3185, -0.3161])\n",
      "train_vars.0 tensor(1.6255)\n",
      "train_vars.1 tensor(2.3417)\n",
      "train_vars.2 tensor(1.7644)\n",
      "train_vars.3 tensor(2.2855)\n",
      "train_vars.4 tensor(1.5487)\n",
      "train_vars.5 tensor(2.4184)\n",
      "train_vars.6 tensor(1.9809)\n",
      "train_vars.7 tensor(2.0975)\n",
      "=====================================\n",
      "[26,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3767,  0.3366,  0.3583,  ..., -0.5206, -0.4965, -0.5091],\n",
      "        [-0.3833, -0.3388, -0.3416,  ...,  0.5067,  0.5379,  0.5148]])\n",
      "rho.1.bias tensor([ 0.3174, -0.3150])\n",
      "train_vars.0 tensor(1.6245)\n",
      "train_vars.1 tensor(2.3427)\n",
      "train_vars.2 tensor(1.7654)\n",
      "train_vars.3 tensor(2.2845)\n",
      "train_vars.4 tensor(1.5477)\n",
      "train_vars.5 tensor(2.4196)\n",
      "train_vars.6 tensor(1.9824)\n",
      "train_vars.7 tensor(2.0961)\n",
      "=====================================\n",
      "[26,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3764,  0.3363,  0.3580,  ..., -0.5213, -0.4972, -0.5098],\n",
      "        [-0.3830, -0.3385, -0.3413,  ...,  0.5074,  0.5387,  0.5156]])\n",
      "rho.1.bias tensor([ 0.3168, -0.3143])\n",
      "train_vars.0 tensor(1.6241)\n",
      "train_vars.1 tensor(2.3432)\n",
      "train_vars.2 tensor(1.7660)\n",
      "train_vars.3 tensor(2.2840)\n",
      "train_vars.4 tensor(1.5471)\n",
      "train_vars.5 tensor(2.4201)\n",
      "train_vars.6 tensor(1.9834)\n",
      "train_vars.7 tensor(2.0952)\n",
      "=====================================\n",
      "[26,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3763,  0.3363,  0.3580,  ..., -0.5218, -0.4978, -0.5104],\n",
      "        [-0.3829, -0.3384, -0.3412,  ...,  0.5080,  0.5393,  0.5161]])\n",
      "rho.1.bias tensor([ 0.3163, -0.3139])\n",
      "train_vars.0 tensor(1.6239)\n",
      "train_vars.1 tensor(2.3433)\n",
      "train_vars.2 tensor(1.7661)\n",
      "train_vars.3 tensor(2.2840)\n",
      "train_vars.4 tensor(1.5469)\n",
      "train_vars.5 tensor(2.4204)\n",
      "train_vars.6 tensor(1.9842)\n",
      "train_vars.7 tensor(2.0945)\n",
      "=====================================\n",
      "[26,     6] loss: 0.544\n",
      "rho.1.weight tensor([[ 0.3760,  0.3359,  0.3576,  ..., -0.5218, -0.4978, -0.5104],\n",
      "        [-0.3826, -0.3381, -0.3409,  ...,  0.5080,  0.5392,  0.5161]])\n",
      "rho.1.bias tensor([ 0.3155, -0.3131])\n",
      "train_vars.0 tensor(1.6234)\n",
      "train_vars.1 tensor(2.3438)\n",
      "train_vars.2 tensor(1.7664)\n",
      "train_vars.3 tensor(2.2837)\n",
      "train_vars.4 tensor(1.5474)\n",
      "train_vars.5 tensor(2.4199)\n",
      "train_vars.6 tensor(1.9841)\n",
      "train_vars.7 tensor(2.0947)\n",
      "=====================================\n",
      "[27,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3761,  0.3360,  0.3577,  ..., -0.5217, -0.4977, -0.5103],\n",
      "        [-0.3826, -0.3382, -0.3410,  ...,  0.5079,  0.5392,  0.5160]])\n",
      "rho.1.bias tensor([ 0.3153, -0.3129])\n",
      "train_vars.0 tensor(1.6235)\n",
      "train_vars.1 tensor(2.3438)\n",
      "train_vars.2 tensor(1.7660)\n",
      "train_vars.3 tensor(2.2843)\n",
      "train_vars.4 tensor(1.5481)\n",
      "train_vars.5 tensor(2.4192)\n",
      "train_vars.6 tensor(1.9840)\n",
      "train_vars.7 tensor(2.0950)\n",
      "=====================================\n",
      "[27,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3768,  0.3367,  0.3584,  ..., -0.5208, -0.4967, -0.5094],\n",
      "        [-0.3834, -0.3389, -0.3417,  ...,  0.5069,  0.5382,  0.5151]])\n",
      "rho.1.bias tensor([ 0.3159, -0.3136])\n",
      "train_vars.0 tensor(1.6246)\n",
      "train_vars.1 tensor(2.3428)\n",
      "train_vars.2 tensor(1.7646)\n",
      "train_vars.3 tensor(2.2857)\n",
      "train_vars.4 tensor(1.5500)\n",
      "train_vars.5 tensor(2.4171)\n",
      "train_vars.6 tensor(1.9825)\n",
      "train_vars.7 tensor(2.0967)\n",
      "=====================================\n",
      "[27,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3761,  0.3361,  0.3578,  ..., -0.5218, -0.4978, -0.5104],\n",
      "        [-0.3827, -0.3382, -0.3410,  ...,  0.5080,  0.5392,  0.5161]])\n",
      "rho.1.bias tensor([ 0.3148, -0.3125])\n",
      "train_vars.0 tensor(1.6235)\n",
      "train_vars.1 tensor(2.3438)\n",
      "train_vars.2 tensor(1.7657)\n",
      "train_vars.3 tensor(2.2847)\n",
      "train_vars.4 tensor(1.5490)\n",
      "train_vars.5 tensor(2.4183)\n",
      "train_vars.6 tensor(1.9840)\n",
      "train_vars.7 tensor(2.0953)\n",
      "=====================================\n",
      "[27,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3758,  0.3358,  0.3575,  ..., -0.5225, -0.4985, -0.5111],\n",
      "        [-0.3824, -0.3379, -0.3407,  ...,  0.5087,  0.5400,  0.5169]])\n",
      "rho.1.bias tensor([ 0.3142, -0.3118])\n",
      "train_vars.0 tensor(1.6231)\n",
      "train_vars.1 tensor(2.3443)\n",
      "train_vars.2 tensor(1.7662)\n",
      "train_vars.3 tensor(2.2842)\n",
      "train_vars.4 tensor(1.5485)\n",
      "train_vars.5 tensor(2.4188)\n",
      "train_vars.6 tensor(1.9850)\n",
      "train_vars.7 tensor(2.0943)\n",
      "=====================================\n",
      "[27,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3757,  0.3357,  0.3574,  ..., -0.5231, -0.4990, -0.5117],\n",
      "        [-0.3823, -0.3378, -0.3406,  ...,  0.5093,  0.5405,  0.5175]])\n",
      "rho.1.bias tensor([ 0.3137, -0.3114])\n",
      "train_vars.0 tensor(1.6229)\n",
      "train_vars.1 tensor(2.3444)\n",
      "train_vars.2 tensor(1.7663)\n",
      "train_vars.3 tensor(2.2842)\n",
      "train_vars.4 tensor(1.5483)\n",
      "train_vars.5 tensor(2.4191)\n",
      "train_vars.6 tensor(1.9858)\n",
      "train_vars.7 tensor(2.0936)\n",
      "=====================================\n",
      "[27,     6] loss: 0.544\n",
      "rho.1.weight tensor([[ 0.3754,  0.3354,  0.3571,  ..., -0.5230, -0.4990, -0.5117],\n",
      "        [-0.3820, -0.3375, -0.3403,  ...,  0.5092,  0.5405,  0.5175]])\n",
      "rho.1.bias tensor([ 0.3129, -0.3105])\n",
      "train_vars.0 tensor(1.6225)\n",
      "train_vars.1 tensor(2.3450)\n",
      "train_vars.2 tensor(1.7666)\n",
      "train_vars.3 tensor(2.2840)\n",
      "train_vars.4 tensor(1.5487)\n",
      "train_vars.5 tensor(2.4186)\n",
      "train_vars.6 tensor(1.9858)\n",
      "train_vars.7 tensor(2.0938)\n",
      "=====================================\n",
      "[28,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3755,  0.3354,  0.3571,  ..., -0.5229, -0.4989, -0.5116],\n",
      "        [-0.3820, -0.3376, -0.3404,  ...,  0.5091,  0.5404,  0.5174]])\n",
      "rho.1.bias tensor([ 0.3127, -0.3104])\n",
      "train_vars.0 tensor(1.6225)\n",
      "train_vars.1 tensor(2.3449)\n",
      "train_vars.2 tensor(1.7662)\n",
      "train_vars.3 tensor(2.2845)\n",
      "train_vars.4 tensor(1.5494)\n",
      "train_vars.5 tensor(2.4179)\n",
      "train_vars.6 tensor(1.9856)\n",
      "train_vars.7 tensor(2.0941)\n",
      "=====================================\n",
      "[28,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3762,  0.3361,  0.3579,  ..., -0.5220, -0.4980, -0.5106],\n",
      "        [-0.3828, -0.3383, -0.3411,  ...,  0.5082,  0.5395,  0.5164]])\n",
      "rho.1.bias tensor([ 0.3133, -0.3110])\n",
      "train_vars.0 tensor(1.6236)\n",
      "train_vars.1 tensor(2.3439)\n",
      "train_vars.2 tensor(1.7649)\n",
      "train_vars.3 tensor(2.2860)\n",
      "train_vars.4 tensor(1.5513)\n",
      "train_vars.5 tensor(2.4158)\n",
      "train_vars.6 tensor(1.9842)\n",
      "train_vars.7 tensor(2.0958)\n",
      "=====================================\n",
      "[28,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3755,  0.3355,  0.3572,  ..., -0.5230, -0.4990, -0.5116],\n",
      "        [-0.3821, -0.3376, -0.3404,  ...,  0.5092,  0.5405,  0.5175]])\n",
      "rho.1.bias tensor([ 0.3122, -0.3099])\n",
      "train_vars.0 tensor(1.6225)\n",
      "train_vars.1 tensor(2.3449)\n",
      "train_vars.2 tensor(1.7659)\n",
      "train_vars.3 tensor(2.2850)\n",
      "train_vars.4 tensor(1.5503)\n",
      "train_vars.5 tensor(2.4170)\n",
      "train_vars.6 tensor(1.9856)\n",
      "train_vars.7 tensor(2.0944)\n",
      "=====================================\n",
      "[28,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3752,  0.3352,  0.3569,  ..., -0.5237, -0.4997, -0.5124],\n",
      "        [-0.3818, -0.3373, -0.3401,  ...,  0.5100,  0.5413,  0.5182]])\n",
      "rho.1.bias tensor([ 0.3116, -0.3093])\n",
      "train_vars.0 tensor(1.6221)\n",
      "train_vars.1 tensor(2.3454)\n",
      "train_vars.2 tensor(1.7665)\n",
      "train_vars.3 tensor(2.2845)\n",
      "train_vars.4 tensor(1.5498)\n",
      "train_vars.5 tensor(2.4176)\n",
      "train_vars.6 tensor(1.9866)\n",
      "train_vars.7 tensor(2.0935)\n",
      "=====================================\n",
      "[28,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3752,  0.3351,  0.3568,  ..., -0.5243, -0.5003, -0.5129],\n",
      "        [-0.3817, -0.3372, -0.3401,  ...,  0.5105,  0.5418,  0.5188]])\n",
      "rho.1.bias tensor([ 0.3111, -0.3088])\n",
      "train_vars.0 tensor(1.6219)\n",
      "train_vars.1 tensor(2.3456)\n",
      "train_vars.2 tensor(1.7666)\n",
      "train_vars.3 tensor(2.2845)\n",
      "train_vars.4 tensor(1.5496)\n",
      "train_vars.5 tensor(2.4178)\n",
      "train_vars.6 tensor(1.9874)\n",
      "train_vars.7 tensor(2.0928)\n",
      "=====================================\n",
      "[28,     6] loss: 0.544\n",
      "rho.1.weight tensor([[ 0.3748,  0.3348,  0.3565,  ..., -0.5243, -0.5003, -0.5129],\n",
      "        [-0.3814, -0.3369, -0.3397,  ...,  0.5105,  0.5418,  0.5188]])\n",
      "rho.1.bias tensor([ 0.3103, -0.3080])\n",
      "train_vars.0 tensor(1.6215)\n",
      "train_vars.1 tensor(2.3461)\n",
      "train_vars.2 tensor(1.7669)\n",
      "train_vars.3 tensor(2.2843)\n",
      "train_vars.4 tensor(1.5500)\n",
      "train_vars.5 tensor(2.4173)\n",
      "train_vars.6 tensor(1.9874)\n",
      "train_vars.7 tensor(2.0929)\n",
      "=====================================\n",
      "[29,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3749,  0.3348,  0.3565,  ..., -0.5242, -0.5002, -0.5128],\n",
      "        [-0.3814, -0.3370, -0.3398,  ...,  0.5104,  0.5417,  0.5187]])\n",
      "rho.1.bias tensor([ 0.3101, -0.3079])\n",
      "train_vars.0 tensor(1.6215)\n",
      "train_vars.1 tensor(2.3460)\n",
      "train_vars.2 tensor(1.7665)\n",
      "train_vars.3 tensor(2.2848)\n",
      "train_vars.4 tensor(1.5507)\n",
      "train_vars.5 tensor(2.4166)\n",
      "train_vars.6 tensor(1.9872)\n",
      "train_vars.7 tensor(2.0933)\n",
      "=====================================\n",
      "[29,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3756,  0.3356,  0.3573,  ..., -0.5232, -0.4992, -0.5119],\n",
      "        [-0.3822, -0.3377, -0.3405,  ...,  0.5095,  0.5408,  0.5177]])\n",
      "rho.1.bias tensor([ 0.3108, -0.3085])\n",
      "train_vars.0 tensor(1.6226)\n",
      "train_vars.1 tensor(2.3450)\n",
      "train_vars.2 tensor(1.7651)\n",
      "train_vars.3 tensor(2.2862)\n",
      "train_vars.4 tensor(1.5526)\n",
      "train_vars.5 tensor(2.4145)\n",
      "train_vars.6 tensor(1.9858)\n",
      "train_vars.7 tensor(2.0949)\n",
      "=====================================\n",
      "[29,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3749,  0.3349,  0.3566,  ..., -0.5242, -0.5002, -0.5129],\n",
      "        [-0.3815, -0.3370, -0.3398,  ...,  0.5105,  0.5418,  0.5188]])\n",
      "rho.1.bias tensor([ 0.3097, -0.3074])\n",
      "train_vars.0 tensor(1.6215)\n",
      "train_vars.1 tensor(2.3460)\n",
      "train_vars.2 tensor(1.7662)\n",
      "train_vars.3 tensor(2.2852)\n",
      "train_vars.4 tensor(1.5516)\n",
      "train_vars.5 tensor(2.4157)\n",
      "train_vars.6 tensor(1.9872)\n",
      "train_vars.7 tensor(2.0935)\n",
      "=====================================\n",
      "[29,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3747,  0.3346,  0.3563,  ..., -0.5249, -0.5010, -0.5136],\n",
      "        [-0.3812, -0.3367, -0.3395,  ...,  0.5112,  0.5425,  0.5195]])\n",
      "rho.1.bias tensor([ 0.3090, -0.3067])\n",
      "train_vars.0 tensor(1.6211)\n",
      "train_vars.1 tensor(2.3465)\n",
      "train_vars.2 tensor(1.7667)\n",
      "train_vars.3 tensor(2.2847)\n",
      "train_vars.4 tensor(1.5510)\n",
      "train_vars.5 tensor(2.4163)\n",
      "train_vars.6 tensor(1.9882)\n",
      "train_vars.7 tensor(2.0926)\n",
      "=====================================\n",
      "[29,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3746,  0.3345,  0.3562,  ..., -0.5255, -0.5015, -0.5142],\n",
      "        [-0.3811, -0.3366, -0.3395,  ...,  0.5118,  0.5431,  0.5201]])\n",
      "rho.1.bias tensor([ 0.3085, -0.3063])\n",
      "train_vars.0 tensor(1.6209)\n",
      "train_vars.1 tensor(2.3467)\n",
      "train_vars.2 tensor(1.7668)\n",
      "train_vars.3 tensor(2.2848)\n",
      "train_vars.4 tensor(1.5508)\n",
      "train_vars.5 tensor(2.4165)\n",
      "train_vars.6 tensor(1.9890)\n",
      "train_vars.7 tensor(2.0919)\n",
      "=====================================\n",
      "[29,     6] loss: 0.544\n",
      "rho.1.weight tensor([[ 0.3742,  0.3342,  0.3559,  ..., -0.5255, -0.5015, -0.5142],\n",
      "        [-0.3808, -0.3363, -0.3391,  ...,  0.5118,  0.5431,  0.5201]])\n",
      "rho.1.bias tensor([ 0.3077, -0.3055])\n",
      "train_vars.0 tensor(1.6205)\n",
      "train_vars.1 tensor(2.3472)\n",
      "train_vars.2 tensor(1.7671)\n",
      "train_vars.3 tensor(2.2845)\n",
      "train_vars.4 tensor(1.5513)\n",
      "train_vars.5 tensor(2.4161)\n",
      "train_vars.6 tensor(1.9890)\n",
      "train_vars.7 tensor(2.0921)\n",
      "=====================================\n",
      "[30,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3743,  0.3342,  0.3560,  ..., -0.5254, -0.5014, -0.5141],\n",
      "        [-0.3808, -0.3364, -0.3392,  ...,  0.5117,  0.5430,  0.5200]])\n",
      "rho.1.bias tensor([ 0.3076, -0.3053])\n",
      "train_vars.0 tensor(1.6205)\n",
      "train_vars.1 tensor(2.3472)\n",
      "train_vars.2 tensor(1.7667)\n",
      "train_vars.3 tensor(2.2850)\n",
      "train_vars.4 tensor(1.5520)\n",
      "train_vars.5 tensor(2.4153)\n",
      "train_vars.6 tensor(1.9888)\n",
      "train_vars.7 tensor(2.0924)\n",
      "=====================================\n",
      "[30,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3750,  0.3350,  0.3567,  ..., -0.5244, -0.5005, -0.5132],\n",
      "        [-0.3816, -0.3371, -0.3399,  ...,  0.5107,  0.5421,  0.5190]])\n",
      "rho.1.bias tensor([ 0.3082, -0.3060])\n",
      "train_vars.0 tensor(1.6215)\n",
      "train_vars.1 tensor(2.3461)\n",
      "train_vars.2 tensor(1.7654)\n",
      "train_vars.3 tensor(2.2865)\n",
      "train_vars.4 tensor(1.5539)\n",
      "train_vars.5 tensor(2.4133)\n",
      "train_vars.6 tensor(1.9874)\n",
      "train_vars.7 tensor(2.0941)\n",
      "=====================================\n",
      "[30,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3743,  0.3343,  0.3560,  ..., -0.5254, -0.5015, -0.5142],\n",
      "        [-0.3809, -0.3364, -0.3392,  ...,  0.5117,  0.5431,  0.5201]])\n",
      "rho.1.bias tensor([ 0.3071, -0.3049])\n",
      "train_vars.0 tensor(1.6205)\n",
      "train_vars.1 tensor(2.3472)\n",
      "train_vars.2 tensor(1.7664)\n",
      "train_vars.3 tensor(2.2855)\n",
      "train_vars.4 tensor(1.5528)\n",
      "train_vars.5 tensor(2.4144)\n",
      "train_vars.6 tensor(1.9888)\n",
      "train_vars.7 tensor(2.0927)\n",
      "=====================================\n",
      "[30,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3741,  0.3340,  0.3557,  ..., -0.5261, -0.5022, -0.5149],\n",
      "        [-0.3806, -0.3361, -0.3389,  ...,  0.5125,  0.5438,  0.5208]])\n",
      "rho.1.bias tensor([ 0.3064, -0.3042])\n",
      "train_vars.0 tensor(1.6201)\n",
      "train_vars.1 tensor(2.3476)\n",
      "train_vars.2 tensor(1.7670)\n",
      "train_vars.3 tensor(2.2850)\n",
      "train_vars.4 tensor(1.5523)\n",
      "train_vars.5 tensor(2.4150)\n",
      "train_vars.6 tensor(1.9898)\n",
      "train_vars.7 tensor(2.0917)\n",
      "=====================================\n",
      "[30,     5] loss: 0.561\n",
      "rho.1.weight tensor([[ 0.3740,  0.3339,  0.3556,  ..., -0.5267, -0.5028, -0.5155],\n",
      "        [-0.3805, -0.3360, -0.3388,  ...,  0.5130,  0.5444,  0.5214]])\n",
      "rho.1.bias tensor([ 0.3060, -0.3038])\n",
      "train_vars.0 tensor(1.6199)\n",
      "train_vars.1 tensor(2.3478)\n",
      "train_vars.2 tensor(1.7670)\n",
      "train_vars.3 tensor(2.2850)\n",
      "train_vars.4 tensor(1.5521)\n",
      "train_vars.5 tensor(2.4152)\n",
      "train_vars.6 tensor(1.9906)\n",
      "train_vars.7 tensor(2.0911)\n",
      "=====================================\n",
      "[30,     6] loss: 0.544\n",
      "rho.1.weight tensor([[ 0.3736,  0.3336,  0.3553,  ..., -0.5267, -0.5027, -0.5154],\n",
      "        [-0.3802, -0.3357, -0.3385,  ...,  0.5130,  0.5444,  0.5214]])\n",
      "rho.1.bias tensor([ 0.3052, -0.3030])\n",
      "train_vars.0 tensor(1.6194)\n",
      "train_vars.1 tensor(2.3483)\n",
      "train_vars.2 tensor(1.7673)\n",
      "train_vars.3 tensor(2.2848)\n",
      "train_vars.4 tensor(1.5526)\n",
      "train_vars.5 tensor(2.4148)\n",
      "train_vars.6 tensor(1.9905)\n",
      "train_vars.7 tensor(2.0912)\n",
      "=====================================\n",
      "[31,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3737,  0.3336,  0.3554,  ..., -0.5266, -0.5026, -0.5154],\n",
      "        [-0.3802, -0.3358, -0.3386,  ...,  0.5129,  0.5443,  0.5213]])\n",
      "rho.1.bias tensor([ 0.3050, -0.3028])\n",
      "train_vars.0 tensor(1.6195)\n",
      "train_vars.1 tensor(2.3483)\n",
      "train_vars.2 tensor(1.7669)\n",
      "train_vars.3 tensor(2.2853)\n",
      "train_vars.4 tensor(1.5533)\n",
      "train_vars.5 tensor(2.4141)\n",
      "train_vars.6 tensor(1.9904)\n",
      "train_vars.7 tensor(2.0916)\n",
      "=====================================\n",
      "[31,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3744,  0.3344,  0.3561,  ..., -0.5256, -0.5017, -0.5144],\n",
      "        [-0.3809, -0.3365, -0.3393,  ...,  0.5120,  0.5433,  0.5203]])\n",
      "rho.1.bias tensor([ 0.3056, -0.3034])\n",
      "train_vars.0 tensor(1.6205)\n",
      "train_vars.1 tensor(2.3473)\n",
      "train_vars.2 tensor(1.7656)\n",
      "train_vars.3 tensor(2.2868)\n",
      "train_vars.4 tensor(1.5552)\n",
      "train_vars.5 tensor(2.4120)\n",
      "train_vars.6 tensor(1.9889)\n",
      "train_vars.7 tensor(2.0932)\n",
      "=====================================\n",
      "[31,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3737,  0.3337,  0.3554,  ..., -0.5266, -0.5027, -0.5154],\n",
      "        [-0.3803, -0.3358, -0.3386,  ...,  0.5130,  0.5444,  0.5214]])\n",
      "rho.1.bias tensor([ 0.3045, -0.3023])\n",
      "train_vars.0 tensor(1.6195)\n",
      "train_vars.1 tensor(2.3483)\n",
      "train_vars.2 tensor(1.7666)\n",
      "train_vars.3 tensor(2.2858)\n",
      "train_vars.4 tensor(1.5541)\n",
      "train_vars.5 tensor(2.4132)\n",
      "train_vars.6 tensor(1.9904)\n",
      "train_vars.7 tensor(2.0918)\n",
      "=====================================\n",
      "[31,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3734,  0.3334,  0.3551,  ..., -0.5274, -0.5034, -0.5161],\n",
      "        [-0.3799, -0.3355, -0.3383,  ...,  0.5137,  0.5451,  0.5221]])\n",
      "rho.1.bias tensor([ 0.3038, -0.3017])\n",
      "train_vars.0 tensor(1.6190)\n",
      "train_vars.1 tensor(2.3488)\n",
      "train_vars.2 tensor(1.7672)\n",
      "train_vars.3 tensor(2.2853)\n",
      "train_vars.4 tensor(1.5536)\n",
      "train_vars.5 tensor(2.4138)\n",
      "train_vars.6 tensor(1.9914)\n",
      "train_vars.7 tensor(2.0909)\n",
      "=====================================\n",
      "[31,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3734,  0.3333,  0.3550,  ..., -0.5279, -0.5040, -0.5167],\n",
      "        [-0.3799, -0.3354, -0.3382,  ...,  0.5143,  0.5457,  0.5227]])\n",
      "rho.1.bias tensor([ 0.3034, -0.3012])\n",
      "train_vars.0 tensor(1.6189)\n",
      "train_vars.1 tensor(2.3489)\n",
      "train_vars.2 tensor(1.7673)\n",
      "train_vars.3 tensor(2.2853)\n",
      "train_vars.4 tensor(1.5534)\n",
      "train_vars.5 tensor(2.4140)\n",
      "train_vars.6 tensor(1.9922)\n",
      "train_vars.7 tensor(2.0902)\n",
      "=====================================\n",
      "[31,     6] loss: 0.544\n",
      "rho.1.weight tensor([[ 0.3730,  0.3330,  0.3547,  ..., -0.5279, -0.5040, -0.5167],\n",
      "        [-0.3795, -0.3351, -0.3379,  ...,  0.5143,  0.5457,  0.5227]])\n",
      "rho.1.bias tensor([ 0.3026, -0.3004])\n",
      "train_vars.0 tensor(1.6184)\n",
      "train_vars.1 tensor(2.3495)\n",
      "train_vars.2 tensor(1.7676)\n",
      "train_vars.3 tensor(2.2851)\n",
      "train_vars.4 tensor(1.5538)\n",
      "train_vars.5 tensor(2.4135)\n",
      "train_vars.6 tensor(1.9921)\n",
      "train_vars.7 tensor(2.0904)\n",
      "=====================================\n",
      "[32,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3731,  0.3330,  0.3548,  ..., -0.5278, -0.5039, -0.5166],\n",
      "        [-0.3796, -0.3351, -0.3380,  ...,  0.5142,  0.5455,  0.5226]])\n",
      "rho.1.bias tensor([ 0.3024, -0.3003])\n",
      "train_vars.0 tensor(1.6185)\n",
      "train_vars.1 tensor(2.3494)\n",
      "train_vars.2 tensor(1.7671)\n",
      "train_vars.3 tensor(2.2856)\n",
      "train_vars.4 tensor(1.5545)\n",
      "train_vars.5 tensor(2.4128)\n",
      "train_vars.6 tensor(1.9919)\n",
      "train_vars.7 tensor(2.0907)\n",
      "=====================================\n",
      "[32,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3738,  0.3338,  0.3555,  ..., -0.5268, -0.5029, -0.5157],\n",
      "        [-0.3803, -0.3359, -0.3387,  ...,  0.5132,  0.5446,  0.5216]])\n",
      "rho.1.bias tensor([ 0.3030, -0.3009])\n",
      "train_vars.0 tensor(1.6195)\n",
      "train_vars.1 tensor(2.3484)\n",
      "train_vars.2 tensor(1.7658)\n",
      "train_vars.3 tensor(2.2870)\n",
      "train_vars.4 tensor(1.5565)\n",
      "train_vars.5 tensor(2.4108)\n",
      "train_vars.6 tensor(1.9905)\n",
      "train_vars.7 tensor(2.0924)\n",
      "=====================================\n",
      "[32,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3731,  0.3331,  0.3548,  ..., -0.5278, -0.5039, -0.5167],\n",
      "        [-0.3796, -0.3352, -0.3380,  ...,  0.5142,  0.5456,  0.5227]])\n",
      "rho.1.bias tensor([ 0.3019, -0.2998])\n",
      "train_vars.0 tensor(1.6185)\n",
      "train_vars.1 tensor(2.3495)\n",
      "train_vars.2 tensor(1.7669)\n",
      "train_vars.3 tensor(2.2860)\n",
      "train_vars.4 tensor(1.5554)\n",
      "train_vars.5 tensor(2.4119)\n",
      "train_vars.6 tensor(1.9920)\n",
      "train_vars.7 tensor(2.0910)\n",
      "=====================================\n",
      "[32,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3728,  0.3328,  0.3545,  ..., -0.5286, -0.5047, -0.5174],\n",
      "        [-0.3793, -0.3349, -0.3377,  ...,  0.5150,  0.5464,  0.5234]])\n",
      "rho.1.bias tensor([ 0.3013, -0.2991])\n",
      "train_vars.0 tensor(1.6180)\n",
      "train_vars.1 tensor(2.3499)\n",
      "train_vars.2 tensor(1.7674)\n",
      "train_vars.3 tensor(2.2855)\n",
      "train_vars.4 tensor(1.5548)\n",
      "train_vars.5 tensor(2.4125)\n",
      "train_vars.6 tensor(1.9930)\n",
      "train_vars.7 tensor(2.0901)\n",
      "=====================================\n",
      "[32,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3727,  0.3327,  0.3544,  ..., -0.5291, -0.5052, -0.5180],\n",
      "        [-0.3792, -0.3348, -0.3376,  ...,  0.5155,  0.5469,  0.5240]])\n",
      "rho.1.bias tensor([ 0.3008, -0.2987])\n",
      "train_vars.0 tensor(1.6179)\n",
      "train_vars.1 tensor(2.3501)\n",
      "train_vars.2 tensor(1.7675)\n",
      "train_vars.3 tensor(2.2856)\n",
      "train_vars.4 tensor(1.5547)\n",
      "train_vars.5 tensor(2.4127)\n",
      "train_vars.6 tensor(1.9937)\n",
      "train_vars.7 tensor(2.0894)\n",
      "=====================================\n",
      "[32,     6] loss: 0.544\n",
      "rho.1.weight tensor([[ 0.3724,  0.3324,  0.3541,  ..., -0.5291, -0.5052, -0.5179],\n",
      "        [-0.3789, -0.3345, -0.3373,  ...,  0.5155,  0.5469,  0.5240]])\n",
      "rho.1.bias tensor([ 0.3000, -0.2979])\n",
      "train_vars.0 tensor(1.6174)\n",
      "train_vars.1 tensor(2.3506)\n",
      "train_vars.2 tensor(1.7678)\n",
      "train_vars.3 tensor(2.2853)\n",
      "train_vars.4 tensor(1.5551)\n",
      "train_vars.5 tensor(2.4123)\n",
      "train_vars.6 tensor(1.9937)\n",
      "train_vars.7 tensor(2.0896)\n",
      "=====================================\n",
      "[33,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3725,  0.3324,  0.3541,  ..., -0.5290, -0.5051, -0.5178],\n",
      "        [-0.3790, -0.3345, -0.3373,  ...,  0.5154,  0.5468,  0.5238]])\n",
      "rho.1.bias tensor([ 0.2998, -0.2978])\n",
      "train_vars.0 tensor(1.6174)\n",
      "train_vars.1 tensor(2.3506)\n",
      "train_vars.2 tensor(1.7674)\n",
      "train_vars.3 tensor(2.2859)\n",
      "train_vars.4 tensor(1.5558)\n",
      "train_vars.5 tensor(2.4115)\n",
      "train_vars.6 tensor(1.9935)\n",
      "train_vars.7 tensor(2.0899)\n",
      "=====================================\n",
      "[33,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3732,  0.3331,  0.3549,  ..., -0.5280, -0.5041, -0.5169],\n",
      "        [-0.3797, -0.3352, -0.3381,  ...,  0.5144,  0.5459,  0.5229]])\n",
      "rho.1.bias tensor([ 0.3004, -0.2984])\n",
      "train_vars.0 tensor(1.6184)\n",
      "train_vars.1 tensor(2.3496)\n",
      "train_vars.2 tensor(1.7661)\n",
      "train_vars.3 tensor(2.2873)\n",
      "train_vars.4 tensor(1.5577)\n",
      "train_vars.5 tensor(2.4095)\n",
      "train_vars.6 tensor(1.9921)\n",
      "train_vars.7 tensor(2.0916)\n",
      "=====================================\n",
      "[33,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3725,  0.3325,  0.3542,  ..., -0.5290, -0.5052, -0.5179],\n",
      "        [-0.3790, -0.3345, -0.3374,  ...,  0.5155,  0.5469,  0.5240]])\n",
      "rho.1.bias tensor([ 0.2993, -0.2973])\n",
      "train_vars.0 tensor(1.6174)\n",
      "train_vars.1 tensor(2.3506)\n",
      "train_vars.2 tensor(1.7671)\n",
      "train_vars.3 tensor(2.2863)\n",
      "train_vars.4 tensor(1.5566)\n",
      "train_vars.5 tensor(2.4107)\n",
      "train_vars.6 tensor(1.9935)\n",
      "train_vars.7 tensor(2.0902)\n",
      "=====================================\n",
      "[33,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3722,  0.3322,  0.3539,  ..., -0.5298, -0.5059, -0.5186],\n",
      "        [-0.3787, -0.3342, -0.3371,  ...,  0.5162,  0.5476,  0.5247]])\n",
      "rho.1.bias tensor([ 0.2987, -0.2966])\n",
      "train_vars.0 tensor(1.6170)\n",
      "train_vars.1 tensor(2.3511)\n",
      "train_vars.2 tensor(1.7677)\n",
      "train_vars.3 tensor(2.2858)\n",
      "train_vars.4 tensor(1.5561)\n",
      "train_vars.5 tensor(2.4113)\n",
      "train_vars.6 tensor(1.9945)\n",
      "train_vars.7 tensor(2.0892)\n",
      "=====================================\n",
      "[33,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3721,  0.3321,  0.3538,  ..., -0.5303, -0.5064, -0.5192],\n",
      "        [-0.3786, -0.3341, -0.3370,  ...,  0.5168,  0.5482,  0.5253]])\n",
      "rho.1.bias tensor([ 0.2982, -0.2962])\n",
      "train_vars.0 tensor(1.6168)\n",
      "train_vars.1 tensor(2.3512)\n",
      "train_vars.2 tensor(1.7677)\n",
      "train_vars.3 tensor(2.2858)\n",
      "train_vars.4 tensor(1.5559)\n",
      "train_vars.5 tensor(2.4115)\n",
      "train_vars.6 tensor(1.9953)\n",
      "train_vars.7 tensor(2.0886)\n",
      "=====================================\n",
      "[33,     6] loss: 0.543\n",
      "rho.1.weight tensor([[ 0.3718,  0.3318,  0.3535,  ..., -0.5303, -0.5064, -0.5192],\n",
      "        [-0.3783, -0.3338, -0.3367,  ...,  0.5167,  0.5482,  0.5252]])\n",
      "rho.1.bias tensor([ 0.2974, -0.2954])\n",
      "train_vars.0 tensor(1.6163)\n",
      "train_vars.1 tensor(2.3518)\n",
      "train_vars.2 tensor(1.7680)\n",
      "train_vars.3 tensor(2.2856)\n",
      "train_vars.4 tensor(1.5563)\n",
      "train_vars.5 tensor(2.4110)\n",
      "train_vars.6 tensor(1.9952)\n",
      "train_vars.7 tensor(2.0887)\n",
      "=====================================\n",
      "[34,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3718,  0.3318,  0.3535,  ..., -0.5302, -0.5063, -0.5191],\n",
      "        [-0.3783, -0.3339, -0.3367,  ...,  0.5166,  0.5481,  0.5251]])\n",
      "rho.1.bias tensor([ 0.2972, -0.2952])\n",
      "train_vars.0 tensor(1.6164)\n",
      "train_vars.1 tensor(2.3517)\n",
      "train_vars.2 tensor(1.7676)\n",
      "train_vars.3 tensor(2.2861)\n",
      "train_vars.4 tensor(1.5570)\n",
      "train_vars.5 tensor(2.4103)\n",
      "train_vars.6 tensor(1.9950)\n",
      "train_vars.7 tensor(2.0891)\n",
      "=====================================\n",
      "[34,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3725,  0.3325,  0.3542,  ..., -0.5292, -0.5054, -0.5181],\n",
      "        [-0.3790, -0.3346, -0.3374,  ...,  0.5157,  0.5471,  0.5242]])\n",
      "rho.1.bias tensor([ 0.2979, -0.2959])\n",
      "train_vars.0 tensor(1.6174)\n",
      "train_vars.1 tensor(2.3507)\n",
      "train_vars.2 tensor(1.7663)\n",
      "train_vars.3 tensor(2.2876)\n",
      "train_vars.4 tensor(1.5590)\n",
      "train_vars.5 tensor(2.4083)\n",
      "train_vars.6 tensor(1.9936)\n",
      "train_vars.7 tensor(2.0907)\n",
      "=====================================\n",
      "[34,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3719,  0.3318,  0.3536,  ..., -0.5302, -0.5064, -0.5192],\n",
      "        [-0.3783, -0.3339, -0.3367,  ...,  0.5167,  0.5482,  0.5252]])\n",
      "rho.1.bias tensor([ 0.2968, -0.2948])\n",
      "train_vars.0 tensor(1.6164)\n",
      "train_vars.1 tensor(2.3518)\n",
      "train_vars.2 tensor(1.7673)\n",
      "train_vars.3 tensor(2.2866)\n",
      "train_vars.4 tensor(1.5579)\n",
      "train_vars.5 tensor(2.4095)\n",
      "train_vars.6 tensor(1.9951)\n",
      "train_vars.7 tensor(2.0893)\n",
      "=====================================\n",
      "[34,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3716,  0.3315,  0.3533,  ..., -0.5309, -0.5071, -0.5199],\n",
      "        [-0.3780, -0.3336, -0.3364,  ...,  0.5174,  0.5489,  0.5260]])\n",
      "rho.1.bias tensor([ 0.2961, -0.2941])\n",
      "train_vars.0 tensor(1.6159)\n",
      "train_vars.1 tensor(2.3523)\n",
      "train_vars.2 tensor(1.7679)\n",
      "train_vars.3 tensor(2.2861)\n",
      "train_vars.4 tensor(1.5573)\n",
      "train_vars.5 tensor(2.4101)\n",
      "train_vars.6 tensor(1.9961)\n",
      "train_vars.7 tensor(2.0884)\n",
      "=====================================\n",
      "[34,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3715,  0.3315,  0.3532,  ..., -0.5315, -0.5076, -0.5204],\n",
      "        [-0.3780, -0.3335, -0.3363,  ...,  0.5180,  0.5495,  0.5265]])\n",
      "rho.1.bias tensor([ 0.2957, -0.2937])\n",
      "train_vars.0 tensor(1.6158)\n",
      "train_vars.1 tensor(2.3524)\n",
      "train_vars.2 tensor(1.7679)\n",
      "train_vars.3 tensor(2.2861)\n",
      "train_vars.4 tensor(1.5571)\n",
      "train_vars.5 tensor(2.4103)\n",
      "train_vars.6 tensor(1.9968)\n",
      "train_vars.7 tensor(2.0878)\n",
      "=====================================\n",
      "[34,     6] loss: 0.543\n",
      "rho.1.weight tensor([[ 0.3712,  0.3311,  0.3529,  ..., -0.5315, -0.5076, -0.5204],\n",
      "        [-0.3776, -0.3332, -0.3360,  ...,  0.5180,  0.5494,  0.5265]])\n",
      "rho.1.bias tensor([ 0.2948, -0.2929])\n",
      "train_vars.0 tensor(1.6153)\n",
      "train_vars.1 tensor(2.3529)\n",
      "train_vars.2 tensor(1.7682)\n",
      "train_vars.3 tensor(2.2859)\n",
      "train_vars.4 tensor(1.5576)\n",
      "train_vars.5 tensor(2.4098)\n",
      "train_vars.6 tensor(1.9968)\n",
      "train_vars.7 tensor(2.0879)\n",
      "=====================================\n",
      "[35,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3712,  0.3312,  0.3529,  ..., -0.5314, -0.5075, -0.5203],\n",
      "        [-0.3777, -0.3332, -0.3361,  ...,  0.5178,  0.5493,  0.5264]])\n",
      "rho.1.bias tensor([ 0.2947, -0.2927])\n",
      "train_vars.0 tensor(1.6153)\n",
      "train_vars.1 tensor(2.3529)\n",
      "train_vars.2 tensor(1.7678)\n",
      "train_vars.3 tensor(2.2864)\n",
      "train_vars.4 tensor(1.5583)\n",
      "train_vars.5 tensor(2.4091)\n",
      "train_vars.6 tensor(1.9966)\n",
      "train_vars.7 tensor(2.0883)\n",
      "=====================================\n",
      "[35,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3719,  0.3319,  0.3536,  ..., -0.5304, -0.5066, -0.5194],\n",
      "        [-0.3784, -0.3339, -0.3368,  ...,  0.5169,  0.5484,  0.5255]])\n",
      "rho.1.bias tensor([ 0.2953, -0.2933])\n",
      "train_vars.0 tensor(1.6163)\n",
      "train_vars.1 tensor(2.3519)\n",
      "train_vars.2 tensor(1.7665)\n",
      "train_vars.3 tensor(2.2878)\n",
      "train_vars.4 tensor(1.5602)\n",
      "train_vars.5 tensor(2.4071)\n",
      "train_vars.6 tensor(1.9952)\n",
      "train_vars.7 tensor(2.0899)\n",
      "=====================================\n",
      "[35,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3712,  0.3312,  0.3529,  ..., -0.5314, -0.5076, -0.5204],\n",
      "        [-0.3777, -0.3332, -0.3361,  ...,  0.5179,  0.5494,  0.5265]])\n",
      "rho.1.bias tensor([ 0.2942, -0.2922])\n",
      "train_vars.0 tensor(1.6153)\n",
      "train_vars.1 tensor(2.3529)\n",
      "train_vars.2 tensor(1.7675)\n",
      "train_vars.3 tensor(2.2869)\n",
      "train_vars.4 tensor(1.5591)\n",
      "train_vars.5 tensor(2.4083)\n",
      "train_vars.6 tensor(1.9966)\n",
      "train_vars.7 tensor(2.0885)\n",
      "=====================================\n",
      "[35,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3709,  0.3309,  0.3526,  ..., -0.5321, -0.5083, -0.5211],\n",
      "        [-0.3774, -0.3329, -0.3358,  ...,  0.5187,  0.5501,  0.5273]])\n",
      "rho.1.bias tensor([ 0.2935, -0.2916])\n",
      "train_vars.0 tensor(1.6148)\n",
      "train_vars.1 tensor(2.3534)\n",
      "train_vars.2 tensor(1.7681)\n",
      "train_vars.3 tensor(2.2864)\n",
      "train_vars.4 tensor(1.5586)\n",
      "train_vars.5 tensor(2.4088)\n",
      "train_vars.6 tensor(1.9976)\n",
      "train_vars.7 tensor(2.0876)\n",
      "=====================================\n",
      "[35,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3709,  0.3308,  0.3525,  ..., -0.5327, -0.5089, -0.5217],\n",
      "        [-0.3773, -0.3329, -0.3357,  ...,  0.5192,  0.5507,  0.5278]])\n",
      "rho.1.bias tensor([ 0.2931, -0.2911])\n",
      "train_vars.0 tensor(1.6147)\n",
      "train_vars.1 tensor(2.3536)\n",
      "train_vars.2 tensor(1.7681)\n",
      "train_vars.3 tensor(2.2864)\n",
      "train_vars.4 tensor(1.5584)\n",
      "train_vars.5 tensor(2.4091)\n",
      "train_vars.6 tensor(1.9984)\n",
      "train_vars.7 tensor(2.0870)\n",
      "=====================================\n",
      "[35,     6] loss: 0.543\n",
      "rho.1.weight tensor([[ 0.3705,  0.3305,  0.3522,  ..., -0.5327, -0.5088, -0.5217],\n",
      "        [-0.3770, -0.3325, -0.3354,  ...,  0.5192,  0.5507,  0.5278]])\n",
      "rho.1.bias tensor([ 0.2923, -0.2903])\n",
      "train_vars.0 tensor(1.6142)\n",
      "train_vars.1 tensor(2.3541)\n",
      "train_vars.2 tensor(1.7684)\n",
      "train_vars.3 tensor(2.2862)\n",
      "train_vars.4 tensor(1.5588)\n",
      "train_vars.5 tensor(2.4086)\n",
      "train_vars.6 tensor(1.9983)\n",
      "train_vars.7 tensor(2.0871)\n",
      "=====================================\n",
      "[36,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3706,  0.3305,  0.3523,  ..., -0.5325, -0.5087, -0.5216],\n",
      "        [-0.3770, -0.3326, -0.3354,  ...,  0.5191,  0.5506,  0.5277]])\n",
      "rho.1.bias tensor([ 0.2921, -0.2902])\n",
      "train_vars.0 tensor(1.6143)\n",
      "train_vars.1 tensor(2.3541)\n",
      "train_vars.2 tensor(1.7680)\n",
      "train_vars.3 tensor(2.2867)\n",
      "train_vars.4 tensor(1.5595)\n",
      "train_vars.5 tensor(2.4079)\n",
      "train_vars.6 tensor(1.9981)\n",
      "train_vars.7 tensor(2.0875)\n",
      "=====================================\n",
      "[36,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3713,  0.3312,  0.3530,  ..., -0.5316, -0.5078, -0.5206],\n",
      "        [-0.3777, -0.3333, -0.3361,  ...,  0.5181,  0.5496,  0.5267]])\n",
      "rho.1.bias tensor([ 0.2927, -0.2908])\n",
      "train_vars.0 tensor(1.6153)\n",
      "train_vars.1 tensor(2.3531)\n",
      "train_vars.2 tensor(1.7667)\n",
      "train_vars.3 tensor(2.2881)\n",
      "train_vars.4 tensor(1.5614)\n",
      "train_vars.5 tensor(2.4059)\n",
      "train_vars.6 tensor(1.9967)\n",
      "train_vars.7 tensor(2.0891)\n",
      "=====================================\n",
      "[36,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3706,  0.3306,  0.3523,  ..., -0.5326, -0.5088, -0.5216],\n",
      "        [-0.3770, -0.3326, -0.3354,  ...,  0.5192,  0.5507,  0.5278]])\n",
      "rho.1.bias tensor([ 0.2916, -0.2897])\n",
      "train_vars.0 tensor(1.6142)\n",
      "train_vars.1 tensor(2.3541)\n",
      "train_vars.2 tensor(1.7677)\n",
      "train_vars.3 tensor(2.2871)\n",
      "train_vars.4 tensor(1.5603)\n",
      "train_vars.5 tensor(2.4071)\n",
      "train_vars.6 tensor(1.9982)\n",
      "train_vars.7 tensor(2.0877)\n",
      "=====================================\n",
      "[36,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3703,  0.3303,  0.3520,  ..., -0.5333, -0.5095, -0.5224],\n",
      "        [-0.3767, -0.3323, -0.3351,  ...,  0.5199,  0.5514,  0.5285]])\n",
      "rho.1.bias tensor([ 0.2910, -0.2890])\n",
      "train_vars.0 tensor(1.6138)\n",
      "train_vars.1 tensor(2.3546)\n",
      "train_vars.2 tensor(1.7683)\n",
      "train_vars.3 tensor(2.2866)\n",
      "train_vars.4 tensor(1.5598)\n",
      "train_vars.5 tensor(2.4076)\n",
      "train_vars.6 tensor(1.9992)\n",
      "train_vars.7 tensor(2.0868)\n",
      "=====================================\n",
      "[36,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3702,  0.3302,  0.3519,  ..., -0.5339, -0.5101, -0.5229],\n",
      "        [-0.3767, -0.3322, -0.3350,  ...,  0.5204,  0.5519,  0.5291]])\n",
      "rho.1.bias tensor([ 0.2905, -0.2886])\n",
      "train_vars.0 tensor(1.6136)\n",
      "train_vars.1 tensor(2.3547)\n",
      "train_vars.2 tensor(1.7683)\n",
      "train_vars.3 tensor(2.2867)\n",
      "train_vars.4 tensor(1.5596)\n",
      "train_vars.5 tensor(2.4078)\n",
      "train_vars.6 tensor(1.9999)\n",
      "train_vars.7 tensor(2.0862)\n",
      "=====================================\n",
      "[36,     6] loss: 0.543\n",
      "rho.1.weight tensor([[ 0.3699,  0.3299,  0.3516,  ..., -0.5338, -0.5100, -0.5229],\n",
      "        [-0.3763, -0.3319, -0.3347,  ...,  0.5204,  0.5519,  0.5291]])\n",
      "rho.1.bias tensor([ 0.2897, -0.2878])\n",
      "train_vars.0 tensor(1.6131)\n",
      "train_vars.1 tensor(2.3552)\n",
      "train_vars.2 tensor(1.7686)\n",
      "train_vars.3 tensor(2.2865)\n",
      "train_vars.4 tensor(1.5600)\n",
      "train_vars.5 tensor(2.4074)\n",
      "train_vars.6 tensor(1.9999)\n",
      "train_vars.7 tensor(2.0864)\n",
      "=====================================\n",
      "[37,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3699,  0.3299,  0.3516,  ..., -0.5337, -0.5099, -0.5228],\n",
      "        [-0.3764, -0.3319, -0.3348,  ...,  0.5203,  0.5518,  0.5289]])\n",
      "rho.1.bias tensor([ 0.2895, -0.2877])\n",
      "train_vars.0 tensor(1.6132)\n",
      "train_vars.1 tensor(2.3552)\n",
      "train_vars.2 tensor(1.7682)\n",
      "train_vars.3 tensor(2.2870)\n",
      "train_vars.4 tensor(1.5607)\n",
      "train_vars.5 tensor(2.4067)\n",
      "train_vars.6 tensor(1.9996)\n",
      "train_vars.7 tensor(2.0867)\n",
      "=====================================\n",
      "[37,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3706,  0.3306,  0.3523,  ..., -0.5328, -0.5090, -0.5218],\n",
      "        [-0.3771, -0.3326, -0.3355,  ...,  0.5193,  0.5509,  0.5280]])\n",
      "rho.1.bias tensor([ 0.2901, -0.2883])\n",
      "train_vars.0 tensor(1.6142)\n",
      "train_vars.1 tensor(2.3543)\n",
      "train_vars.2 tensor(1.7669)\n",
      "train_vars.3 tensor(2.2884)\n",
      "train_vars.4 tensor(1.5626)\n",
      "train_vars.5 tensor(2.4047)\n",
      "train_vars.6 tensor(1.9982)\n",
      "train_vars.7 tensor(2.0884)\n",
      "=====================================\n",
      "[37,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3699,  0.3299,  0.3516,  ..., -0.5338, -0.5100, -0.5229],\n",
      "        [-0.3764, -0.3319, -0.3348,  ...,  0.5204,  0.5519,  0.5291]])\n",
      "rho.1.bias tensor([ 0.2890, -0.2872])\n",
      "train_vars.0 tensor(1.6132)\n",
      "train_vars.1 tensor(2.3553)\n",
      "train_vars.2 tensor(1.7679)\n",
      "train_vars.3 tensor(2.2874)\n",
      "train_vars.4 tensor(1.5615)\n",
      "train_vars.5 tensor(2.4059)\n",
      "train_vars.6 tensor(1.9997)\n",
      "train_vars.7 tensor(2.0870)\n",
      "=====================================\n",
      "[37,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3696,  0.3296,  0.3513,  ..., -0.5345, -0.5107, -0.5236],\n",
      "        [-0.3761, -0.3316, -0.3345,  ...,  0.5211,  0.5526,  0.5298]])\n",
      "rho.1.bias tensor([ 0.2884, -0.2865])\n",
      "train_vars.0 tensor(1.6127)\n",
      "train_vars.1 tensor(2.3558)\n",
      "train_vars.2 tensor(1.7685)\n",
      "train_vars.3 tensor(2.2869)\n",
      "train_vars.4 tensor(1.5610)\n",
      "train_vars.5 tensor(2.4065)\n",
      "train_vars.6 tensor(2.0007)\n",
      "train_vars.7 tensor(2.0860)\n",
      "=====================================\n",
      "[37,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3696,  0.3295,  0.3513,  ..., -0.5350, -0.5113, -0.5241],\n",
      "        [-0.3760, -0.3315, -0.3344,  ...,  0.5216,  0.5532,  0.5303]])\n",
      "rho.1.bias tensor([ 0.2879, -0.2861])\n",
      "train_vars.0 tensor(1.6126)\n",
      "train_vars.1 tensor(2.3559)\n",
      "train_vars.2 tensor(1.7685)\n",
      "train_vars.3 tensor(2.2870)\n",
      "train_vars.4 tensor(1.5608)\n",
      "train_vars.5 tensor(2.4067)\n",
      "train_vars.6 tensor(2.0014)\n",
      "train_vars.7 tensor(2.0854)\n",
      "=====================================\n",
      "[37,     6] loss: 0.543\n",
      "rho.1.weight tensor([[ 0.3692,  0.3292,  0.3509,  ..., -0.5350, -0.5112, -0.5241],\n",
      "        [-0.3757, -0.3312, -0.3341,  ...,  0.5216,  0.5531,  0.5303]])\n",
      "rho.1.bias tensor([ 0.2871, -0.2853])\n",
      "train_vars.0 tensor(1.6121)\n",
      "train_vars.1 tensor(2.3564)\n",
      "train_vars.2 tensor(1.7688)\n",
      "train_vars.3 tensor(2.2867)\n",
      "train_vars.4 tensor(1.5612)\n",
      "train_vars.5 tensor(2.4062)\n",
      "train_vars.6 tensor(2.0014)\n",
      "train_vars.7 tensor(2.0856)\n",
      "=====================================\n",
      "[38,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3693,  0.3293,  0.3510,  ..., -0.5349, -0.5111, -0.5240],\n",
      "        [-0.3757, -0.3313, -0.3341,  ...,  0.5215,  0.5530,  0.5302]])\n",
      "rho.1.bias tensor([ 0.2870, -0.2852])\n",
      "train_vars.0 tensor(1.6121)\n",
      "train_vars.1 tensor(2.3564)\n",
      "train_vars.2 tensor(1.7684)\n",
      "train_vars.3 tensor(2.2873)\n",
      "train_vars.4 tensor(1.5619)\n",
      "train_vars.5 tensor(2.4055)\n",
      "train_vars.6 tensor(2.0012)\n",
      "train_vars.7 tensor(2.0859)\n",
      "=====================================\n",
      "[38,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3700,  0.3300,  0.3517,  ..., -0.5339, -0.5102, -0.5231],\n",
      "        [-0.3764, -0.3320, -0.3348,  ...,  0.5205,  0.5521,  0.5293]])\n",
      "rho.1.bias tensor([ 0.2876, -0.2858])\n",
      "train_vars.0 tensor(1.6131)\n",
      "train_vars.1 tensor(2.3554)\n",
      "train_vars.2 tensor(1.7671)\n",
      "train_vars.3 tensor(2.2887)\n",
      "train_vars.4 tensor(1.5638)\n",
      "train_vars.5 tensor(2.4035)\n",
      "train_vars.6 tensor(1.9998)\n",
      "train_vars.7 tensor(2.0876)\n",
      "=====================================\n",
      "[38,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3693,  0.3293,  0.3510,  ..., -0.5350, -0.5112, -0.5241],\n",
      "        [-0.3757, -0.3313, -0.3341,  ...,  0.5216,  0.5531,  0.5303]])\n",
      "rho.1.bias tensor([ 0.2865, -0.2847])\n",
      "train_vars.0 tensor(1.6121)\n",
      "train_vars.1 tensor(2.3565)\n",
      "train_vars.2 tensor(1.7681)\n",
      "train_vars.3 tensor(2.2877)\n",
      "train_vars.4 tensor(1.5627)\n",
      "train_vars.5 tensor(2.4047)\n",
      "train_vars.6 tensor(2.0012)\n",
      "train_vars.7 tensor(2.0862)\n",
      "=====================================\n",
      "[38,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3690,  0.3290,  0.3507,  ..., -0.5357, -0.5119, -0.5248],\n",
      "        [-0.3754, -0.3310, -0.3338,  ...,  0.5223,  0.5539,  0.5311]])\n",
      "rho.1.bias tensor([ 0.2858, -0.2840])\n",
      "train_vars.0 tensor(1.6116)\n",
      "train_vars.1 tensor(2.3570)\n",
      "train_vars.2 tensor(1.7687)\n",
      "train_vars.3 tensor(2.2872)\n",
      "train_vars.4 tensor(1.5622)\n",
      "train_vars.5 tensor(2.4053)\n",
      "train_vars.6 tensor(2.0022)\n",
      "train_vars.7 tensor(2.0852)\n",
      "=====================================\n",
      "[38,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3689,  0.3289,  0.3506,  ..., -0.5362, -0.5125, -0.5254],\n",
      "        [-0.3753, -0.3309, -0.3337,  ...,  0.5228,  0.5544,  0.5316]])\n",
      "rho.1.bias tensor([ 0.2854, -0.2836])\n",
      "train_vars.0 tensor(1.6115)\n",
      "train_vars.1 tensor(2.3571)\n",
      "train_vars.2 tensor(1.7687)\n",
      "train_vars.3 tensor(2.2872)\n",
      "train_vars.4 tensor(1.5620)\n",
      "train_vars.5 tensor(2.4055)\n",
      "train_vars.6 tensor(2.0029)\n",
      "train_vars.7 tensor(2.0846)\n",
      "=====================================\n",
      "[38,     6] loss: 0.543\n",
      "rho.1.weight tensor([[ 0.3686,  0.3286,  0.3503,  ..., -0.5362, -0.5124, -0.5253],\n",
      "        [-0.3750, -0.3306, -0.3334,  ...,  0.5228,  0.5544,  0.5316]])\n",
      "rho.1.bias tensor([ 0.2846, -0.2828])\n",
      "train_vars.0 tensor(1.6110)\n",
      "train_vars.1 tensor(2.3576)\n",
      "train_vars.2 tensor(1.7690)\n",
      "train_vars.3 tensor(2.2870)\n",
      "train_vars.4 tensor(1.5624)\n",
      "train_vars.5 tensor(2.4050)\n",
      "train_vars.6 tensor(2.0029)\n",
      "train_vars.7 tensor(2.0848)\n",
      "=====================================\n",
      "[39,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3686,  0.3286,  0.3503,  ..., -0.5360, -0.5123, -0.5252],\n",
      "        [-0.3751, -0.3306, -0.3335,  ...,  0.5227,  0.5543,  0.5314]])\n",
      "rho.1.bias tensor([ 0.2844, -0.2827])\n",
      "train_vars.0 tensor(1.6110)\n",
      "train_vars.1 tensor(2.3576)\n",
      "train_vars.2 tensor(1.7686)\n",
      "train_vars.3 tensor(2.2876)\n",
      "train_vars.4 tensor(1.5631)\n",
      "train_vars.5 tensor(2.4043)\n",
      "train_vars.6 tensor(2.0027)\n",
      "train_vars.7 tensor(2.0852)\n",
      "=====================================\n",
      "[39,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3693,  0.3293,  0.3510,  ..., -0.5351, -0.5114, -0.5243],\n",
      "        [-0.3758, -0.3313, -0.3342,  ...,  0.5217,  0.5533,  0.5305]])\n",
      "rho.1.bias tensor([ 0.2850, -0.2833])\n",
      "train_vars.0 tensor(1.6120)\n",
      "train_vars.1 tensor(2.3566)\n",
      "train_vars.2 tensor(1.7673)\n",
      "train_vars.3 tensor(2.2890)\n",
      "train_vars.4 tensor(1.5650)\n",
      "train_vars.5 tensor(2.4023)\n",
      "train_vars.6 tensor(2.0013)\n",
      "train_vars.7 tensor(2.0868)\n",
      "=====================================\n",
      "[39,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3686,  0.3286,  0.3503,  ..., -0.5361, -0.5124, -0.5253],\n",
      "        [-0.3751, -0.3306, -0.3335,  ...,  0.5228,  0.5544,  0.5316]])\n",
      "rho.1.bias tensor([ 0.2839, -0.2822])\n",
      "train_vars.0 tensor(1.6110)\n",
      "train_vars.1 tensor(2.3577)\n",
      "train_vars.2 tensor(1.7683)\n",
      "train_vars.3 tensor(2.2880)\n",
      "train_vars.4 tensor(1.5639)\n",
      "train_vars.5 tensor(2.4035)\n",
      "train_vars.6 tensor(2.0027)\n",
      "train_vars.7 tensor(2.0854)\n",
      "=====================================\n",
      "[39,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3683,  0.3283,  0.3500,  ..., -0.5368, -0.5131, -0.5260],\n",
      "        [-0.3747, -0.3303, -0.3331,  ...,  0.5235,  0.5551,  0.5323]])\n",
      "rho.1.bias tensor([ 0.2832, -0.2815])\n",
      "train_vars.0 tensor(1.6105)\n",
      "train_vars.1 tensor(2.3581)\n",
      "train_vars.2 tensor(1.7689)\n",
      "train_vars.3 tensor(2.2875)\n",
      "train_vars.4 tensor(1.5634)\n",
      "train_vars.5 tensor(2.4041)\n",
      "train_vars.6 tensor(2.0037)\n",
      "train_vars.7 tensor(2.0845)\n",
      "=====================================\n",
      "[39,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3683,  0.3282,  0.3500,  ..., -0.5374, -0.5136, -0.5266],\n",
      "        [-0.3747, -0.3302, -0.3331,  ...,  0.5240,  0.5556,  0.5328]])\n",
      "rho.1.bias tensor([ 0.2828, -0.2811])\n",
      "train_vars.0 tensor(1.6104)\n",
      "train_vars.1 tensor(2.3583)\n",
      "train_vars.2 tensor(1.7689)\n",
      "train_vars.3 tensor(2.2875)\n",
      "train_vars.4 tensor(1.5632)\n",
      "train_vars.5 tensor(2.4043)\n",
      "train_vars.6 tensor(2.0044)\n",
      "train_vars.7 tensor(2.0838)\n",
      "=====================================\n",
      "[39,     6] loss: 0.543\n",
      "rho.1.weight tensor([[ 0.3679,  0.3279,  0.3496,  ..., -0.5373, -0.5136, -0.5265],\n",
      "        [-0.3743, -0.3299, -0.3327,  ...,  0.5240,  0.5556,  0.5328]])\n",
      "rho.1.bias tensor([ 0.2820, -0.2803])\n",
      "train_vars.0 tensor(1.6099)\n",
      "train_vars.1 tensor(2.3588)\n",
      "train_vars.2 tensor(1.7692)\n",
      "train_vars.3 tensor(2.2873)\n",
      "train_vars.4 tensor(1.5636)\n",
      "train_vars.5 tensor(2.4039)\n",
      "train_vars.6 tensor(2.0044)\n",
      "train_vars.7 tensor(2.0840)\n",
      "=====================================\n",
      "[40,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3680,  0.3280,  0.3497,  ..., -0.5372, -0.5135, -0.5264],\n",
      "        [-0.3744, -0.3299, -0.3328,  ...,  0.5239,  0.5555,  0.5327]])\n",
      "rho.1.bias tensor([ 0.2818, -0.2801])\n",
      "train_vars.0 tensor(1.6099)\n",
      "train_vars.1 tensor(2.3588)\n",
      "train_vars.2 tensor(1.7688)\n",
      "train_vars.3 tensor(2.2878)\n",
      "train_vars.4 tensor(1.5643)\n",
      "train_vars.5 tensor(2.4031)\n",
      "train_vars.6 tensor(2.0041)\n",
      "train_vars.7 tensor(2.0844)\n",
      "=====================================\n",
      "[40,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3687,  0.3286,  0.3504,  ..., -0.5363, -0.5125, -0.5255],\n",
      "        [-0.3751, -0.3306, -0.3335,  ...,  0.5229,  0.5545,  0.5318]])\n",
      "rho.1.bias tensor([ 0.2825, -0.2808])\n",
      "train_vars.0 tensor(1.6109)\n",
      "train_vars.1 tensor(2.3578)\n",
      "train_vars.2 tensor(1.7675)\n",
      "train_vars.3 tensor(2.2892)\n",
      "train_vars.4 tensor(1.5662)\n",
      "train_vars.5 tensor(2.4011)\n",
      "train_vars.6 tensor(2.0027)\n",
      "train_vars.7 tensor(2.0861)\n",
      "=====================================\n",
      "[40,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3680,  0.3280,  0.3497,  ..., -0.5373, -0.5136, -0.5265],\n",
      "        [-0.3744, -0.3299, -0.3328,  ...,  0.5240,  0.5556,  0.5328]])\n",
      "rho.1.bias tensor([ 0.2814, -0.2797])\n",
      "train_vars.0 tensor(1.6099)\n",
      "train_vars.1 tensor(2.3589)\n",
      "train_vars.2 tensor(1.7685)\n",
      "train_vars.3 tensor(2.2883)\n",
      "train_vars.4 tensor(1.5651)\n",
      "train_vars.5 tensor(2.4023)\n",
      "train_vars.6 tensor(2.0042)\n",
      "train_vars.7 tensor(2.0846)\n",
      "=====================================\n",
      "[40,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3677,  0.3276,  0.3494,  ..., -0.5380, -0.5143, -0.5272],\n",
      "        [-0.3741, -0.3296, -0.3325,  ...,  0.5247,  0.5563,  0.5336]])\n",
      "rho.1.bias tensor([ 0.2807, -0.2790])\n",
      "train_vars.0 tensor(1.6094)\n",
      "train_vars.1 tensor(2.3593)\n",
      "train_vars.2 tensor(1.7691)\n",
      "train_vars.3 tensor(2.2878)\n",
      "train_vars.4 tensor(1.5645)\n",
      "train_vars.5 tensor(2.4029)\n",
      "train_vars.6 tensor(2.0052)\n",
      "train_vars.7 tensor(2.0837)\n",
      "=====================================\n",
      "[40,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3676,  0.3276,  0.3493,  ..., -0.5385, -0.5148, -0.5278],\n",
      "        [-0.3740, -0.3295, -0.3324,  ...,  0.5252,  0.5569,  0.5341]])\n",
      "rho.1.bias tensor([ 0.2802, -0.2786])\n",
      "train_vars.0 tensor(1.6093)\n",
      "train_vars.1 tensor(2.3595)\n",
      "train_vars.2 tensor(1.7691)\n",
      "train_vars.3 tensor(2.2878)\n",
      "train_vars.4 tensor(1.5644)\n",
      "train_vars.5 tensor(2.4031)\n",
      "train_vars.6 tensor(2.0059)\n",
      "train_vars.7 tensor(2.0831)\n",
      "=====================================\n",
      "[40,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3673,  0.3272,  0.3490,  ..., -0.5385, -0.5148, -0.5277],\n",
      "        [-0.3737, -0.3292, -0.3321,  ...,  0.5252,  0.5568,  0.5341]])\n",
      "rho.1.bias tensor([ 0.2794, -0.2778])\n",
      "train_vars.0 tensor(1.6088)\n",
      "train_vars.1 tensor(2.3600)\n",
      "train_vars.2 tensor(1.7694)\n",
      "train_vars.3 tensor(2.2876)\n",
      "train_vars.4 tensor(1.5648)\n",
      "train_vars.5 tensor(2.4027)\n",
      "train_vars.6 tensor(2.0058)\n",
      "train_vars.7 tensor(2.0833)\n",
      "=====================================\n",
      "[41,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3673,  0.3273,  0.3490,  ..., -0.5384, -0.5147, -0.5276],\n",
      "        [-0.3737, -0.3293, -0.3321,  ...,  0.5251,  0.5567,  0.5339]])\n",
      "rho.1.bias tensor([ 0.2793, -0.2776])\n",
      "train_vars.0 tensor(1.6088)\n",
      "train_vars.1 tensor(2.3600)\n",
      "train_vars.2 tensor(1.7690)\n",
      "train_vars.3 tensor(2.2881)\n",
      "train_vars.4 tensor(1.5655)\n",
      "train_vars.5 tensor(2.4020)\n",
      "train_vars.6 tensor(2.0056)\n",
      "train_vars.7 tensor(2.0837)\n",
      "=====================================\n",
      "[41,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3680,  0.3280,  0.3497,  ..., -0.5374, -0.5137, -0.5267],\n",
      "        [-0.3744, -0.3300, -0.3328,  ...,  0.5241,  0.5558,  0.5330]])\n",
      "rho.1.bias tensor([ 0.2799, -0.2783])\n",
      "train_vars.0 tensor(1.6098)\n",
      "train_vars.1 tensor(2.3590)\n",
      "train_vars.2 tensor(1.7677)\n",
      "train_vars.3 tensor(2.2895)\n",
      "train_vars.4 tensor(1.5674)\n",
      "train_vars.5 tensor(2.4000)\n",
      "train_vars.6 tensor(2.0042)\n",
      "train_vars.7 tensor(2.0853)\n",
      "=====================================\n",
      "[41,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3673,  0.3273,  0.3490,  ..., -0.5384, -0.5148, -0.5277],\n",
      "        [-0.3737, -0.3293, -0.3321,  ...,  0.5252,  0.5568,  0.5341]])\n",
      "rho.1.bias tensor([ 0.2788, -0.2772])\n",
      "train_vars.0 tensor(1.6088)\n",
      "train_vars.1 tensor(2.3600)\n",
      "train_vars.2 tensor(1.7687)\n",
      "train_vars.3 tensor(2.2885)\n",
      "train_vars.4 tensor(1.5663)\n",
      "train_vars.5 tensor(2.4012)\n",
      "train_vars.6 tensor(2.0057)\n",
      "train_vars.7 tensor(2.0839)\n",
      "=====================================\n",
      "[41,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3670,  0.3270,  0.3487,  ..., -0.5392, -0.5155, -0.5285],\n",
      "        [-0.3734, -0.3289, -0.3318,  ...,  0.5259,  0.5575,  0.5348]])\n",
      "rho.1.bias tensor([ 0.2781, -0.2765])\n",
      "train_vars.0 tensor(1.6083)\n",
      "train_vars.1 tensor(2.3605)\n",
      "train_vars.2 tensor(1.7693)\n",
      "train_vars.3 tensor(2.2880)\n",
      "train_vars.4 tensor(1.5657)\n",
      "train_vars.5 tensor(2.4018)\n",
      "train_vars.6 tensor(2.0067)\n",
      "train_vars.7 tensor(2.0830)\n",
      "=====================================\n",
      "[41,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3669,  0.3269,  0.3486,  ..., -0.5397, -0.5160, -0.5290],\n",
      "        [-0.3733, -0.3289, -0.3317,  ...,  0.5264,  0.5581,  0.5353]])\n",
      "rho.1.bias tensor([ 0.2777, -0.2761])\n",
      "train_vars.0 tensor(1.6082)\n",
      "train_vars.1 tensor(2.3607)\n",
      "train_vars.2 tensor(1.7693)\n",
      "train_vars.3 tensor(2.2881)\n",
      "train_vars.4 tensor(1.5656)\n",
      "train_vars.5 tensor(2.4020)\n",
      "train_vars.6 tensor(2.0074)\n",
      "train_vars.7 tensor(2.0824)\n",
      "=====================================\n",
      "[41,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3666,  0.3266,  0.3483,  ..., -0.5396, -0.5160, -0.5289],\n",
      "        [-0.3730, -0.3285, -0.3314,  ...,  0.5264,  0.5580,  0.5353]])\n",
      "rho.1.bias tensor([ 0.2769, -0.2753])\n",
      "train_vars.0 tensor(1.6077)\n",
      "train_vars.1 tensor(2.3612)\n",
      "train_vars.2 tensor(1.7696)\n",
      "train_vars.3 tensor(2.2879)\n",
      "train_vars.4 tensor(1.5660)\n",
      "train_vars.5 tensor(2.4015)\n",
      "train_vars.6 tensor(2.0073)\n",
      "train_vars.7 tensor(2.0826)\n",
      "=====================================\n",
      "[42,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3666,  0.3266,  0.3484,  ..., -0.5395, -0.5158, -0.5288],\n",
      "        [-0.3730, -0.3286, -0.3314,  ...,  0.5262,  0.5579,  0.5352]])\n",
      "rho.1.bias tensor([ 0.2767, -0.2751])\n",
      "train_vars.0 tensor(1.6077)\n",
      "train_vars.1 tensor(2.3611)\n",
      "train_vars.2 tensor(1.7691)\n",
      "train_vars.3 tensor(2.2884)\n",
      "train_vars.4 tensor(1.5667)\n",
      "train_vars.5 tensor(2.4008)\n",
      "train_vars.6 tensor(2.0071)\n",
      "train_vars.7 tensor(2.0829)\n",
      "=====================================\n",
      "[42,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3673,  0.3273,  0.3490,  ..., -0.5386, -0.5149, -0.5279],\n",
      "        [-0.3737, -0.3293, -0.3321,  ...,  0.5253,  0.5570,  0.5342]])\n",
      "rho.1.bias tensor([ 0.2773, -0.2758])\n",
      "train_vars.0 tensor(1.6087)\n",
      "train_vars.1 tensor(2.3602)\n",
      "train_vars.2 tensor(1.7679)\n",
      "train_vars.3 tensor(2.2898)\n",
      "train_vars.4 tensor(1.5685)\n",
      "train_vars.5 tensor(2.3988)\n",
      "train_vars.6 tensor(2.0057)\n",
      "train_vars.7 tensor(2.0846)\n",
      "=====================================\n",
      "[42,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3666,  0.3266,  0.3484,  ..., -0.5396, -0.5159, -0.5289],\n",
      "        [-0.3730, -0.3286, -0.3314,  ...,  0.5264,  0.5580,  0.5353]])\n",
      "rho.1.bias tensor([ 0.2762, -0.2747])\n",
      "train_vars.0 tensor(1.6077)\n",
      "train_vars.1 tensor(2.3612)\n",
      "train_vars.2 tensor(1.7689)\n",
      "train_vars.3 tensor(2.2888)\n",
      "train_vars.4 tensor(1.5674)\n",
      "train_vars.5 tensor(2.4001)\n",
      "train_vars.6 tensor(2.0072)\n",
      "train_vars.7 tensor(2.0832)\n",
      "=====================================\n",
      "[42,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3663,  0.3263,  0.3481,  ..., -0.5403, -0.5166, -0.5297],\n",
      "        [-0.3727, -0.3283, -0.3311,  ...,  0.5271,  0.5587,  0.5360]])\n",
      "rho.1.bias tensor([ 0.2756, -0.2740])\n",
      "train_vars.0 tensor(1.6072)\n",
      "train_vars.1 tensor(2.3617)\n",
      "train_vars.2 tensor(1.7695)\n",
      "train_vars.3 tensor(2.2883)\n",
      "train_vars.4 tensor(1.5669)\n",
      "train_vars.5 tensor(2.4007)\n",
      "train_vars.6 tensor(2.0082)\n",
      "train_vars.7 tensor(2.0822)\n",
      "=====================================\n",
      "[42,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3663,  0.3262,  0.3480,  ..., -0.5408, -0.5172, -0.5302],\n",
      "        [-0.3726, -0.3282, -0.3310,  ...,  0.5276,  0.5593,  0.5366]])\n",
      "rho.1.bias tensor([ 0.2751, -0.2736])\n",
      "train_vars.0 tensor(1.6071)\n",
      "train_vars.1 tensor(2.3619)\n",
      "train_vars.2 tensor(1.7695)\n",
      "train_vars.3 tensor(2.2884)\n",
      "train_vars.4 tensor(1.5667)\n",
      "train_vars.5 tensor(2.4008)\n",
      "train_vars.6 tensor(2.0089)\n",
      "train_vars.7 tensor(2.0816)\n",
      "=====================================\n",
      "[42,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3659,  0.3259,  0.3477,  ..., -0.5408, -0.5171, -0.5301],\n",
      "        [-0.3723, -0.3279, -0.3307,  ...,  0.5276,  0.5592,  0.5365]])\n",
      "rho.1.bias tensor([ 0.2743, -0.2728])\n",
      "train_vars.0 tensor(1.6066)\n",
      "train_vars.1 tensor(2.3624)\n",
      "train_vars.2 tensor(1.7697)\n",
      "train_vars.3 tensor(2.2882)\n",
      "train_vars.4 tensor(1.5672)\n",
      "train_vars.5 tensor(2.4004)\n",
      "train_vars.6 tensor(2.0088)\n",
      "train_vars.7 tensor(2.0818)\n",
      "=====================================\n",
      "[43,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3660,  0.3260,  0.3477,  ..., -0.5406, -0.5170, -0.5300],\n",
      "        [-0.3723, -0.3279, -0.3308,  ...,  0.5274,  0.5591,  0.5364]])\n",
      "rho.1.bias tensor([ 0.2742, -0.2726])\n",
      "train_vars.0 tensor(1.6066)\n",
      "train_vars.1 tensor(2.3623)\n",
      "train_vars.2 tensor(1.7693)\n",
      "train_vars.3 tensor(2.2887)\n",
      "train_vars.4 tensor(1.5678)\n",
      "train_vars.5 tensor(2.3997)\n",
      "train_vars.6 tensor(2.0086)\n",
      "train_vars.7 tensor(2.0822)\n",
      "=====================================\n",
      "[43,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3666,  0.3266,  0.3484,  ..., -0.5397, -0.5161, -0.5291],\n",
      "        [-0.3730, -0.3286, -0.3314,  ...,  0.5265,  0.5582,  0.5355]])\n",
      "rho.1.bias tensor([ 0.2748, -0.2733])\n",
      "train_vars.0 tensor(1.6076)\n",
      "train_vars.1 tensor(2.3614)\n",
      "train_vars.2 tensor(1.7680)\n",
      "train_vars.3 tensor(2.2901)\n",
      "train_vars.4 tensor(1.5697)\n",
      "train_vars.5 tensor(2.3977)\n",
      "train_vars.6 tensor(2.0072)\n",
      "train_vars.7 tensor(2.0838)\n",
      "=====================================\n",
      "[43,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3660,  0.3259,  0.3477,  ..., -0.5407, -0.5171, -0.5301],\n",
      "        [-0.3723, -0.3279, -0.3307,  ...,  0.5275,  0.5592,  0.5365]])\n",
      "rho.1.bias tensor([ 0.2737, -0.2722])\n",
      "train_vars.0 tensor(1.6066)\n",
      "train_vars.1 tensor(2.3624)\n",
      "train_vars.2 tensor(1.7691)\n",
      "train_vars.3 tensor(2.2891)\n",
      "train_vars.4 tensor(1.5686)\n",
      "train_vars.5 tensor(2.3989)\n",
      "train_vars.6 tensor(2.0086)\n",
      "train_vars.7 tensor(2.0824)\n",
      "=====================================\n",
      "[43,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3657,  0.3256,  0.3474,  ..., -0.5414, -0.5178, -0.5308],\n",
      "        [-0.3720, -0.3276, -0.3304,  ...,  0.5283,  0.5599,  0.5373]])\n",
      "rho.1.bias tensor([ 0.2730, -0.2715])\n",
      "train_vars.0 tensor(1.6061)\n",
      "train_vars.1 tensor(2.3629)\n",
      "train_vars.2 tensor(1.7696)\n",
      "train_vars.3 tensor(2.2886)\n",
      "train_vars.4 tensor(1.5680)\n",
      "train_vars.5 tensor(2.3995)\n",
      "train_vars.6 tensor(2.0096)\n",
      "train_vars.7 tensor(2.0815)\n",
      "=====================================\n",
      "[43,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3656,  0.3256,  0.3473,  ..., -0.5420, -0.5183, -0.5314],\n",
      "        [-0.3719, -0.3275, -0.3303,  ...,  0.5288,  0.5605,  0.5378]])\n",
      "rho.1.bias tensor([ 0.2726, -0.2711])\n",
      "train_vars.0 tensor(1.6060)\n",
      "train_vars.1 tensor(2.3631)\n",
      "train_vars.2 tensor(1.7696)\n",
      "train_vars.3 tensor(2.2887)\n",
      "train_vars.4 tensor(1.5679)\n",
      "train_vars.5 tensor(2.3997)\n",
      "train_vars.6 tensor(2.0103)\n",
      "train_vars.7 tensor(2.0809)\n",
      "=====================================\n",
      "[43,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3653,  0.3252,  0.3470,  ..., -0.5419, -0.5183, -0.5313],\n",
      "        [-0.3716, -0.3272, -0.3300,  ...,  0.5287,  0.5604,  0.5377]])\n",
      "rho.1.bias tensor([ 0.2718, -0.2703])\n",
      "train_vars.0 tensor(1.6055)\n",
      "train_vars.1 tensor(2.3636)\n",
      "train_vars.2 tensor(1.7699)\n",
      "train_vars.3 tensor(2.2885)\n",
      "train_vars.4 tensor(1.5683)\n",
      "train_vars.5 tensor(2.3993)\n",
      "train_vars.6 tensor(2.0102)\n",
      "train_vars.7 tensor(2.0811)\n",
      "=====================================\n",
      "[44,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3653,  0.3253,  0.3470,  ..., -0.5418, -0.5182, -0.5312],\n",
      "        [-0.3717, -0.3272, -0.3301,  ...,  0.5286,  0.5603,  0.5376]])\n",
      "rho.1.bias tensor([ 0.2716, -0.2702])\n",
      "train_vars.0 tensor(1.6055)\n",
      "train_vars.1 tensor(2.3635)\n",
      "train_vars.2 tensor(1.7695)\n",
      "train_vars.3 tensor(2.2890)\n",
      "train_vars.4 tensor(1.5690)\n",
      "train_vars.5 tensor(2.3985)\n",
      "train_vars.6 tensor(2.0100)\n",
      "train_vars.7 tensor(2.0815)\n",
      "=====================================\n",
      "[44,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3660,  0.3260,  0.3477,  ..., -0.5408, -0.5172, -0.5303],\n",
      "        [-0.3723, -0.3279, -0.3308,  ...,  0.5277,  0.5594,  0.5367]])\n",
      "rho.1.bias tensor([ 0.2722, -0.2708])\n",
      "train_vars.0 tensor(1.6065)\n",
      "train_vars.1 tensor(2.3626)\n",
      "train_vars.2 tensor(1.7682)\n",
      "train_vars.3 tensor(2.2904)\n",
      "train_vars.4 tensor(1.5708)\n",
      "train_vars.5 tensor(2.3966)\n",
      "train_vars.6 tensor(2.0086)\n",
      "train_vars.7 tensor(2.0831)\n",
      "=====================================\n",
      "[44,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3653,  0.3253,  0.3470,  ..., -0.5419, -0.5183, -0.5313],\n",
      "        [-0.3716, -0.3272, -0.3300,  ...,  0.5287,  0.5604,  0.5377]])\n",
      "rho.1.bias tensor([ 0.2711, -0.2697])\n",
      "train_vars.0 tensor(1.6054)\n",
      "train_vars.1 tensor(2.3637)\n",
      "train_vars.2 tensor(1.7692)\n",
      "train_vars.3 tensor(2.2894)\n",
      "train_vars.4 tensor(1.5697)\n",
      "train_vars.5 tensor(2.3978)\n",
      "train_vars.6 tensor(2.0101)\n",
      "train_vars.7 tensor(2.0817)\n",
      "=====================================\n",
      "[44,     4] loss: 0.480\n",
      "rho.1.weight tensor([[ 0.3650,  0.3250,  0.3467,  ..., -0.5426, -0.5190, -0.5320],\n",
      "        [-0.3713, -0.3269, -0.3297,  ...,  0.5294,  0.5611,  0.5385]])\n",
      "rho.1.bias tensor([ 0.2705, -0.2690])\n",
      "train_vars.0 tensor(1.6050)\n",
      "train_vars.1 tensor(2.3641)\n",
      "train_vars.2 tensor(1.7698)\n",
      "train_vars.3 tensor(2.2889)\n",
      "train_vars.4 tensor(1.5692)\n",
      "train_vars.5 tensor(2.3984)\n",
      "train_vars.6 tensor(2.0111)\n",
      "train_vars.7 tensor(2.0808)\n",
      "=====================================\n",
      "[44,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3649,  0.3249,  0.3466,  ..., -0.5431, -0.5195, -0.5326],\n",
      "        [-0.3712, -0.3268, -0.3297,  ...,  0.5299,  0.5617,  0.5390]])\n",
      "rho.1.bias tensor([ 0.2700, -0.2686])\n",
      "train_vars.0 tensor(1.6048)\n",
      "train_vars.1 tensor(2.3643)\n",
      "train_vars.2 tensor(1.7698)\n",
      "train_vars.3 tensor(2.2890)\n",
      "train_vars.4 tensor(1.5690)\n",
      "train_vars.5 tensor(2.3986)\n",
      "train_vars.6 tensor(2.0118)\n",
      "train_vars.7 tensor(2.0802)\n",
      "=====================================\n",
      "[44,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3646,  0.3246,  0.3463,  ..., -0.5431, -0.5195, -0.5325],\n",
      "        [-0.3709, -0.3265, -0.3293,  ...,  0.5299,  0.5616,  0.5390]])\n",
      "rho.1.bias tensor([ 0.2692, -0.2678])\n",
      "train_vars.0 tensor(1.6044)\n",
      "train_vars.1 tensor(2.3648)\n",
      "train_vars.2 tensor(1.7701)\n",
      "train_vars.3 tensor(2.2888)\n",
      "train_vars.4 tensor(1.5694)\n",
      "train_vars.5 tensor(2.3981)\n",
      "train_vars.6 tensor(2.0117)\n",
      "train_vars.7 tensor(2.0804)\n",
      "=====================================\n",
      "[45,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3646,  0.3246,  0.3463,  ..., -0.5429, -0.5193, -0.5324],\n",
      "        [-0.3710, -0.3265, -0.3294,  ...,  0.5298,  0.5615,  0.5388]])\n",
      "rho.1.bias tensor([ 0.2691, -0.2677])\n",
      "train_vars.0 tensor(1.6044)\n",
      "train_vars.1 tensor(2.3647)\n",
      "train_vars.2 tensor(1.7696)\n",
      "train_vars.3 tensor(2.2893)\n",
      "train_vars.4 tensor(1.5701)\n",
      "train_vars.5 tensor(2.3974)\n",
      "train_vars.6 tensor(2.0114)\n",
      "train_vars.7 tensor(2.0808)\n",
      "=====================================\n",
      "[45,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3653,  0.3253,  0.3470,  ..., -0.5420, -0.5184, -0.5315],\n",
      "        [-0.3716, -0.3272, -0.3301,  ...,  0.5288,  0.5605,  0.5379]])\n",
      "rho.1.bias tensor([ 0.2697, -0.2683])\n",
      "train_vars.0 tensor(1.6053)\n",
      "train_vars.1 tensor(2.3638)\n",
      "train_vars.2 tensor(1.7684)\n",
      "train_vars.3 tensor(2.2907)\n",
      "train_vars.4 tensor(1.5720)\n",
      "train_vars.5 tensor(2.3955)\n",
      "train_vars.6 tensor(2.0101)\n",
      "train_vars.7 tensor(2.0824)\n",
      "=====================================\n",
      "[45,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3646,  0.3246,  0.3463,  ..., -0.5430, -0.5194, -0.5325],\n",
      "        [-0.3709, -0.3265, -0.3294,  ...,  0.5299,  0.5616,  0.5390]])\n",
      "rho.1.bias tensor([ 0.2686, -0.2672])\n",
      "train_vars.0 tensor(1.6043)\n",
      "train_vars.1 tensor(2.3649)\n",
      "train_vars.2 tensor(1.7694)\n",
      "train_vars.3 tensor(2.2897)\n",
      "train_vars.4 tensor(1.5708)\n",
      "train_vars.5 tensor(2.3967)\n",
      "train_vars.6 tensor(2.0115)\n",
      "train_vars.7 tensor(2.0810)\n",
      "=====================================\n",
      "[45,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3643,  0.3243,  0.3460,  ..., -0.5437, -0.5201, -0.5332],\n",
      "        [-0.3706, -0.3262, -0.3290,  ...,  0.5306,  0.5623,  0.5397]])\n",
      "rho.1.bias tensor([ 0.2679, -0.2665])\n",
      "train_vars.0 tensor(1.6038)\n",
      "train_vars.1 tensor(2.3653)\n",
      "train_vars.2 tensor(1.7700)\n",
      "train_vars.3 tensor(2.2892)\n",
      "train_vars.4 tensor(1.5703)\n",
      "train_vars.5 tensor(2.3973)\n",
      "train_vars.6 tensor(2.0125)\n",
      "train_vars.7 tensor(2.0801)\n",
      "=====================================\n",
      "[45,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3642,  0.3242,  0.3459,  ..., -0.5442, -0.5207, -0.5337],\n",
      "        [-0.3705, -0.3261, -0.3290,  ...,  0.5311,  0.5628,  0.5402]])\n",
      "rho.1.bias tensor([ 0.2675, -0.2661])\n",
      "train_vars.0 tensor(1.6037)\n",
      "train_vars.1 tensor(2.3655)\n",
      "train_vars.2 tensor(1.7700)\n",
      "train_vars.3 tensor(2.2893)\n",
      "train_vars.4 tensor(1.5701)\n",
      "train_vars.5 tensor(2.3975)\n",
      "train_vars.6 tensor(2.0132)\n",
      "train_vars.7 tensor(2.0795)\n",
      "=====================================\n",
      "[45,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3639,  0.3239,  0.3456,  ..., -0.5442, -0.5206, -0.5337],\n",
      "        [-0.3702, -0.3258, -0.3286,  ...,  0.5311,  0.5628,  0.5402]])\n",
      "rho.1.bias tensor([ 0.2667, -0.2653])\n",
      "train_vars.0 tensor(1.6032)\n",
      "train_vars.1 tensor(2.3660)\n",
      "train_vars.2 tensor(1.7702)\n",
      "train_vars.3 tensor(2.2891)\n",
      "train_vars.4 tensor(1.5706)\n",
      "train_vars.5 tensor(2.3970)\n",
      "train_vars.6 tensor(2.0131)\n",
      "train_vars.7 tensor(2.0797)\n",
      "=====================================\n",
      "[46,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3639,  0.3239,  0.3457,  ..., -0.5440, -0.5205, -0.5336],\n",
      "        [-0.3703, -0.3258, -0.3287,  ...,  0.5309,  0.5627,  0.5400]])\n",
      "rho.1.bias tensor([ 0.2665, -0.2652])\n",
      "train_vars.0 tensor(1.6033)\n",
      "train_vars.1 tensor(2.3659)\n",
      "train_vars.2 tensor(1.7698)\n",
      "train_vars.3 tensor(2.2896)\n",
      "train_vars.4 tensor(1.5713)\n",
      "train_vars.5 tensor(2.3963)\n",
      "train_vars.6 tensor(2.0129)\n",
      "train_vars.7 tensor(2.0801)\n",
      "=====================================\n",
      "[46,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3646,  0.3246,  0.3463,  ..., -0.5431, -0.5195, -0.5326],\n",
      "        [-0.3709, -0.3265, -0.3294,  ...,  0.5300,  0.5617,  0.5391]])\n",
      "rho.1.bias tensor([ 0.2671, -0.2658])\n",
      "train_vars.0 tensor(1.6042)\n",
      "train_vars.1 tensor(2.3650)\n",
      "train_vars.2 tensor(1.7686)\n",
      "train_vars.3 tensor(2.2910)\n",
      "train_vars.4 tensor(1.5731)\n",
      "train_vars.5 tensor(2.3944)\n",
      "train_vars.6 tensor(2.0115)\n",
      "train_vars.7 tensor(2.0817)\n",
      "=====================================\n",
      "[46,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3639,  0.3239,  0.3456,  ..., -0.5441, -0.5206, -0.5337],\n",
      "        [-0.3702, -0.3258, -0.3287,  ...,  0.5310,  0.5628,  0.5402]])\n",
      "rho.1.bias tensor([ 0.2660, -0.2647])\n",
      "train_vars.0 tensor(1.6032)\n",
      "train_vars.1 tensor(2.3661)\n",
      "train_vars.2 tensor(1.7696)\n",
      "train_vars.3 tensor(2.2900)\n",
      "train_vars.4 tensor(1.5720)\n",
      "train_vars.5 tensor(2.3956)\n",
      "train_vars.6 tensor(2.0129)\n",
      "train_vars.7 tensor(2.0803)\n",
      "=====================================\n",
      "[46,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3636,  0.3236,  0.3453,  ..., -0.5448, -0.5213, -0.5344],\n",
      "        [-0.3699, -0.3255, -0.3283,  ...,  0.5318,  0.5635,  0.5409]])\n",
      "rho.1.bias tensor([ 0.2654, -0.2640])\n",
      "train_vars.0 tensor(1.6027)\n",
      "train_vars.1 tensor(2.3665)\n",
      "train_vars.2 tensor(1.7701)\n",
      "train_vars.3 tensor(2.2895)\n",
      "train_vars.4 tensor(1.5714)\n",
      "train_vars.5 tensor(2.3962)\n",
      "train_vars.6 tensor(2.0139)\n",
      "train_vars.7 tensor(2.0794)\n",
      "=====================================\n",
      "[46,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3635,  0.3235,  0.3453,  ..., -0.5454, -0.5218, -0.5349],\n",
      "        [-0.3698, -0.3254, -0.3283,  ...,  0.5323,  0.5640,  0.5414]])\n",
      "rho.1.bias tensor([ 0.2649, -0.2636])\n",
      "train_vars.0 tensor(1.6026)\n",
      "train_vars.1 tensor(2.3667)\n",
      "train_vars.2 tensor(1.7701)\n",
      "train_vars.3 tensor(2.2896)\n",
      "train_vars.4 tensor(1.5713)\n",
      "train_vars.5 tensor(2.3964)\n",
      "train_vars.6 tensor(2.0146)\n",
      "train_vars.7 tensor(2.0788)\n",
      "=====================================\n",
      "[46,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3632,  0.3232,  0.3449,  ..., -0.5453, -0.5218, -0.5349],\n",
      "        [-0.3695, -0.3251, -0.3279,  ...,  0.5322,  0.5640,  0.5414]])\n",
      "rho.1.bias tensor([ 0.2641, -0.2628])\n",
      "train_vars.0 tensor(1.6021)\n",
      "train_vars.1 tensor(2.3672)\n",
      "train_vars.2 tensor(1.7704)\n",
      "train_vars.3 tensor(2.2894)\n",
      "train_vars.4 tensor(1.5717)\n",
      "train_vars.5 tensor(2.3959)\n",
      "train_vars.6 tensor(2.0145)\n",
      "train_vars.7 tensor(2.0790)\n",
      "=====================================\n",
      "[47,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3632,  0.3232,  0.3450,  ..., -0.5452, -0.5216, -0.5347],\n",
      "        [-0.3696, -0.3251, -0.3280,  ...,  0.5321,  0.5638,  0.5412]])\n",
      "rho.1.bias tensor([ 0.2640, -0.2627])\n",
      "train_vars.0 tensor(1.6021)\n",
      "train_vars.1 tensor(2.3672)\n",
      "train_vars.2 tensor(1.7700)\n",
      "train_vars.3 tensor(2.2899)\n",
      "train_vars.4 tensor(1.5724)\n",
      "train_vars.5 tensor(2.3952)\n",
      "train_vars.6 tensor(2.0143)\n",
      "train_vars.7 tensor(2.0794)\n",
      "=====================================\n",
      "[47,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3639,  0.3239,  0.3456,  ..., -0.5442, -0.5207, -0.5338],\n",
      "        [-0.3702, -0.3258, -0.3287,  ...,  0.5311,  0.5629,  0.5403]])\n",
      "rho.1.bias tensor([ 0.2646, -0.2633])\n",
      "train_vars.0 tensor(1.6031)\n",
      "train_vars.1 tensor(2.3663)\n",
      "train_vars.2 tensor(1.7687)\n",
      "train_vars.3 tensor(2.2913)\n",
      "train_vars.4 tensor(1.5742)\n",
      "train_vars.5 tensor(2.3933)\n",
      "train_vars.6 tensor(2.0129)\n",
      "train_vars.7 tensor(2.0810)\n",
      "=====================================\n",
      "[47,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3632,  0.3232,  0.3450,  ..., -0.5453, -0.5217, -0.5349],\n",
      "        [-0.3695, -0.3251, -0.3280,  ...,  0.5322,  0.5640,  0.5414]])\n",
      "rho.1.bias tensor([ 0.2635, -0.2622])\n",
      "train_vars.0 tensor(1.6020)\n",
      "train_vars.1 tensor(2.3673)\n",
      "train_vars.2 tensor(1.7698)\n",
      "train_vars.3 tensor(2.2903)\n",
      "train_vars.4 tensor(1.5731)\n",
      "train_vars.5 tensor(2.3945)\n",
      "train_vars.6 tensor(2.0144)\n",
      "train_vars.7 tensor(2.0796)\n",
      "=====================================\n",
      "[47,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3629,  0.3229,  0.3446,  ..., -0.5460, -0.5224, -0.5356],\n",
      "        [-0.3692, -0.3248, -0.3276,  ...,  0.5329,  0.5647,  0.5421]])\n",
      "rho.1.bias tensor([ 0.2628, -0.2615])\n",
      "train_vars.0 tensor(1.6016)\n",
      "train_vars.1 tensor(2.3678)\n",
      "train_vars.2 tensor(1.7703)\n",
      "train_vars.3 tensor(2.2898)\n",
      "train_vars.4 tensor(1.5725)\n",
      "train_vars.5 tensor(2.3951)\n",
      "train_vars.6 tensor(2.0154)\n",
      "train_vars.7 tensor(2.0787)\n",
      "=====================================\n",
      "[47,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3628,  0.3228,  0.3446,  ..., -0.5465, -0.5230, -0.5361],\n",
      "        [-0.3691, -0.3247, -0.3276,  ...,  0.5334,  0.5652,  0.5426]])\n",
      "rho.1.bias tensor([ 0.2624, -0.2611])\n",
      "train_vars.0 tensor(1.6015)\n",
      "train_vars.1 tensor(2.3679)\n",
      "train_vars.2 tensor(1.7703)\n",
      "train_vars.3 tensor(2.2899)\n",
      "train_vars.4 tensor(1.5724)\n",
      "train_vars.5 tensor(2.3953)\n",
      "train_vars.6 tensor(2.0160)\n",
      "train_vars.7 tensor(2.0781)\n",
      "=====================================\n",
      "[47,     6] loss: 0.542\n",
      "rho.1.weight tensor([[ 0.3625,  0.3225,  0.3443,  ..., -0.5464, -0.5229, -0.5360],\n",
      "        [-0.3688, -0.3244, -0.3272,  ...,  0.5334,  0.5652,  0.5426]])\n",
      "rho.1.bias tensor([ 0.2616, -0.2603])\n",
      "train_vars.0 tensor(1.6010)\n",
      "train_vars.1 tensor(2.3684)\n",
      "train_vars.2 tensor(1.7706)\n",
      "train_vars.3 tensor(2.2897)\n",
      "train_vars.4 tensor(1.5728)\n",
      "train_vars.5 tensor(2.3948)\n",
      "train_vars.6 tensor(2.0159)\n",
      "train_vars.7 tensor(2.0783)\n",
      "=====================================\n",
      "[48,     1] loss: 0.507\n",
      "rho.1.weight tensor([[ 0.3625,  0.3225,  0.3443,  ..., -0.5463, -0.5228, -0.5359],\n",
      "        [-0.3689, -0.3244, -0.3273,  ...,  0.5332,  0.5650,  0.5424]])\n",
      "rho.1.bias tensor([ 0.2615, -0.2602])\n",
      "train_vars.0 tensor(1.6010)\n",
      "train_vars.1 tensor(2.3684)\n",
      "train_vars.2 tensor(1.7701)\n",
      "train_vars.3 tensor(2.2902)\n",
      "train_vars.4 tensor(1.5735)\n",
      "train_vars.5 tensor(2.3941)\n",
      "train_vars.6 tensor(2.0157)\n",
      "train_vars.7 tensor(2.0787)\n",
      "=====================================\n",
      "[48,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3632,  0.3232,  0.3450,  ..., -0.5453, -0.5218, -0.5350],\n",
      "        [-0.3695, -0.3251, -0.3280,  ...,  0.5323,  0.5641,  0.5415]])\n",
      "rho.1.bias tensor([ 0.2621, -0.2608])\n",
      "train_vars.0 tensor(1.6019)\n",
      "train_vars.1 tensor(2.3675)\n",
      "train_vars.2 tensor(1.7689)\n",
      "train_vars.3 tensor(2.2916)\n",
      "train_vars.4 tensor(1.5753)\n",
      "train_vars.5 tensor(2.3922)\n",
      "train_vars.6 tensor(2.0143)\n",
      "train_vars.7 tensor(2.0803)\n",
      "=====================================\n",
      "[48,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3625,  0.3225,  0.3443,  ..., -0.5464, -0.5229, -0.5360],\n",
      "        [-0.3688, -0.3244, -0.3272,  ...,  0.5333,  0.5651,  0.5426]])\n",
      "rho.1.bias tensor([ 0.2610, -0.2597])\n",
      "train_vars.0 tensor(1.6009)\n",
      "train_vars.1 tensor(2.3685)\n",
      "train_vars.2 tensor(1.7699)\n",
      "train_vars.3 tensor(2.2906)\n",
      "train_vars.4 tensor(1.5742)\n",
      "train_vars.5 tensor(2.3934)\n",
      "train_vars.6 tensor(2.0158)\n",
      "train_vars.7 tensor(2.0789)\n",
      "=====================================\n",
      "[48,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3622,  0.3222,  0.3440,  ..., -0.5471, -0.5236, -0.5367],\n",
      "        [-0.3685, -0.3241, -0.3269,  ...,  0.5341,  0.5659,  0.5433]])\n",
      "rho.1.bias tensor([ 0.2603, -0.2590])\n",
      "train_vars.0 tensor(1.6004)\n",
      "train_vars.1 tensor(2.3690)\n",
      "train_vars.2 tensor(1.7705)\n",
      "train_vars.3 tensor(2.2901)\n",
      "train_vars.4 tensor(1.5736)\n",
      "train_vars.5 tensor(2.3941)\n",
      "train_vars.6 tensor(2.0168)\n",
      "train_vars.7 tensor(2.0780)\n",
      "=====================================\n",
      "[48,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3621,  0.3221,  0.3439,  ..., -0.5476, -0.5241, -0.5373],\n",
      "        [-0.3684, -0.3240, -0.3269,  ...,  0.5346,  0.5664,  0.5438]])\n",
      "rho.1.bias tensor([ 0.2599, -0.2587])\n",
      "train_vars.0 tensor(1.6003)\n",
      "train_vars.1 tensor(2.3691)\n",
      "train_vars.2 tensor(1.7705)\n",
      "train_vars.3 tensor(2.2902)\n",
      "train_vars.4 tensor(1.5735)\n",
      "train_vars.5 tensor(2.3942)\n",
      "train_vars.6 tensor(2.0174)\n",
      "train_vars.7 tensor(2.0774)\n",
      "=====================================\n",
      "[48,     6] loss: 0.541\n",
      "rho.1.weight tensor([[ 0.3618,  0.3218,  0.3436,  ..., -0.5475, -0.5240, -0.5372],\n",
      "        [-0.3681, -0.3237, -0.3265,  ...,  0.5345,  0.5663,  0.5438]])\n",
      "rho.1.bias tensor([ 0.2591, -0.2579])\n",
      "train_vars.0 tensor(1.5998)\n",
      "train_vars.1 tensor(2.3696)\n",
      "train_vars.2 tensor(1.7707)\n",
      "train_vars.3 tensor(2.2900)\n",
      "train_vars.4 tensor(1.5739)\n",
      "train_vars.5 tensor(2.3938)\n",
      "train_vars.6 tensor(2.0173)\n",
      "train_vars.7 tensor(2.0776)\n",
      "=====================================\n",
      "[49,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3619,  0.3218,  0.3436,  ..., -0.5474, -0.5239, -0.5371],\n",
      "        [-0.3682, -0.3237, -0.3266,  ...,  0.5343,  0.5662,  0.5436]])\n",
      "rho.1.bias tensor([ 0.2589, -0.2577])\n",
      "train_vars.0 tensor(1.5999)\n",
      "train_vars.1 tensor(2.3696)\n",
      "train_vars.2 tensor(1.7703)\n",
      "train_vars.3 tensor(2.2905)\n",
      "train_vars.4 tensor(1.5746)\n",
      "train_vars.5 tensor(2.3930)\n",
      "train_vars.6 tensor(2.0171)\n",
      "train_vars.7 tensor(2.0780)\n",
      "=====================================\n",
      "[49,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3625,  0.3225,  0.3443,  ..., -0.5464, -0.5230, -0.5361],\n",
      "        [-0.3688, -0.3244, -0.3272,  ...,  0.5334,  0.5652,  0.5427]])\n",
      "rho.1.bias tensor([ 0.2595, -0.2584])\n",
      "train_vars.0 tensor(1.6008)\n",
      "train_vars.1 tensor(2.3687)\n",
      "train_vars.2 tensor(1.7690)\n",
      "train_vars.3 tensor(2.2918)\n",
      "train_vars.4 tensor(1.5764)\n",
      "train_vars.5 tensor(2.3911)\n",
      "train_vars.6 tensor(2.0157)\n",
      "train_vars.7 tensor(2.0796)\n",
      "=====================================\n",
      "[49,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3618,  0.3218,  0.3436,  ..., -0.5475, -0.5240, -0.5372],\n",
      "        [-0.3681, -0.3237, -0.3265,  ...,  0.5345,  0.5663,  0.5438]])\n",
      "rho.1.bias tensor([ 0.2584, -0.2572])\n",
      "train_vars.0 tensor(1.5998)\n",
      "train_vars.1 tensor(2.3697)\n",
      "train_vars.2 tensor(1.7701)\n",
      "train_vars.3 tensor(2.2909)\n",
      "train_vars.4 tensor(1.5753)\n",
      "train_vars.5 tensor(2.3924)\n",
      "train_vars.6 tensor(2.0172)\n",
      "train_vars.7 tensor(2.0782)\n",
      "=====================================\n",
      "[49,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3615,  0.3215,  0.3433,  ..., -0.5482, -0.5247, -0.5379],\n",
      "        [-0.3678, -0.3234, -0.3262,  ...,  0.5352,  0.5670,  0.5445]])\n",
      "rho.1.bias tensor([ 0.2578, -0.2566])\n",
      "train_vars.0 tensor(1.5993)\n",
      "train_vars.1 tensor(2.3702)\n",
      "train_vars.2 tensor(1.7706)\n",
      "train_vars.3 tensor(2.2904)\n",
      "train_vars.4 tensor(1.5747)\n",
      "train_vars.5 tensor(2.3930)\n",
      "train_vars.6 tensor(2.0182)\n",
      "train_vars.7 tensor(2.0773)\n",
      "=====================================\n",
      "[49,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3614,  0.3214,  0.3432,  ..., -0.5487, -0.5252, -0.5384],\n",
      "        [-0.3677, -0.3233, -0.3262,  ...,  0.5357,  0.5675,  0.5450]])\n",
      "rho.1.bias tensor([ 0.2574, -0.2562])\n",
      "train_vars.0 tensor(1.5992)\n",
      "train_vars.1 tensor(2.3703)\n",
      "train_vars.2 tensor(1.7706)\n",
      "train_vars.3 tensor(2.2905)\n",
      "train_vars.4 tensor(1.5746)\n",
      "train_vars.5 tensor(2.3931)\n",
      "train_vars.6 tensor(2.0188)\n",
      "train_vars.7 tensor(2.0767)\n",
      "=====================================\n",
      "[49,     6] loss: 0.541\n",
      "rho.1.weight tensor([[ 0.3611,  0.3211,  0.3429,  ..., -0.5486, -0.5252, -0.5384],\n",
      "        [-0.3674, -0.3230, -0.3258,  ...,  0.5356,  0.5675,  0.5450]])\n",
      "rho.1.bias tensor([ 0.2565, -0.2554])\n",
      "train_vars.0 tensor(1.5987)\n",
      "train_vars.1 tensor(2.3708)\n",
      "train_vars.2 tensor(1.7709)\n",
      "train_vars.3 tensor(2.2903)\n",
      "train_vars.4 tensor(1.5750)\n",
      "train_vars.5 tensor(2.3927)\n",
      "train_vars.6 tensor(2.0187)\n",
      "train_vars.7 tensor(2.0770)\n",
      "=====================================\n",
      "[50,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3612,  0.3212,  0.3429,  ..., -0.5485, -0.5250, -0.5382],\n",
      "        [-0.3674, -0.3230, -0.3259,  ...,  0.5355,  0.5673,  0.5448]])\n",
      "rho.1.bias tensor([ 0.2564, -0.2553])\n",
      "train_vars.0 tensor(1.5987)\n",
      "train_vars.1 tensor(2.3708)\n",
      "train_vars.2 tensor(1.7704)\n",
      "train_vars.3 tensor(2.2908)\n",
      "train_vars.4 tensor(1.5757)\n",
      "train_vars.5 tensor(2.3920)\n",
      "train_vars.6 tensor(2.0185)\n",
      "train_vars.7 tensor(2.0774)\n",
      "=====================================\n",
      "[50,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3618,  0.3218,  0.3436,  ..., -0.5476, -0.5241, -0.5373],\n",
      "        [-0.3681, -0.3237, -0.3265,  ...,  0.5345,  0.5664,  0.5439]])\n",
      "rho.1.bias tensor([ 0.2570, -0.2559])\n",
      "train_vars.0 tensor(1.5997)\n",
      "train_vars.1 tensor(2.3699)\n",
      "train_vars.2 tensor(1.7692)\n",
      "train_vars.3 tensor(2.2921)\n",
      "train_vars.4 tensor(1.5775)\n",
      "train_vars.5 tensor(2.3901)\n",
      "train_vars.6 tensor(2.0171)\n",
      "train_vars.7 tensor(2.0790)\n",
      "=====================================\n",
      "[50,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3611,  0.3211,  0.3429,  ..., -0.5486, -0.5251, -0.5383],\n",
      "        [-0.3674, -0.3230, -0.3258,  ...,  0.5356,  0.5675,  0.5450]])\n",
      "rho.1.bias tensor([ 0.2559, -0.2548])\n",
      "train_vars.0 tensor(1.5986)\n",
      "train_vars.1 tensor(2.3709)\n",
      "train_vars.2 tensor(1.7702)\n",
      "train_vars.3 tensor(2.2912)\n",
      "train_vars.4 tensor(1.5764)\n",
      "train_vars.5 tensor(2.3913)\n",
      "train_vars.6 tensor(2.0186)\n",
      "train_vars.7 tensor(2.0776)\n",
      "=====================================\n",
      "[50,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3608,  0.3208,  0.3426,  ..., -0.5493, -0.5259, -0.5391],\n",
      "        [-0.3671, -0.3226, -0.3255,  ...,  0.5363,  0.5682,  0.5457]])\n",
      "rho.1.bias tensor([ 0.2552, -0.2541])\n",
      "train_vars.0 tensor(1.5982)\n",
      "train_vars.1 tensor(2.3714)\n",
      "train_vars.2 tensor(1.7708)\n",
      "train_vars.3 tensor(2.2907)\n",
      "train_vars.4 tensor(1.5758)\n",
      "train_vars.5 tensor(2.3919)\n",
      "train_vars.6 tensor(2.0196)\n",
      "train_vars.7 tensor(2.0766)\n",
      "=====================================\n",
      "[50,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3607,  0.3207,  0.3425,  ..., -0.5498, -0.5264, -0.5396],\n",
      "        [-0.3670, -0.3226, -0.3254,  ...,  0.5368,  0.5687,  0.5462]])\n",
      "rho.1.bias tensor([ 0.2548, -0.2537])\n",
      "train_vars.0 tensor(1.5980)\n",
      "train_vars.1 tensor(2.3715)\n",
      "train_vars.2 tensor(1.7708)\n",
      "train_vars.3 tensor(2.2908)\n",
      "train_vars.4 tensor(1.5757)\n",
      "train_vars.5 tensor(2.3921)\n",
      "train_vars.6 tensor(2.0202)\n",
      "train_vars.7 tensor(2.0761)\n",
      "=====================================\n",
      "[50,     6] loss: 0.541\n",
      "rho.1.weight tensor([[ 0.3604,  0.3204,  0.3422,  ..., -0.5497, -0.5263, -0.5395],\n",
      "        [-0.3667, -0.3223, -0.3251,  ...,  0.5368,  0.5686,  0.5461]])\n",
      "rho.1.bias tensor([ 0.2540, -0.2529])\n",
      "train_vars.0 tensor(1.5976)\n",
      "train_vars.1 tensor(2.3720)\n",
      "train_vars.2 tensor(1.7710)\n",
      "train_vars.3 tensor(2.2906)\n",
      "train_vars.4 tensor(1.5761)\n",
      "train_vars.5 tensor(2.3916)\n",
      "train_vars.6 tensor(2.0201)\n",
      "train_vars.7 tensor(2.0763)\n",
      "=====================================\n",
      "[51,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3605,  0.3205,  0.3422,  ..., -0.5496, -0.5262, -0.5394],\n",
      "        [-0.3667, -0.3223, -0.3252,  ...,  0.5366,  0.5685,  0.5460]])\n",
      "rho.1.bias tensor([ 0.2539, -0.2528])\n",
      "train_vars.0 tensor(1.5976)\n",
      "train_vars.1 tensor(2.3720)\n",
      "train_vars.2 tensor(1.7706)\n",
      "train_vars.3 tensor(2.2911)\n",
      "train_vars.4 tensor(1.5768)\n",
      "train_vars.5 tensor(2.3909)\n",
      "train_vars.6 tensor(2.0199)\n",
      "train_vars.7 tensor(2.0767)\n",
      "=====================================\n",
      "[51,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3611,  0.3211,  0.3429,  ..., -0.5487, -0.5252, -0.5384],\n",
      "        [-0.3674, -0.3230, -0.3258,  ...,  0.5357,  0.5676,  0.5451]])\n",
      "rho.1.bias tensor([ 0.2545, -0.2534])\n",
      "train_vars.0 tensor(1.5985)\n",
      "train_vars.1 tensor(2.3711)\n",
      "train_vars.2 tensor(1.7694)\n",
      "train_vars.3 tensor(2.2924)\n",
      "train_vars.4 tensor(1.5786)\n",
      "train_vars.5 tensor(2.3890)\n",
      "train_vars.6 tensor(2.0185)\n",
      "train_vars.7 tensor(2.0783)\n",
      "=====================================\n",
      "[51,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3604,  0.3204,  0.3422,  ..., -0.5497, -0.5263, -0.5395],\n",
      "        [-0.3667, -0.3222, -0.3251,  ...,  0.5367,  0.5686,  0.5461]])\n",
      "rho.1.bias tensor([ 0.2534, -0.2523])\n",
      "train_vars.0 tensor(1.5975)\n",
      "train_vars.1 tensor(2.3721)\n",
      "train_vars.2 tensor(1.7704)\n",
      "train_vars.3 tensor(2.2914)\n",
      "train_vars.4 tensor(1.5774)\n",
      "train_vars.5 tensor(2.3903)\n",
      "train_vars.6 tensor(2.0199)\n",
      "train_vars.7 tensor(2.0769)\n",
      "=====================================\n",
      "[51,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3601,  0.3201,  0.3419,  ..., -0.5504, -0.5270, -0.5402],\n",
      "        [-0.3664, -0.3219, -0.3248,  ...,  0.5375,  0.5693,  0.5469]])\n",
      "rho.1.bias tensor([ 0.2527, -0.2516])\n",
      "train_vars.0 tensor(1.5970)\n",
      "train_vars.1 tensor(2.3726)\n",
      "train_vars.2 tensor(1.7709)\n",
      "train_vars.3 tensor(2.2910)\n",
      "train_vars.4 tensor(1.5769)\n",
      "train_vars.5 tensor(2.3909)\n",
      "train_vars.6 tensor(2.0209)\n",
      "train_vars.7 tensor(2.0760)\n",
      "=====================================\n",
      "[51,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3600,  0.3200,  0.3418,  ..., -0.5509, -0.5275, -0.5407],\n",
      "        [-0.3663, -0.3219, -0.3247,  ...,  0.5379,  0.5698,  0.5474]])\n",
      "rho.1.bias tensor([ 0.2523, -0.2513])\n",
      "train_vars.0 tensor(1.5969)\n",
      "train_vars.1 tensor(2.3727)\n",
      "train_vars.2 tensor(1.7709)\n",
      "train_vars.3 tensor(2.2911)\n",
      "train_vars.4 tensor(1.5767)\n",
      "train_vars.5 tensor(2.3910)\n",
      "train_vars.6 tensor(2.0216)\n",
      "train_vars.7 tensor(2.0754)\n",
      "=====================================\n",
      "[51,     6] loss: 0.541\n",
      "rho.1.weight tensor([[ 0.3597,  0.3197,  0.3415,  ..., -0.5508, -0.5274, -0.5407],\n",
      "        [-0.3660, -0.3215, -0.3244,  ...,  0.5379,  0.5698,  0.5473]])\n",
      "rho.1.bias tensor([ 0.2515, -0.2505])\n",
      "train_vars.0 tensor(1.5964)\n",
      "train_vars.1 tensor(2.3732)\n",
      "train_vars.2 tensor(1.7712)\n",
      "train_vars.3 tensor(2.2909)\n",
      "train_vars.4 tensor(1.5772)\n",
      "train_vars.5 tensor(2.3906)\n",
      "train_vars.6 tensor(2.0215)\n",
      "train_vars.7 tensor(2.0757)\n",
      "=====================================\n",
      "[52,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3598,  0.3197,  0.3415,  ..., -0.5507, -0.5273, -0.5405],\n",
      "        [-0.3660, -0.3216, -0.3245,  ...,  0.5377,  0.5696,  0.5472]])\n",
      "rho.1.bias tensor([ 0.2514, -0.2504])\n",
      "train_vars.0 tensor(1.5965)\n",
      "train_vars.1 tensor(2.3732)\n",
      "train_vars.2 tensor(1.7707)\n",
      "train_vars.3 tensor(2.2914)\n",
      "train_vars.4 tensor(1.5778)\n",
      "train_vars.5 tensor(2.3899)\n",
      "train_vars.6 tensor(2.0212)\n",
      "train_vars.7 tensor(2.0761)\n",
      "=====================================\n",
      "[52,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3604,  0.3204,  0.3422,  ..., -0.5497, -0.5263, -0.5396],\n",
      "        [-0.3667, -0.3222, -0.3251,  ...,  0.5368,  0.5687,  0.5462]])\n",
      "rho.1.bias tensor([ 0.2520, -0.2510])\n",
      "train_vars.0 tensor(1.5974)\n",
      "train_vars.1 tensor(2.3723)\n",
      "train_vars.2 tensor(1.7695)\n",
      "train_vars.3 tensor(2.2927)\n",
      "train_vars.4 tensor(1.5796)\n",
      "train_vars.5 tensor(2.3880)\n",
      "train_vars.6 tensor(2.0199)\n",
      "train_vars.7 tensor(2.0777)\n",
      "=====================================\n",
      "[52,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3597,  0.3197,  0.3415,  ..., -0.5508, -0.5274, -0.5406],\n",
      "        [-0.3660, -0.3215, -0.3244,  ...,  0.5378,  0.5698,  0.5473]])\n",
      "rho.1.bias tensor([ 0.2509, -0.2499])\n",
      "train_vars.0 tensor(1.5963)\n",
      "train_vars.1 tensor(2.3733)\n",
      "train_vars.2 tensor(1.7705)\n",
      "train_vars.3 tensor(2.2917)\n",
      "train_vars.4 tensor(1.5785)\n",
      "train_vars.5 tensor(2.3892)\n",
      "train_vars.6 tensor(2.0213)\n",
      "train_vars.7 tensor(2.0763)\n",
      "=====================================\n",
      "[52,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3594,  0.3194,  0.3412,  ..., -0.5515, -0.5281, -0.5414],\n",
      "        [-0.3656, -0.3212, -0.3241,  ...,  0.5386,  0.5705,  0.5480]])\n",
      "rho.1.bias tensor([ 0.2502, -0.2492])\n",
      "train_vars.0 tensor(1.5959)\n",
      "train_vars.1 tensor(2.3738)\n",
      "train_vars.2 tensor(1.7711)\n",
      "train_vars.3 tensor(2.2912)\n",
      "train_vars.4 tensor(1.5779)\n",
      "train_vars.5 tensor(2.3898)\n",
      "train_vars.6 tensor(2.0223)\n",
      "train_vars.7 tensor(2.0753)\n",
      "=====================================\n",
      "[52,     5] loss: 0.560\n",
      "rho.1.weight tensor([[ 0.3593,  0.3193,  0.3411,  ..., -0.5520, -0.5286, -0.5419],\n",
      "        [-0.3656, -0.3211, -0.3240,  ...,  0.5391,  0.5710,  0.5485]])\n",
      "rho.1.bias tensor([ 0.2498, -0.2488])\n",
      "train_vars.0 tensor(1.5958)\n",
      "train_vars.1 tensor(2.3739)\n",
      "train_vars.2 tensor(1.7710)\n",
      "train_vars.3 tensor(2.2914)\n",
      "train_vars.4 tensor(1.5778)\n",
      "train_vars.5 tensor(2.3900)\n",
      "train_vars.6 tensor(2.0230)\n",
      "train_vars.7 tensor(2.0748)\n",
      "=====================================\n",
      "[52,     6] loss: 0.541\n",
      "rho.1.weight tensor([[ 0.3590,  0.3190,  0.3408,  ..., -0.5519, -0.5285, -0.5418],\n",
      "        [-0.3653, -0.3208, -0.3237,  ...,  0.5390,  0.5709,  0.5485]])\n",
      "rho.1.bias tensor([ 0.2490, -0.2480])\n",
      "train_vars.0 tensor(1.5953)\n",
      "train_vars.1 tensor(2.3744)\n",
      "train_vars.2 tensor(1.7713)\n",
      "train_vars.3 tensor(2.2912)\n",
      "train_vars.4 tensor(1.5782)\n",
      "train_vars.5 tensor(2.3896)\n",
      "train_vars.6 tensor(2.0229)\n",
      "train_vars.7 tensor(2.0750)\n",
      "=====================================\n",
      "[53,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3590,  0.3190,  0.3408,  ..., -0.5518, -0.5284, -0.5417],\n",
      "        [-0.3653, -0.3209, -0.3237,  ...,  0.5388,  0.5708,  0.5483]])\n",
      "rho.1.bias tensor([ 0.2489, -0.2479])\n",
      "train_vars.0 tensor(1.5953)\n",
      "train_vars.1 tensor(2.3744)\n",
      "train_vars.2 tensor(1.7709)\n",
      "train_vars.3 tensor(2.2917)\n",
      "train_vars.4 tensor(1.5789)\n",
      "train_vars.5 tensor(2.3888)\n",
      "train_vars.6 tensor(2.0226)\n",
      "train_vars.7 tensor(2.0754)\n",
      "=====================================\n",
      "[53,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3597,  0.3197,  0.3415,  ..., -0.5508, -0.5275, -0.5407],\n",
      "        [-0.3659, -0.3215, -0.3244,  ...,  0.5379,  0.5698,  0.5474]])\n",
      "rho.1.bias tensor([ 0.2495, -0.2485])\n",
      "train_vars.0 tensor(1.5962)\n",
      "train_vars.1 tensor(2.3735)\n",
      "train_vars.2 tensor(1.7697)\n",
      "train_vars.3 tensor(2.2930)\n",
      "train_vars.4 tensor(1.5807)\n",
      "train_vars.5 tensor(2.3869)\n",
      "train_vars.6 tensor(2.0212)\n",
      "train_vars.7 tensor(2.0770)\n",
      "=====================================\n",
      "[53,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3590,  0.3190,  0.3408,  ..., -0.5519, -0.5285, -0.5418],\n",
      "        [-0.3652, -0.3208, -0.3237,  ...,  0.5390,  0.5709,  0.5485]])\n",
      "rho.1.bias tensor([ 0.2483, -0.2474])\n",
      "train_vars.0 tensor(1.5952)\n",
      "train_vars.1 tensor(2.3746)\n",
      "train_vars.2 tensor(1.7707)\n",
      "train_vars.3 tensor(2.2920)\n",
      "train_vars.4 tensor(1.5795)\n",
      "train_vars.5 tensor(2.3882)\n",
      "train_vars.6 tensor(2.0227)\n",
      "train_vars.7 tensor(2.0756)\n",
      "=====================================\n",
      "[53,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3587,  0.3187,  0.3404,  ..., -0.5526, -0.5292, -0.5425],\n",
      "        [-0.3649, -0.3205, -0.3234,  ...,  0.5397,  0.5716,  0.5492]])\n",
      "rho.1.bias tensor([ 0.2477, -0.2467])\n",
      "train_vars.0 tensor(1.5947)\n",
      "train_vars.1 tensor(2.3750)\n",
      "train_vars.2 tensor(1.7712)\n",
      "train_vars.3 tensor(2.2915)\n",
      "train_vars.4 tensor(1.5790)\n",
      "train_vars.5 tensor(2.3888)\n",
      "train_vars.6 tensor(2.0237)\n",
      "train_vars.7 tensor(2.0747)\n",
      "=====================================\n",
      "[53,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3586,  0.3186,  0.3404,  ..., -0.5531, -0.5297, -0.5430],\n",
      "        [-0.3648, -0.3204, -0.3233,  ...,  0.5402,  0.5721,  0.5497]])\n",
      "rho.1.bias tensor([ 0.2473, -0.2464])\n",
      "train_vars.0 tensor(1.5946)\n",
      "train_vars.1 tensor(2.3752)\n",
      "train_vars.2 tensor(1.7712)\n",
      "train_vars.3 tensor(2.2917)\n",
      "train_vars.4 tensor(1.5788)\n",
      "train_vars.5 tensor(2.3890)\n",
      "train_vars.6 tensor(2.0243)\n",
      "train_vars.7 tensor(2.0742)\n",
      "=====================================\n",
      "[53,     6] loss: 0.541\n",
      "rho.1.weight tensor([[ 0.3583,  0.3183,  0.3401,  ..., -0.5530, -0.5296, -0.5429],\n",
      "        [-0.3645, -0.3201, -0.3230,  ...,  0.5401,  0.5721,  0.5496]])\n",
      "rho.1.bias tensor([ 0.2465, -0.2456])\n",
      "train_vars.0 tensor(1.5941)\n",
      "train_vars.1 tensor(2.3756)\n",
      "train_vars.2 tensor(1.7715)\n",
      "train_vars.3 tensor(2.2915)\n",
      "train_vars.4 tensor(1.5793)\n",
      "train_vars.5 tensor(2.3885)\n",
      "train_vars.6 tensor(2.0242)\n",
      "train_vars.7 tensor(2.0744)\n",
      "=====================================\n",
      "[54,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3583,  0.3183,  0.3401,  ..., -0.5529, -0.5295, -0.5428],\n",
      "        [-0.3646, -0.3202, -0.3230,  ...,  0.5399,  0.5719,  0.5495]])\n",
      "rho.1.bias tensor([ 0.2463, -0.2455])\n",
      "train_vars.0 tensor(1.5942)\n",
      "train_vars.1 tensor(2.3756)\n",
      "train_vars.2 tensor(1.7710)\n",
      "train_vars.3 tensor(2.2920)\n",
      "train_vars.4 tensor(1.5800)\n",
      "train_vars.5 tensor(2.3878)\n",
      "train_vars.6 tensor(2.0239)\n",
      "train_vars.7 tensor(2.0748)\n",
      "=====================================\n",
      "[54,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3590,  0.3190,  0.3407,  ..., -0.5519, -0.5286, -0.5419],\n",
      "        [-0.3652, -0.3208, -0.3237,  ...,  0.5390,  0.5710,  0.5486]])\n",
      "rho.1.bias tensor([ 0.2470, -0.2461])\n",
      "train_vars.0 tensor(1.5951)\n",
      "train_vars.1 tensor(2.3748)\n",
      "train_vars.2 tensor(1.7698)\n",
      "train_vars.3 tensor(2.2933)\n",
      "train_vars.4 tensor(1.5818)\n",
      "train_vars.5 tensor(2.3859)\n",
      "train_vars.6 tensor(2.0226)\n",
      "train_vars.7 tensor(2.0764)\n",
      "=====================================\n",
      "[54,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3583,  0.3183,  0.3400,  ..., -0.5530, -0.5296, -0.5429],\n",
      "        [-0.3645, -0.3201, -0.3230,  ...,  0.5401,  0.5720,  0.5496]])\n",
      "rho.1.bias tensor([ 0.2458, -0.2450])\n",
      "train_vars.0 tensor(1.5940)\n",
      "train_vars.1 tensor(2.3758)\n",
      "train_vars.2 tensor(1.7708)\n",
      "train_vars.3 tensor(2.2923)\n",
      "train_vars.4 tensor(1.5806)\n",
      "train_vars.5 tensor(2.3872)\n",
      "train_vars.6 tensor(2.0240)\n",
      "train_vars.7 tensor(2.0750)\n",
      "=====================================\n",
      "[54,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3580,  0.3180,  0.3397,  ..., -0.5537, -0.5303, -0.5436],\n",
      "        [-0.3642, -0.3198, -0.3226,  ...,  0.5408,  0.5728,  0.5504]])\n",
      "rho.1.bias tensor([ 0.2452, -0.2443])\n",
      "train_vars.0 tensor(1.5936)\n",
      "train_vars.1 tensor(2.3763)\n",
      "train_vars.2 tensor(1.7714)\n",
      "train_vars.3 tensor(2.2918)\n",
      "train_vars.4 tensor(1.5800)\n",
      "train_vars.5 tensor(2.3878)\n",
      "train_vars.6 tensor(2.0250)\n",
      "train_vars.7 tensor(2.0741)\n",
      "=====================================\n",
      "[54,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3579,  0.3179,  0.3397,  ..., -0.5541, -0.5308, -0.5441],\n",
      "        [-0.3641, -0.3197, -0.3226,  ...,  0.5413,  0.5732,  0.5508]])\n",
      "rho.1.bias tensor([ 0.2448, -0.2439])\n",
      "train_vars.0 tensor(1.5935)\n",
      "train_vars.1 tensor(2.3764)\n",
      "train_vars.2 tensor(1.7713)\n",
      "train_vars.3 tensor(2.2920)\n",
      "train_vars.4 tensor(1.5799)\n",
      "train_vars.5 tensor(2.3879)\n",
      "train_vars.6 tensor(2.0257)\n",
      "train_vars.7 tensor(2.0735)\n",
      "=====================================\n",
      "[54,     6] loss: 0.541\n",
      "rho.1.weight tensor([[ 0.3576,  0.3176,  0.3394,  ..., -0.5541, -0.5307, -0.5441],\n",
      "        [-0.3638, -0.3194, -0.3223,  ...,  0.5412,  0.5732,  0.5508]])\n",
      "rho.1.bias tensor([ 0.2440, -0.2431])\n",
      "train_vars.0 tensor(1.5930)\n",
      "train_vars.1 tensor(2.3768)\n",
      "train_vars.2 tensor(1.7716)\n",
      "train_vars.3 tensor(2.2918)\n",
      "train_vars.4 tensor(1.5803)\n",
      "train_vars.5 tensor(2.3875)\n",
      "train_vars.6 tensor(2.0255)\n",
      "train_vars.7 tensor(2.0738)\n",
      "=====================================\n",
      "[55,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3576,  0.3176,  0.3394,  ..., -0.5539, -0.5306, -0.5439],\n",
      "        [-0.3639, -0.3194, -0.3223,  ...,  0.5410,  0.5730,  0.5506]])\n",
      "rho.1.bias tensor([ 0.2438, -0.2430])\n",
      "train_vars.0 tensor(1.5930)\n",
      "train_vars.1 tensor(2.3768)\n",
      "train_vars.2 tensor(1.7712)\n",
      "train_vars.3 tensor(2.2923)\n",
      "train_vars.4 tensor(1.5810)\n",
      "train_vars.5 tensor(2.3868)\n",
      "train_vars.6 tensor(2.0253)\n",
      "train_vars.7 tensor(2.0742)\n",
      "=====================================\n",
      "[55,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3583,  0.3183,  0.3400,  ..., -0.5530, -0.5297, -0.5430],\n",
      "        [-0.3645, -0.3201, -0.3229,  ...,  0.5401,  0.5721,  0.5497]])\n",
      "rho.1.bias tensor([ 0.2445, -0.2436])\n",
      "train_vars.0 tensor(1.5939)\n",
      "train_vars.1 tensor(2.3760)\n",
      "train_vars.2 tensor(1.7699)\n",
      "train_vars.3 tensor(2.2936)\n",
      "train_vars.4 tensor(1.5828)\n",
      "train_vars.5 tensor(2.3849)\n",
      "train_vars.6 tensor(2.0239)\n",
      "train_vars.7 tensor(2.0758)\n",
      "=====================================\n",
      "[55,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3576,  0.3176,  0.3393,  ..., -0.5540, -0.5307, -0.5441],\n",
      "        [-0.3638, -0.3194, -0.3222,  ...,  0.5412,  0.5732,  0.5508]])\n",
      "rho.1.bias tensor([ 0.2433, -0.2425])\n",
      "train_vars.0 tensor(1.5929)\n",
      "train_vars.1 tensor(2.3770)\n",
      "train_vars.2 tensor(1.7710)\n",
      "train_vars.3 tensor(2.2926)\n",
      "train_vars.4 tensor(1.5816)\n",
      "train_vars.5 tensor(2.3862)\n",
      "train_vars.6 tensor(2.0254)\n",
      "train_vars.7 tensor(2.0744)\n",
      "=====================================\n",
      "[55,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3573,  0.3173,  0.3390,  ..., -0.5547, -0.5314, -0.5448],\n",
      "        [-0.3635, -0.3190, -0.3219,  ...,  0.5419,  0.5739,  0.5515]])\n",
      "rho.1.bias tensor([ 0.2427, -0.2418])\n",
      "train_vars.0 tensor(1.5924)\n",
      "train_vars.1 tensor(2.3775)\n",
      "train_vars.2 tensor(1.7715)\n",
      "train_vars.3 tensor(2.2921)\n",
      "train_vars.4 tensor(1.5810)\n",
      "train_vars.5 tensor(2.3868)\n",
      "train_vars.6 tensor(2.0264)\n",
      "train_vars.7 tensor(2.0735)\n",
      "=====================================\n",
      "[55,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3572,  0.3172,  0.3390,  ..., -0.5552, -0.5319, -0.5452],\n",
      "        [-0.3634, -0.3190, -0.3218,  ...,  0.5424,  0.5744,  0.5520]])\n",
      "rho.1.bias tensor([ 0.2423, -0.2415])\n",
      "train_vars.0 tensor(1.5923)\n",
      "train_vars.1 tensor(2.3776)\n",
      "train_vars.2 tensor(1.7715)\n",
      "train_vars.3 tensor(2.2923)\n",
      "train_vars.4 tensor(1.5809)\n",
      "train_vars.5 tensor(2.3869)\n",
      "train_vars.6 tensor(2.0270)\n",
      "train_vars.7 tensor(2.0729)\n",
      "=====================================\n",
      "[55,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3569,  0.3169,  0.3386,  ..., -0.5552, -0.5318, -0.5452],\n",
      "        [-0.3631, -0.3187, -0.3215,  ...,  0.5423,  0.5743,  0.5519]])\n",
      "rho.1.bias tensor([ 0.2415, -0.2407])\n",
      "train_vars.0 tensor(1.5918)\n",
      "train_vars.1 tensor(2.3781)\n",
      "train_vars.2 tensor(1.7717)\n",
      "train_vars.3 tensor(2.2921)\n",
      "train_vars.4 tensor(1.5814)\n",
      "train_vars.5 tensor(2.3865)\n",
      "train_vars.6 tensor(2.0269)\n",
      "train_vars.7 tensor(2.0732)\n",
      "=====================================\n",
      "[56,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3569,  0.3169,  0.3387,  ..., -0.5550, -0.5317, -0.5450],\n",
      "        [-0.3631, -0.3187, -0.3216,  ...,  0.5421,  0.5741,  0.5518]])\n",
      "rho.1.bias tensor([ 0.2413, -0.2406])\n",
      "train_vars.0 tensor(1.5919)\n",
      "train_vars.1 tensor(2.3780)\n",
      "train_vars.2 tensor(1.7713)\n",
      "train_vars.3 tensor(2.2926)\n",
      "train_vars.4 tensor(1.5820)\n",
      "train_vars.5 tensor(2.3858)\n",
      "train_vars.6 tensor(2.0266)\n",
      "train_vars.7 tensor(2.0736)\n",
      "=====================================\n",
      "[56,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3575,  0.3176,  0.3393,  ..., -0.5541, -0.5308, -0.5441],\n",
      "        [-0.3638, -0.3193, -0.3222,  ...,  0.5412,  0.5732,  0.5509]])\n",
      "rho.1.bias tensor([ 0.2420, -0.2412])\n",
      "train_vars.0 tensor(1.5928)\n",
      "train_vars.1 tensor(2.3772)\n",
      "train_vars.2 tensor(1.7701)\n",
      "train_vars.3 tensor(2.2939)\n",
      "train_vars.4 tensor(1.5838)\n",
      "train_vars.5 tensor(2.3839)\n",
      "train_vars.6 tensor(2.0252)\n",
      "train_vars.7 tensor(2.0752)\n",
      "=====================================\n",
      "[56,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3568,  0.3169,  0.3386,  ..., -0.5551, -0.5318, -0.5452],\n",
      "        [-0.3631, -0.3186, -0.3215,  ...,  0.5423,  0.5743,  0.5519]])\n",
      "rho.1.bias tensor([ 0.2408, -0.2401])\n",
      "train_vars.0 tensor(1.5917)\n",
      "train_vars.1 tensor(2.3782)\n",
      "train_vars.2 tensor(1.7711)\n",
      "train_vars.3 tensor(2.2929)\n",
      "train_vars.4 tensor(1.5826)\n",
      "train_vars.5 tensor(2.3852)\n",
      "train_vars.6 tensor(2.0267)\n",
      "train_vars.7 tensor(2.0738)\n",
      "=====================================\n",
      "[56,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3565,  0.3165,  0.3383,  ..., -0.5558, -0.5325, -0.5459],\n",
      "        [-0.3627, -0.3183, -0.3212,  ...,  0.5430,  0.5750,  0.5527]])\n",
      "rho.1.bias tensor([ 0.2402, -0.2394])\n",
      "train_vars.0 tensor(1.5913)\n",
      "train_vars.1 tensor(2.3787)\n",
      "train_vars.2 tensor(1.7717)\n",
      "train_vars.3 tensor(2.2924)\n",
      "train_vars.4 tensor(1.5821)\n",
      "train_vars.5 tensor(2.3858)\n",
      "train_vars.6 tensor(2.0277)\n",
      "train_vars.7 tensor(2.0728)\n",
      "=====================================\n",
      "[56,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3565,  0.3165,  0.3382,  ..., -0.5563, -0.5330, -0.5464],\n",
      "        [-0.3627, -0.3183, -0.3211,  ...,  0.5435,  0.5755,  0.5531]])\n",
      "rho.1.bias tensor([ 0.2398, -0.2390])\n",
      "train_vars.0 tensor(1.5912)\n",
      "train_vars.1 tensor(2.3788)\n",
      "train_vars.2 tensor(1.7716)\n",
      "train_vars.3 tensor(2.2926)\n",
      "train_vars.4 tensor(1.5820)\n",
      "train_vars.5 tensor(2.3859)\n",
      "train_vars.6 tensor(2.0283)\n",
      "train_vars.7 tensor(2.0723)\n",
      "=====================================\n",
      "[56,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3562,  0.3162,  0.3379,  ..., -0.5562, -0.5329, -0.5463],\n",
      "        [-0.3624, -0.3179, -0.3208,  ...,  0.5434,  0.5754,  0.5531]])\n",
      "rho.1.bias tensor([ 0.2390, -0.2383])\n",
      "train_vars.0 tensor(1.5907)\n",
      "train_vars.1 tensor(2.3793)\n",
      "train_vars.2 tensor(1.7719)\n",
      "train_vars.3 tensor(2.2924)\n",
      "train_vars.4 tensor(1.5824)\n",
      "train_vars.5 tensor(2.3855)\n",
      "train_vars.6 tensor(2.0282)\n",
      "train_vars.7 tensor(2.0726)\n",
      "=====================================\n",
      "[57,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3562,  0.3162,  0.3380,  ..., -0.5561, -0.5328, -0.5462],\n",
      "        [-0.3624, -0.3180, -0.3209,  ...,  0.5432,  0.5753,  0.5529]])\n",
      "rho.1.bias tensor([ 0.2389, -0.2381])\n",
      "train_vars.0 tensor(1.5907)\n",
      "train_vars.1 tensor(2.3792)\n",
      "train_vars.2 tensor(1.7714)\n",
      "train_vars.3 tensor(2.2929)\n",
      "train_vars.4 tensor(1.5831)\n",
      "train_vars.5 tensor(2.3848)\n",
      "train_vars.6 tensor(2.0279)\n",
      "train_vars.7 tensor(2.0730)\n",
      "=====================================\n",
      "[57,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3568,  0.3168,  0.3386,  ..., -0.5551, -0.5319, -0.5452],\n",
      "        [-0.3630, -0.3186, -0.3215,  ...,  0.5423,  0.5743,  0.5520]])\n",
      "rho.1.bias tensor([ 0.2395, -0.2388])\n",
      "train_vars.0 tensor(1.5916)\n",
      "train_vars.1 tensor(2.3784)\n",
      "train_vars.2 tensor(1.7702)\n",
      "train_vars.3 tensor(2.2942)\n",
      "train_vars.4 tensor(1.5848)\n",
      "train_vars.5 tensor(2.3829)\n",
      "train_vars.6 tensor(2.0266)\n",
      "train_vars.7 tensor(2.0746)\n",
      "=====================================\n",
      "[57,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3561,  0.3161,  0.3379,  ..., -0.5562, -0.5329, -0.5463],\n",
      "        [-0.3623, -0.3179, -0.3208,  ...,  0.5434,  0.5754,  0.5531]])\n",
      "rho.1.bias tensor([ 0.2383, -0.2376])\n",
      "train_vars.0 tensor(1.5906)\n",
      "train_vars.1 tensor(2.3794)\n",
      "train_vars.2 tensor(1.7713)\n",
      "train_vars.3 tensor(2.2932)\n",
      "train_vars.4 tensor(1.5837)\n",
      "train_vars.5 tensor(2.3842)\n",
      "train_vars.6 tensor(2.0280)\n",
      "train_vars.7 tensor(2.0732)\n",
      "=====================================\n",
      "[57,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3558,  0.3158,  0.3376,  ..., -0.5569, -0.5336, -0.5470],\n",
      "        [-0.3620, -0.3176, -0.3205,  ...,  0.5441,  0.5761,  0.5538]])\n",
      "rho.1.bias tensor([ 0.2377, -0.2370])\n",
      "train_vars.0 tensor(1.5901)\n",
      "train_vars.1 tensor(2.3799)\n",
      "train_vars.2 tensor(1.7718)\n",
      "train_vars.3 tensor(2.2927)\n",
      "train_vars.4 tensor(1.5831)\n",
      "train_vars.5 tensor(2.3848)\n",
      "train_vars.6 tensor(2.0290)\n",
      "train_vars.7 tensor(2.0722)\n",
      "=====================================\n",
      "[57,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3558,  0.3158,  0.3375,  ..., -0.5573, -0.5341, -0.5475],\n",
      "        [-0.3619, -0.3175, -0.3204,  ...,  0.5445,  0.5766,  0.5543]])\n",
      "rho.1.bias tensor([ 0.2373, -0.2366])\n",
      "train_vars.0 tensor(1.5900)\n",
      "train_vars.1 tensor(2.3800)\n",
      "train_vars.2 tensor(1.7717)\n",
      "train_vars.3 tensor(2.2929)\n",
      "train_vars.4 tensor(1.5830)\n",
      "train_vars.5 tensor(2.3849)\n",
      "train_vars.6 tensor(2.0296)\n",
      "train_vars.7 tensor(2.0717)\n",
      "=====================================\n",
      "[57,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3554,  0.3154,  0.3372,  ..., -0.5573, -0.5340, -0.5474],\n",
      "        [-0.3616, -0.3172, -0.3201,  ...,  0.5445,  0.5765,  0.5542]])\n",
      "rho.1.bias tensor([ 0.2365, -0.2358])\n",
      "train_vars.0 tensor(1.5895)\n",
      "train_vars.1 tensor(2.3805)\n",
      "train_vars.2 tensor(1.7720)\n",
      "train_vars.3 tensor(2.2927)\n",
      "train_vars.4 tensor(1.5834)\n",
      "train_vars.5 tensor(2.3845)\n",
      "train_vars.6 tensor(2.0295)\n",
      "train_vars.7 tensor(2.0720)\n",
      "=====================================\n",
      "[58,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3555,  0.3155,  0.3373,  ..., -0.5571, -0.5339, -0.5473],\n",
      "        [-0.3617, -0.3173, -0.3201,  ...,  0.5443,  0.5764,  0.5541]])\n",
      "rho.1.bias tensor([ 0.2364, -0.2357])\n",
      "train_vars.0 tensor(1.5896)\n",
      "train_vars.1 tensor(2.3805)\n",
      "train_vars.2 tensor(1.7716)\n",
      "train_vars.3 tensor(2.2932)\n",
      "train_vars.4 tensor(1.5841)\n",
      "train_vars.5 tensor(2.3838)\n",
      "train_vars.6 tensor(2.0292)\n",
      "train_vars.7 tensor(2.0724)\n",
      "=====================================\n",
      "[58,     2] loss: 0.530\n",
      "rho.1.weight tensor([[ 0.3561,  0.3161,  0.3379,  ..., -0.5562, -0.5329, -0.5463],\n",
      "        [-0.3623, -0.3179, -0.3208,  ...,  0.5434,  0.5754,  0.5531]])\n",
      "rho.1.bias tensor([ 0.2370, -0.2363])\n",
      "train_vars.0 tensor(1.5904)\n",
      "train_vars.1 tensor(2.3796)\n",
      "train_vars.2 tensor(1.7704)\n",
      "train_vars.3 tensor(2.2945)\n",
      "train_vars.4 tensor(1.5858)\n",
      "train_vars.5 tensor(2.3819)\n",
      "train_vars.6 tensor(2.0279)\n",
      "train_vars.7 tensor(2.0740)\n",
      "=====================================\n",
      "[58,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3554,  0.3154,  0.3372,  ..., -0.5572, -0.5340, -0.5474],\n",
      "        [-0.3616, -0.3172, -0.3200,  ...,  0.5444,  0.5765,  0.5542]])\n",
      "rho.1.bias tensor([ 0.2359, -0.2352])\n",
      "train_vars.0 tensor(1.5894)\n",
      "train_vars.1 tensor(2.3806)\n",
      "train_vars.2 tensor(1.7714)\n",
      "train_vars.3 tensor(2.2935)\n",
      "train_vars.4 tensor(1.5847)\n",
      "train_vars.5 tensor(2.3832)\n",
      "train_vars.6 tensor(2.0293)\n",
      "train_vars.7 tensor(2.0726)\n",
      "=====================================\n",
      "[58,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3551,  0.3151,  0.3369,  ..., -0.5579, -0.5347, -0.5481],\n",
      "        [-0.3613, -0.3169, -0.3197,  ...,  0.5452,  0.5772,  0.5549]])\n",
      "rho.1.bias tensor([ 0.2352, -0.2345])\n",
      "train_vars.0 tensor(1.5889)\n",
      "train_vars.1 tensor(2.3811)\n",
      "train_vars.2 tensor(1.7719)\n",
      "train_vars.3 tensor(2.2930)\n",
      "train_vars.4 tensor(1.5841)\n",
      "train_vars.5 tensor(2.3838)\n",
      "train_vars.6 tensor(2.0303)\n",
      "train_vars.7 tensor(2.0716)\n",
      "=====================================\n",
      "[58,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3550,  0.3150,  0.3368,  ..., -0.5584, -0.5352, -0.5486],\n",
      "        [-0.3612, -0.3168, -0.3197,  ...,  0.5456,  0.5777,  0.5554]])\n",
      "rho.1.bias tensor([ 0.2348, -0.2342])\n",
      "train_vars.0 tensor(1.5888)\n",
      "train_vars.1 tensor(2.3812)\n",
      "train_vars.2 tensor(1.7719)\n",
      "train_vars.3 tensor(2.2932)\n",
      "train_vars.4 tensor(1.5840)\n",
      "train_vars.5 tensor(2.3840)\n",
      "train_vars.6 tensor(2.0309)\n",
      "train_vars.7 tensor(2.0711)\n",
      "=====================================\n",
      "[58,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3547,  0.3147,  0.3365,  ..., -0.5583, -0.5351, -0.5485],\n",
      "        [-0.3609, -0.3165, -0.3194,  ...,  0.5455,  0.5776,  0.5553]])\n",
      "rho.1.bias tensor([ 0.2340, -0.2334])\n",
      "train_vars.0 tensor(1.5884)\n",
      "train_vars.1 tensor(2.3817)\n",
      "train_vars.2 tensor(1.7721)\n",
      "train_vars.3 tensor(2.2929)\n",
      "train_vars.4 tensor(1.5844)\n",
      "train_vars.5 tensor(2.3835)\n",
      "train_vars.6 tensor(2.0308)\n",
      "train_vars.7 tensor(2.0714)\n",
      "=====================================\n",
      "[59,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3548,  0.3148,  0.3365,  ..., -0.5582, -0.5349, -0.5484],\n",
      "        [-0.3609, -0.3165, -0.3194,  ...,  0.5454,  0.5775,  0.5552]])\n",
      "rho.1.bias tensor([ 0.2339, -0.2333])\n",
      "train_vars.0 tensor(1.5884)\n",
      "train_vars.1 tensor(2.3817)\n",
      "train_vars.2 tensor(1.7717)\n",
      "train_vars.3 tensor(2.2935)\n",
      "train_vars.4 tensor(1.5851)\n",
      "train_vars.5 tensor(2.3828)\n",
      "train_vars.6 tensor(2.0305)\n",
      "train_vars.7 tensor(2.0718)\n",
      "=====================================\n",
      "[59,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3554,  0.3154,  0.3372,  ..., -0.5572, -0.5340, -0.5475],\n",
      "        [-0.3616, -0.3172, -0.3200,  ...,  0.5445,  0.5765,  0.5543]])\n",
      "rho.1.bias tensor([ 0.2345, -0.2339])\n",
      "train_vars.0 tensor(1.5893)\n",
      "train_vars.1 tensor(2.3808)\n",
      "train_vars.2 tensor(1.7705)\n",
      "train_vars.3 tensor(2.2948)\n",
      "train_vars.4 tensor(1.5868)\n",
      "train_vars.5 tensor(2.3810)\n",
      "train_vars.6 tensor(2.0292)\n",
      "train_vars.7 tensor(2.0734)\n",
      "=====================================\n",
      "[59,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3547,  0.3147,  0.3365,  ..., -0.5583, -0.5351, -0.5485],\n",
      "        [-0.3609, -0.3164, -0.3193,  ...,  0.5455,  0.5776,  0.5553]])\n",
      "rho.1.bias tensor([ 0.2334, -0.2328])\n",
      "train_vars.0 tensor(1.5883)\n",
      "train_vars.1 tensor(2.3818)\n",
      "train_vars.2 tensor(1.7715)\n",
      "train_vars.3 tensor(2.2938)\n",
      "train_vars.4 tensor(1.5857)\n",
      "train_vars.5 tensor(2.3822)\n",
      "train_vars.6 tensor(2.0306)\n",
      "train_vars.7 tensor(2.0720)\n",
      "=====================================\n",
      "[59,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3544,  0.3144,  0.3362,  ..., -0.5590, -0.5358, -0.5492],\n",
      "        [-0.3605, -0.3161, -0.3190,  ...,  0.5462,  0.5783,  0.5561]])\n",
      "rho.1.bias tensor([ 0.2327, -0.2321])\n",
      "train_vars.0 tensor(1.5878)\n",
      "train_vars.1 tensor(2.3823)\n",
      "train_vars.2 tensor(1.7721)\n",
      "train_vars.3 tensor(2.2933)\n",
      "train_vars.4 tensor(1.5851)\n",
      "train_vars.5 tensor(2.3829)\n",
      "train_vars.6 tensor(2.0316)\n",
      "train_vars.7 tensor(2.0711)\n",
      "=====================================\n",
      "[59,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3543,  0.3143,  0.3361,  ..., -0.5595, -0.5362, -0.5497],\n",
      "        [-0.3605, -0.3161, -0.3189,  ...,  0.5467,  0.5788,  0.5565]])\n",
      "rho.1.bias tensor([ 0.2323, -0.2318])\n",
      "train_vars.0 tensor(1.5877)\n",
      "train_vars.1 tensor(2.3824)\n",
      "train_vars.2 tensor(1.7720)\n",
      "train_vars.3 tensor(2.2935)\n",
      "train_vars.4 tensor(1.5850)\n",
      "train_vars.5 tensor(2.3830)\n",
      "train_vars.6 tensor(2.0322)\n",
      "train_vars.7 tensor(2.0706)\n",
      "=====================================\n",
      "[59,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3540,  0.3140,  0.3358,  ..., -0.5594, -0.5362, -0.5496],\n",
      "        [-0.3602, -0.3158, -0.3186,  ...,  0.5466,  0.5787,  0.5565]])\n",
      "rho.1.bias tensor([ 0.2315, -0.2310])\n",
      "train_vars.0 tensor(1.5872)\n",
      "train_vars.1 tensor(2.3829)\n",
      "train_vars.2 tensor(1.7723)\n",
      "train_vars.3 tensor(2.2932)\n",
      "train_vars.4 tensor(1.5854)\n",
      "train_vars.5 tensor(2.3826)\n",
      "train_vars.6 tensor(2.0321)\n",
      "train_vars.7 tensor(2.0708)\n",
      "=====================================\n",
      "[60,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3540,  0.3140,  0.3358,  ..., -0.5592, -0.5360, -0.5495],\n",
      "        [-0.3602, -0.3158, -0.3187,  ...,  0.5464,  0.5786,  0.5563]])\n",
      "rho.1.bias tensor([ 0.2314, -0.2309])\n",
      "train_vars.0 tensor(1.5873)\n",
      "train_vars.1 tensor(2.3829)\n",
      "train_vars.2 tensor(1.7718)\n",
      "train_vars.3 tensor(2.2937)\n",
      "train_vars.4 tensor(1.5861)\n",
      "train_vars.5 tensor(2.3819)\n",
      "train_vars.6 tensor(2.0318)\n",
      "train_vars.7 tensor(2.0712)\n",
      "=====================================\n",
      "[60,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3547,  0.3147,  0.3364,  ..., -0.5583, -0.5351, -0.5486],\n",
      "        [-0.3608, -0.3164, -0.3193,  ...,  0.5455,  0.5776,  0.5554]])\n",
      "rho.1.bias tensor([ 0.2320, -0.2315])\n",
      "train_vars.0 tensor(1.5881)\n",
      "train_vars.1 tensor(2.3821)\n",
      "train_vars.2 tensor(1.7706)\n",
      "train_vars.3 tensor(2.2951)\n",
      "train_vars.4 tensor(1.5878)\n",
      "train_vars.5 tensor(2.3800)\n",
      "train_vars.6 tensor(2.0305)\n",
      "train_vars.7 tensor(2.0728)\n",
      "=====================================\n",
      "[60,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3540,  0.3140,  0.3357,  ..., -0.5593, -0.5361, -0.5496],\n",
      "        [-0.3601, -0.3157, -0.3186,  ...,  0.5466,  0.5787,  0.5565]])\n",
      "rho.1.bias tensor([ 0.2309, -0.2304])\n",
      "train_vars.0 tensor(1.5871)\n",
      "train_vars.1 tensor(2.3831)\n",
      "train_vars.2 tensor(1.7717)\n",
      "train_vars.3 tensor(2.2941)\n",
      "train_vars.4 tensor(1.5866)\n",
      "train_vars.5 tensor(2.3813)\n",
      "train_vars.6 tensor(2.0319)\n",
      "train_vars.7 tensor(2.0714)\n",
      "=====================================\n",
      "[60,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3537,  0.3137,  0.3354,  ..., -0.5600, -0.5369, -0.5503],\n",
      "        [-0.3598, -0.3154, -0.3183,  ...,  0.5473,  0.5794,  0.5572]])\n",
      "rho.1.bias tensor([ 0.2302, -0.2297])\n",
      "train_vars.0 tensor(1.5866)\n",
      "train_vars.1 tensor(2.3835)\n",
      "train_vars.2 tensor(1.7722)\n",
      "train_vars.3 tensor(2.2936)\n",
      "train_vars.4 tensor(1.5861)\n",
      "train_vars.5 tensor(2.3819)\n",
      "train_vars.6 tensor(2.0329)\n",
      "train_vars.7 tensor(2.0705)\n",
      "=====================================\n",
      "[60,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3536,  0.3136,  0.3354,  ..., -0.5605, -0.5373, -0.5508],\n",
      "        [-0.3598, -0.3153, -0.3182,  ...,  0.5478,  0.5799,  0.5576]])\n",
      "rho.1.bias tensor([ 0.2299, -0.2294])\n",
      "train_vars.0 tensor(1.5865)\n",
      "train_vars.1 tensor(2.3836)\n",
      "train_vars.2 tensor(1.7721)\n",
      "train_vars.3 tensor(2.2938)\n",
      "train_vars.4 tensor(1.5860)\n",
      "train_vars.5 tensor(2.3820)\n",
      "train_vars.6 tensor(2.0335)\n",
      "train_vars.7 tensor(2.0700)\n",
      "=====================================\n",
      "[60,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3533,  0.3133,  0.3351,  ..., -0.5604, -0.5372, -0.5507],\n",
      "        [-0.3594, -0.3150, -0.3179,  ...,  0.5477,  0.5798,  0.5576]])\n",
      "rho.1.bias tensor([ 0.2291, -0.2286])\n",
      "train_vars.0 tensor(1.5861)\n",
      "train_vars.1 tensor(2.3841)\n",
      "train_vars.2 tensor(1.7724)\n",
      "train_vars.3 tensor(2.2935)\n",
      "train_vars.4 tensor(1.5864)\n",
      "train_vars.5 tensor(2.3816)\n",
      "train_vars.6 tensor(2.0334)\n",
      "train_vars.7 tensor(2.0702)\n",
      "=====================================\n",
      "[61,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3533,  0.3133,  0.3351,  ..., -0.5603, -0.5371, -0.5506],\n",
      "        [-0.3595, -0.3151, -0.3179,  ...,  0.5475,  0.5796,  0.5574]])\n",
      "rho.1.bias tensor([ 0.2289, -0.2285])\n",
      "train_vars.0 tensor(1.5861)\n",
      "train_vars.1 tensor(2.3841)\n",
      "train_vars.2 tensor(1.7720)\n",
      "train_vars.3 tensor(2.2940)\n",
      "train_vars.4 tensor(1.5871)\n",
      "train_vars.5 tensor(2.3809)\n",
      "train_vars.6 tensor(2.0331)\n",
      "train_vars.7 tensor(2.0707)\n",
      "=====================================\n",
      "[61,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3539,  0.3139,  0.3357,  ..., -0.5593, -0.5362, -0.5496],\n",
      "        [-0.3601, -0.3157, -0.3186,  ...,  0.5466,  0.5787,  0.5565]])\n",
      "rho.1.bias tensor([ 0.2296, -0.2291])\n",
      "train_vars.0 tensor(1.5870)\n",
      "train_vars.1 tensor(2.3833)\n",
      "train_vars.2 tensor(1.7708)\n",
      "train_vars.3 tensor(2.2954)\n",
      "train_vars.4 tensor(1.5888)\n",
      "train_vars.5 tensor(2.3791)\n",
      "train_vars.6 tensor(2.0317)\n",
      "train_vars.7 tensor(2.0723)\n",
      "=====================================\n",
      "[61,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3532,  0.3132,  0.3350,  ..., -0.5604, -0.5372, -0.5507],\n",
      "        [-0.3594, -0.3150, -0.3178,  ...,  0.5476,  0.5798,  0.5576]])\n",
      "rho.1.bias tensor([ 0.2284, -0.2280])\n",
      "train_vars.0 tensor(1.5859)\n",
      "train_vars.1 tensor(2.3843)\n",
      "train_vars.2 tensor(1.7718)\n",
      "train_vars.3 tensor(2.2944)\n",
      "train_vars.4 tensor(1.5876)\n",
      "train_vars.5 tensor(2.3803)\n",
      "train_vars.6 tensor(2.0332)\n",
      "train_vars.7 tensor(2.0708)\n",
      "=====================================\n",
      "[61,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3529,  0.3129,  0.3347,  ..., -0.5611, -0.5379, -0.5514],\n",
      "        [-0.3591, -0.3147, -0.3175,  ...,  0.5484,  0.5805,  0.5583]])\n",
      "rho.1.bias tensor([ 0.2278, -0.2273])\n",
      "train_vars.0 tensor(1.5855)\n",
      "train_vars.1 tensor(2.3847)\n",
      "train_vars.2 tensor(1.7723)\n",
      "train_vars.3 tensor(2.2939)\n",
      "train_vars.4 tensor(1.5870)\n",
      "train_vars.5 tensor(2.3810)\n",
      "train_vars.6 tensor(2.0342)\n",
      "train_vars.7 tensor(2.0699)\n",
      "=====================================\n",
      "[61,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3529,  0.3129,  0.3347,  ..., -0.5615, -0.5384, -0.5519],\n",
      "        [-0.3590, -0.3146, -0.3175,  ...,  0.5488,  0.5810,  0.5588]])\n",
      "rho.1.bias tensor([ 0.2274, -0.2269])\n",
      "train_vars.0 tensor(1.5854)\n",
      "train_vars.1 tensor(2.3848)\n",
      "train_vars.2 tensor(1.7723)\n",
      "train_vars.3 tensor(2.2940)\n",
      "train_vars.4 tensor(1.5869)\n",
      "train_vars.5 tensor(2.3811)\n",
      "train_vars.6 tensor(2.0348)\n",
      "train_vars.7 tensor(2.0694)\n",
      "=====================================\n",
      "[61,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3526,  0.3126,  0.3343,  ..., -0.5615, -0.5383, -0.5518],\n",
      "        [-0.3587, -0.3143, -0.3172,  ...,  0.5487,  0.5809,  0.5587]])\n",
      "rho.1.bias tensor([ 0.2266, -0.2262])\n",
      "train_vars.0 tensor(1.5849)\n",
      "train_vars.1 tensor(2.3853)\n",
      "train_vars.2 tensor(1.7725)\n",
      "train_vars.3 tensor(2.2938)\n",
      "train_vars.4 tensor(1.5874)\n",
      "train_vars.5 tensor(2.3807)\n",
      "train_vars.6 tensor(2.0347)\n",
      "train_vars.7 tensor(2.0697)\n",
      "=====================================\n",
      "[62,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3526,  0.3126,  0.3344,  ..., -0.5613, -0.5381, -0.5516],\n",
      "        [-0.3588, -0.3143, -0.3172,  ...,  0.5486,  0.5807,  0.5585]])\n",
      "rho.1.bias tensor([ 0.2265, -0.2261])\n",
      "train_vars.0 tensor(1.5849)\n",
      "train_vars.1 tensor(2.3853)\n",
      "train_vars.2 tensor(1.7721)\n",
      "train_vars.3 tensor(2.2943)\n",
      "train_vars.4 tensor(1.5880)\n",
      "train_vars.5 tensor(2.3800)\n",
      "train_vars.6 tensor(2.0344)\n",
      "train_vars.7 tensor(2.0701)\n",
      "=====================================\n",
      "[62,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3532,  0.3132,  0.3350,  ..., -0.5604, -0.5372, -0.5507],\n",
      "        [-0.3594, -0.3150, -0.3178,  ...,  0.5476,  0.5798,  0.5576]])\n",
      "rho.1.bias tensor([ 0.2271, -0.2267])\n",
      "train_vars.0 tensor(1.5858)\n",
      "train_vars.1 tensor(2.3845)\n",
      "train_vars.2 tensor(1.7709)\n",
      "train_vars.3 tensor(2.2956)\n",
      "train_vars.4 tensor(1.5898)\n",
      "train_vars.5 tensor(2.3781)\n",
      "train_vars.6 tensor(2.0330)\n",
      "train_vars.7 tensor(2.0717)\n",
      "=====================================\n",
      "[62,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3525,  0.3125,  0.3343,  ..., -0.5614, -0.5383, -0.5518],\n",
      "        [-0.3587, -0.3142, -0.3171,  ...,  0.5487,  0.5809,  0.5587]])\n",
      "rho.1.bias tensor([ 0.2260, -0.2256])\n",
      "train_vars.0 tensor(1.5848)\n",
      "train_vars.1 tensor(2.3855)\n",
      "train_vars.2 tensor(1.7719)\n",
      "train_vars.3 tensor(2.2947)\n",
      "train_vars.4 tensor(1.5886)\n",
      "train_vars.5 tensor(2.3794)\n",
      "train_vars.6 tensor(2.0345)\n",
      "train_vars.7 tensor(2.0703)\n",
      "=====================================\n",
      "[62,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3522,  0.3122,  0.3340,  ..., -0.5621, -0.5390, -0.5525],\n",
      "        [-0.3583, -0.3139, -0.3168,  ...,  0.5494,  0.5816,  0.5594]])\n",
      "rho.1.bias tensor([ 0.2253, -0.2249])\n",
      "train_vars.0 tensor(1.5843)\n",
      "train_vars.1 tensor(2.3859)\n",
      "train_vars.2 tensor(1.7725)\n",
      "train_vars.3 tensor(2.2942)\n",
      "train_vars.4 tensor(1.5880)\n",
      "train_vars.5 tensor(2.3800)\n",
      "train_vars.6 tensor(2.0355)\n",
      "train_vars.7 tensor(2.0694)\n",
      "=====================================\n",
      "[62,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3522,  0.3122,  0.3339,  ..., -0.5626, -0.5394, -0.5530],\n",
      "        [-0.3583, -0.3139, -0.3167,  ...,  0.5499,  0.5820,  0.5599]])\n",
      "rho.1.bias tensor([ 0.2249, -0.2245])\n",
      "train_vars.0 tensor(1.5842)\n",
      "train_vars.1 tensor(2.3860)\n",
      "train_vars.2 tensor(1.7724)\n",
      "train_vars.3 tensor(2.2943)\n",
      "train_vars.4 tensor(1.5879)\n",
      "train_vars.5 tensor(2.3801)\n",
      "train_vars.6 tensor(2.0360)\n",
      "train_vars.7 tensor(2.0689)\n",
      "=====================================\n",
      "[62,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3518,  0.3118,  0.3336,  ..., -0.5625, -0.5394, -0.5529],\n",
      "        [-0.3580, -0.3136, -0.3164,  ...,  0.5498,  0.5820,  0.5598]])\n",
      "rho.1.bias tensor([ 0.2241, -0.2238])\n",
      "train_vars.0 tensor(1.5838)\n",
      "train_vars.1 tensor(2.3865)\n",
      "train_vars.2 tensor(1.7726)\n",
      "train_vars.3 tensor(2.2941)\n",
      "train_vars.4 tensor(1.5883)\n",
      "train_vars.5 tensor(2.3797)\n",
      "train_vars.6 tensor(2.0359)\n",
      "train_vars.7 tensor(2.0691)\n",
      "=====================================\n",
      "[63,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3519,  0.3119,  0.3337,  ..., -0.5623, -0.5392, -0.5527],\n",
      "        [-0.3580, -0.3136, -0.3165,  ...,  0.5496,  0.5818,  0.5596]])\n",
      "rho.1.bias tensor([ 0.2240, -0.2237])\n",
      "train_vars.0 tensor(1.5838)\n",
      "train_vars.1 tensor(2.3865)\n",
      "train_vars.2 tensor(1.7722)\n",
      "train_vars.3 tensor(2.2946)\n",
      "train_vars.4 tensor(1.5890)\n",
      "train_vars.5 tensor(2.3790)\n",
      "train_vars.6 tensor(2.0356)\n",
      "train_vars.7 tensor(2.0696)\n",
      "=====================================\n",
      "[63,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3525,  0.3125,  0.3343,  ..., -0.5614, -0.5383, -0.5518],\n",
      "        [-0.3586, -0.3142, -0.3171,  ...,  0.5487,  0.5809,  0.5587]])\n",
      "rho.1.bias tensor([ 0.2246, -0.2243])\n",
      "train_vars.0 tensor(1.5846)\n",
      "train_vars.1 tensor(2.3857)\n",
      "train_vars.2 tensor(1.7710)\n",
      "train_vars.3 tensor(2.2959)\n",
      "train_vars.4 tensor(1.5907)\n",
      "train_vars.5 tensor(2.3772)\n",
      "train_vars.6 tensor(2.0343)\n",
      "train_vars.7 tensor(2.0711)\n",
      "=====================================\n",
      "[63,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3518,  0.3118,  0.3336,  ..., -0.5625, -0.5393, -0.5529],\n",
      "        [-0.3579, -0.3135, -0.3164,  ...,  0.5498,  0.5820,  0.5598]])\n",
      "rho.1.bias tensor([ 0.2235, -0.2232])\n",
      "train_vars.0 tensor(1.5836)\n",
      "train_vars.1 tensor(2.3867)\n",
      "train_vars.2 tensor(1.7721)\n",
      "train_vars.3 tensor(2.2949)\n",
      "train_vars.4 tensor(1.5896)\n",
      "train_vars.5 tensor(2.3785)\n",
      "train_vars.6 tensor(2.0357)\n",
      "train_vars.7 tensor(2.0697)\n",
      "=====================================\n",
      "[63,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3515,  0.3115,  0.3333,  ..., -0.5632, -0.5400, -0.5536],\n",
      "        [-0.3576, -0.3132, -0.3161,  ...,  0.5505,  0.5827,  0.5605]])\n",
      "rho.1.bias tensor([ 0.2228, -0.2225])\n",
      "train_vars.0 tensor(1.5832)\n",
      "train_vars.1 tensor(2.3871)\n",
      "train_vars.2 tensor(1.7726)\n",
      "train_vars.3 tensor(2.2945)\n",
      "train_vars.4 tensor(1.5890)\n",
      "train_vars.5 tensor(2.3791)\n",
      "train_vars.6 tensor(2.0367)\n",
      "train_vars.7 tensor(2.0688)\n",
      "=====================================\n",
      "[63,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3514,  0.3114,  0.3332,  ..., -0.5636, -0.5405, -0.5540],\n",
      "        [-0.3576, -0.3131, -0.3160,  ...,  0.5509,  0.5831,  0.5610]])\n",
      "rho.1.bias tensor([ 0.2225, -0.2222])\n",
      "train_vars.0 tensor(1.5831)\n",
      "train_vars.1 tensor(2.3872)\n",
      "train_vars.2 tensor(1.7725)\n",
      "train_vars.3 tensor(2.2946)\n",
      "train_vars.4 tensor(1.5889)\n",
      "train_vars.5 tensor(2.3792)\n",
      "train_vars.6 tensor(2.0373)\n",
      "train_vars.7 tensor(2.0683)\n",
      "=====================================\n",
      "[63,     6] loss: 0.540\n",
      "rho.1.weight tensor([[ 0.3511,  0.3111,  0.3329,  ..., -0.5635, -0.5404, -0.5540],\n",
      "        [-0.3572, -0.3128, -0.3157,  ...,  0.5508,  0.5830,  0.5609]])\n",
      "rho.1.bias tensor([ 0.2217, -0.2214])\n",
      "train_vars.0 tensor(1.5826)\n",
      "train_vars.1 tensor(2.3877)\n",
      "train_vars.2 tensor(1.7728)\n",
      "train_vars.3 tensor(2.2944)\n",
      "train_vars.4 tensor(1.5893)\n",
      "train_vars.5 tensor(2.3788)\n",
      "train_vars.6 tensor(2.0372)\n",
      "train_vars.7 tensor(2.0686)\n",
      "=====================================\n",
      "[64,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3511,  0.3112,  0.3329,  ..., -0.5633, -0.5402, -0.5538],\n",
      "        [-0.3573, -0.3129, -0.3157,  ...,  0.5507,  0.5829,  0.5607]])\n",
      "rho.1.bias tensor([ 0.2216, -0.2213])\n",
      "train_vars.0 tensor(1.5826)\n",
      "train_vars.1 tensor(2.3877)\n",
      "train_vars.2 tensor(1.7723)\n",
      "train_vars.3 tensor(2.2949)\n",
      "train_vars.4 tensor(1.5900)\n",
      "train_vars.5 tensor(2.3781)\n",
      "train_vars.6 tensor(2.0369)\n",
      "train_vars.7 tensor(2.0690)\n",
      "=====================================\n",
      "[64,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3518,  0.3118,  0.3335,  ..., -0.5624, -0.5393, -0.5529],\n",
      "        [-0.3579, -0.3135, -0.3164,  ...,  0.5497,  0.5820,  0.5598]])\n",
      "rho.1.bias tensor([ 0.2222, -0.2219])\n",
      "train_vars.0 tensor(1.5835)\n",
      "train_vars.1 tensor(2.3869)\n",
      "train_vars.2 tensor(1.7712)\n",
      "train_vars.3 tensor(2.2962)\n",
      "train_vars.4 tensor(1.5917)\n",
      "train_vars.5 tensor(2.3763)\n",
      "train_vars.6 tensor(2.0355)\n",
      "train_vars.7 tensor(2.0706)\n",
      "=====================================\n",
      "[64,     3] loss: 0.465\n",
      "rho.1.weight tensor([[ 0.3511,  0.3111,  0.3328,  ..., -0.5635, -0.5404, -0.5540],\n",
      "        [-0.3572, -0.3128, -0.3156,  ...,  0.5508,  0.5830,  0.5609]])\n",
      "rho.1.bias tensor([ 0.2210, -0.2208])\n",
      "train_vars.0 tensor(1.5825)\n",
      "train_vars.1 tensor(2.3879)\n",
      "train_vars.2 tensor(1.7722)\n",
      "train_vars.3 tensor(2.2952)\n",
      "train_vars.4 tensor(1.5905)\n",
      "train_vars.5 tensor(2.3775)\n",
      "train_vars.6 tensor(2.0370)\n",
      "train_vars.7 tensor(2.0692)\n",
      "=====================================\n",
      "[64,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3507,  0.3108,  0.3325,  ..., -0.5642, -0.5411, -0.5547],\n",
      "        [-0.3569, -0.3124, -0.3153,  ...,  0.5515,  0.5838,  0.5616]])\n",
      "rho.1.bias tensor([ 0.2204, -0.2201])\n",
      "train_vars.0 tensor(1.5820)\n",
      "train_vars.1 tensor(2.3883)\n",
      "train_vars.2 tensor(1.7727)\n",
      "train_vars.3 tensor(2.2948)\n",
      "train_vars.4 tensor(1.5899)\n",
      "train_vars.5 tensor(2.3782)\n",
      "train_vars.6 tensor(2.0380)\n",
      "train_vars.7 tensor(2.0683)\n",
      "=====================================\n",
      "[64,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3507,  0.3107,  0.3325,  ..., -0.5646, -0.5415, -0.5551],\n",
      "        [-0.3568, -0.3124, -0.3153,  ...,  0.5519,  0.5842,  0.5621]])\n",
      "rho.1.bias tensor([ 0.2200, -0.2198])\n",
      "train_vars.0 tensor(1.5819)\n",
      "train_vars.1 tensor(2.3884)\n",
      "train_vars.2 tensor(1.7726)\n",
      "train_vars.3 tensor(2.2949)\n",
      "train_vars.4 tensor(1.5898)\n",
      "train_vars.5 tensor(2.3783)\n",
      "train_vars.6 tensor(2.0385)\n",
      "train_vars.7 tensor(2.0678)\n",
      "=====================================\n",
      "[64,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3504,  0.3104,  0.3322,  ..., -0.5645, -0.5415, -0.5550],\n",
      "        [-0.3565, -0.3121, -0.3150,  ...,  0.5519,  0.5841,  0.5620]])\n",
      "rho.1.bias tensor([ 0.2192, -0.2190])\n",
      "train_vars.0 tensor(1.5815)\n",
      "train_vars.1 tensor(2.3889)\n",
      "train_vars.2 tensor(1.7729)\n",
      "train_vars.3 tensor(2.2947)\n",
      "train_vars.4 tensor(1.5902)\n",
      "train_vars.5 tensor(2.3779)\n",
      "train_vars.6 tensor(2.0384)\n",
      "train_vars.7 tensor(2.0681)\n",
      "=====================================\n",
      "[65,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3504,  0.3104,  0.3322,  ..., -0.5644, -0.5413, -0.5549],\n",
      "        [-0.3565, -0.3121, -0.3150,  ...,  0.5517,  0.5839,  0.5618]])\n",
      "rho.1.bias tensor([ 0.2191, -0.2189])\n",
      "train_vars.0 tensor(1.5815)\n",
      "train_vars.1 tensor(2.3889)\n",
      "train_vars.2 tensor(1.7725)\n",
      "train_vars.3 tensor(2.2952)\n",
      "train_vars.4 tensor(1.5909)\n",
      "train_vars.5 tensor(2.3772)\n",
      "train_vars.6 tensor(2.0381)\n",
      "train_vars.7 tensor(2.0685)\n",
      "=====================================\n",
      "[65,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3510,  0.3110,  0.3328,  ..., -0.5634, -0.5404, -0.5540],\n",
      "        [-0.3572, -0.3127, -0.3156,  ...,  0.5508,  0.5830,  0.5609]])\n",
      "rho.1.bias tensor([ 0.2197, -0.2195])\n",
      "train_vars.0 tensor(1.5823)\n",
      "train_vars.1 tensor(2.3881)\n",
      "train_vars.2 tensor(1.7713)\n",
      "train_vars.3 tensor(2.2965)\n",
      "train_vars.4 tensor(1.5926)\n",
      "train_vars.5 tensor(2.3753)\n",
      "train_vars.6 tensor(2.0368)\n",
      "train_vars.7 tensor(2.0701)\n",
      "=====================================\n",
      "[65,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3503,  0.3103,  0.3321,  ..., -0.5645, -0.5414, -0.5550],\n",
      "        [-0.3564, -0.3120, -0.3149,  ...,  0.5518,  0.5841,  0.5620]])\n",
      "rho.1.bias tensor([ 0.2186, -0.2184])\n",
      "train_vars.0 tensor(1.5813)\n",
      "train_vars.1 tensor(2.3891)\n",
      "train_vars.2 tensor(1.7723)\n",
      "train_vars.3 tensor(2.2955)\n",
      "train_vars.4 tensor(1.5914)\n",
      "train_vars.5 tensor(2.3766)\n",
      "train_vars.6 tensor(2.0382)\n",
      "train_vars.7 tensor(2.0687)\n",
      "=====================================\n",
      "[65,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3500,  0.3100,  0.3318,  ..., -0.5652, -0.5421, -0.5557],\n",
      "        [-0.3561, -0.3117, -0.3146,  ...,  0.5526,  0.5848,  0.5627]])\n",
      "rho.1.bias tensor([ 0.2179, -0.2177])\n",
      "train_vars.0 tensor(1.5808)\n",
      "train_vars.1 tensor(2.3895)\n",
      "train_vars.2 tensor(1.7729)\n",
      "train_vars.3 tensor(2.2950)\n",
      "train_vars.4 tensor(1.5908)\n",
      "train_vars.5 tensor(2.3773)\n",
      "train_vars.6 tensor(2.0392)\n",
      "train_vars.7 tensor(2.0677)\n",
      "=====================================\n",
      "[65,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3500,  0.3100,  0.3318,  ..., -0.5656, -0.5426, -0.5562],\n",
      "        [-0.3561, -0.3117, -0.3145,  ...,  0.5530,  0.5852,  0.5631]])\n",
      "rho.1.bias tensor([ 0.2176, -0.2174])\n",
      "train_vars.0 tensor(1.5808)\n",
      "train_vars.1 tensor(2.3896)\n",
      "train_vars.2 tensor(1.7727)\n",
      "train_vars.3 tensor(2.2952)\n",
      "train_vars.4 tensor(1.5908)\n",
      "train_vars.5 tensor(2.3774)\n",
      "train_vars.6 tensor(2.0398)\n",
      "train_vars.7 tensor(2.0673)\n",
      "=====================================\n",
      "[65,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3497,  0.3097,  0.3314,  ..., -0.5656, -0.5425, -0.5561],\n",
      "        [-0.3558, -0.3114, -0.3142,  ...,  0.5529,  0.5852,  0.5631]])\n",
      "rho.1.bias tensor([ 0.2168, -0.2166])\n",
      "train_vars.0 tensor(1.5803)\n",
      "train_vars.1 tensor(2.3901)\n",
      "train_vars.2 tensor(1.7730)\n",
      "train_vars.3 tensor(2.2950)\n",
      "train_vars.4 tensor(1.5912)\n",
      "train_vars.5 tensor(2.3770)\n",
      "train_vars.6 tensor(2.0397)\n",
      "train_vars.7 tensor(2.0675)\n",
      "=====================================\n",
      "[66,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3497,  0.3097,  0.3315,  ..., -0.5654, -0.5423, -0.5559],\n",
      "        [-0.3558, -0.3114, -0.3143,  ...,  0.5527,  0.5850,  0.5629]])\n",
      "rho.1.bias tensor([ 0.2167, -0.2165])\n",
      "train_vars.0 tensor(1.5803)\n",
      "train_vars.1 tensor(2.3901)\n",
      "train_vars.2 tensor(1.7726)\n",
      "train_vars.3 tensor(2.2955)\n",
      "train_vars.4 tensor(1.5919)\n",
      "train_vars.5 tensor(2.3763)\n",
      "train_vars.6 tensor(2.0394)\n",
      "train_vars.7 tensor(2.0680)\n",
      "=====================================\n",
      "[66,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3503,  0.3103,  0.3321,  ..., -0.5645, -0.5414, -0.5550],\n",
      "        [-0.3564, -0.3120, -0.3149,  ...,  0.5518,  0.5841,  0.5620]])\n",
      "rho.1.bias tensor([ 0.2173, -0.2171])\n",
      "train_vars.0 tensor(1.5812)\n",
      "train_vars.1 tensor(2.3893)\n",
      "train_vars.2 tensor(1.7714)\n",
      "train_vars.3 tensor(2.2968)\n",
      "train_vars.4 tensor(1.5936)\n",
      "train_vars.5 tensor(2.3744)\n",
      "train_vars.6 tensor(2.0380)\n",
      "train_vars.7 tensor(2.0696)\n",
      "=====================================\n",
      "[66,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3496,  0.3096,  0.3314,  ..., -0.5655, -0.5425, -0.5561],\n",
      "        [-0.3557, -0.3113, -0.3142,  ...,  0.5529,  0.5851,  0.5631]])\n",
      "rho.1.bias tensor([ 0.2161, -0.2160])\n",
      "train_vars.0 tensor(1.5801)\n",
      "train_vars.1 tensor(2.3903)\n",
      "train_vars.2 tensor(1.7724)\n",
      "train_vars.3 tensor(2.2958)\n",
      "train_vars.4 tensor(1.5924)\n",
      "train_vars.5 tensor(2.3757)\n",
      "train_vars.6 tensor(2.0395)\n",
      "train_vars.7 tensor(2.0681)\n",
      "=====================================\n",
      "[66,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3493,  0.3093,  0.3311,  ..., -0.5662, -0.5432, -0.5568],\n",
      "        [-0.3554, -0.3110, -0.3138,  ...,  0.5536,  0.5859,  0.5638]])\n",
      "rho.1.bias tensor([ 0.2155, -0.2153])\n",
      "train_vars.0 tensor(1.5797)\n",
      "train_vars.1 tensor(2.3907)\n",
      "train_vars.2 tensor(1.7730)\n",
      "train_vars.3 tensor(2.2953)\n",
      "train_vars.4 tensor(1.5918)\n",
      "train_vars.5 tensor(2.3764)\n",
      "train_vars.6 tensor(2.0405)\n",
      "train_vars.7 tensor(2.0672)\n",
      "=====================================\n",
      "[66,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3493,  0.3093,  0.3310,  ..., -0.5666, -0.5436, -0.5572],\n",
      "        [-0.3553, -0.3109, -0.3138,  ...,  0.5540,  0.5863,  0.5642]])\n",
      "rho.1.bias tensor([ 0.2151, -0.2150])\n",
      "train_vars.0 tensor(1.5796)\n",
      "train_vars.1 tensor(2.3908)\n",
      "train_vars.2 tensor(1.7728)\n",
      "train_vars.3 tensor(2.2955)\n",
      "train_vars.4 tensor(1.5917)\n",
      "train_vars.5 tensor(2.3765)\n",
      "train_vars.6 tensor(2.0410)\n",
      "train_vars.7 tensor(2.0668)\n",
      "=====================================\n",
      "[66,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3489,  0.3089,  0.3307,  ..., -0.5666, -0.5435, -0.5572],\n",
      "        [-0.3550, -0.3106, -0.3135,  ...,  0.5539,  0.5862,  0.5641]])\n",
      "rho.1.bias tensor([ 0.2144, -0.2142])\n",
      "train_vars.0 tensor(1.5791)\n",
      "train_vars.1 tensor(2.3913)\n",
      "train_vars.2 tensor(1.7731)\n",
      "train_vars.3 tensor(2.2953)\n",
      "train_vars.4 tensor(1.5921)\n",
      "train_vars.5 tensor(2.3761)\n",
      "train_vars.6 tensor(2.0409)\n",
      "train_vars.7 tensor(2.0670)\n",
      "=====================================\n",
      "[67,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3490,  0.3090,  0.3308,  ..., -0.5664, -0.5434, -0.5570],\n",
      "        [-0.3551, -0.3107, -0.3135,  ...,  0.5537,  0.5860,  0.5640]])\n",
      "rho.1.bias tensor([ 0.2142, -0.2141])\n",
      "train_vars.0 tensor(1.5792)\n",
      "train_vars.1 tensor(2.3913)\n",
      "train_vars.2 tensor(1.7727)\n",
      "train_vars.3 tensor(2.2958)\n",
      "train_vars.4 tensor(1.5928)\n",
      "train_vars.5 tensor(2.3754)\n",
      "train_vars.6 tensor(2.0406)\n",
      "train_vars.7 tensor(2.0675)\n",
      "=====================================\n",
      "[67,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3496,  0.3096,  0.3314,  ..., -0.5655, -0.5424, -0.5561],\n",
      "        [-0.3557, -0.3113, -0.3141,  ...,  0.5528,  0.5851,  0.5631]])\n",
      "rho.1.bias tensor([ 0.2148, -0.2148])\n",
      "train_vars.0 tensor(1.5800)\n",
      "train_vars.1 tensor(2.3905)\n",
      "train_vars.2 tensor(1.7715)\n",
      "train_vars.3 tensor(2.2971)\n",
      "train_vars.4 tensor(1.5945)\n",
      "train_vars.5 tensor(2.3735)\n",
      "train_vars.6 tensor(2.0392)\n",
      "train_vars.7 tensor(2.0690)\n",
      "=====================================\n",
      "[67,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3489,  0.3089,  0.3307,  ..., -0.5665, -0.5435, -0.5572],\n",
      "        [-0.3550, -0.3106, -0.3134,  ...,  0.5539,  0.5862,  0.5641]])\n",
      "rho.1.bias tensor([ 0.2137, -0.2136])\n",
      "train_vars.0 tensor(1.5790)\n",
      "train_vars.1 tensor(2.3915)\n",
      "train_vars.2 tensor(1.7726)\n",
      "train_vars.3 tensor(2.2961)\n",
      "train_vars.4 tensor(1.5933)\n",
      "train_vars.5 tensor(2.3748)\n",
      "train_vars.6 tensor(2.0407)\n",
      "train_vars.7 tensor(2.0676)\n",
      "=====================================\n",
      "[67,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3486,  0.3086,  0.3303,  ..., -0.5672, -0.5442, -0.5579],\n",
      "        [-0.3546, -0.3102, -0.3131,  ...,  0.5546,  0.5869,  0.5649]])\n",
      "rho.1.bias tensor([ 0.2130, -0.2130])\n",
      "train_vars.0 tensor(1.5785)\n",
      "train_vars.1 tensor(2.3919)\n",
      "train_vars.2 tensor(1.7731)\n",
      "train_vars.3 tensor(2.2956)\n",
      "train_vars.4 tensor(1.5927)\n",
      "train_vars.5 tensor(2.3755)\n",
      "train_vars.6 tensor(2.0417)\n",
      "train_vars.7 tensor(2.0667)\n",
      "=====================================\n",
      "[67,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3485,  0.3085,  0.3303,  ..., -0.5676, -0.5446, -0.5583],\n",
      "        [-0.3546, -0.3102, -0.3131,  ...,  0.5550,  0.5873,  0.5653]])\n",
      "rho.1.bias tensor([ 0.2127, -0.2126])\n",
      "train_vars.0 tensor(1.5784)\n",
      "train_vars.1 tensor(2.3920)\n",
      "train_vars.2 tensor(1.7730)\n",
      "train_vars.3 tensor(2.2958)\n",
      "train_vars.4 tensor(1.5926)\n",
      "train_vars.5 tensor(2.3756)\n",
      "train_vars.6 tensor(2.0422)\n",
      "train_vars.7 tensor(2.0663)\n",
      "=====================================\n",
      "[67,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3482,  0.3082,  0.3300,  ..., -0.5676, -0.5446, -0.5582],\n",
      "        [-0.3543, -0.3099, -0.3128,  ...,  0.5550,  0.5873,  0.5652]])\n",
      "rho.1.bias tensor([ 0.2119, -0.2119])\n",
      "train_vars.0 tensor(1.5780)\n",
      "train_vars.1 tensor(2.3925)\n",
      "train_vars.2 tensor(1.7732)\n",
      "train_vars.3 tensor(2.2956)\n",
      "train_vars.4 tensor(1.5930)\n",
      "train_vars.5 tensor(2.3752)\n",
      "train_vars.6 tensor(2.0421)\n",
      "train_vars.7 tensor(2.0665)\n",
      "=====================================\n",
      "[68,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3482,  0.3082,  0.3300,  ..., -0.5674, -0.5444, -0.5581],\n",
      "        [-0.3543, -0.3099, -0.3128,  ...,  0.5548,  0.5871,  0.5650]])\n",
      "rho.1.bias tensor([ 0.2118, -0.2118])\n",
      "train_vars.0 tensor(1.5780)\n",
      "train_vars.1 tensor(2.3924)\n",
      "train_vars.2 tensor(1.7728)\n",
      "train_vars.3 tensor(2.2961)\n",
      "train_vars.4 tensor(1.5937)\n",
      "train_vars.5 tensor(2.3745)\n",
      "train_vars.6 tensor(2.0418)\n",
      "train_vars.7 tensor(2.0670)\n",
      "=====================================\n",
      "[68,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3488,  0.3089,  0.3306,  ..., -0.5665, -0.5435, -0.5572],\n",
      "        [-0.3549, -0.3105, -0.3134,  ...,  0.5538,  0.5862,  0.5641]])\n",
      "rho.1.bias tensor([ 0.2124, -0.2124])\n",
      "train_vars.0 tensor(1.5788)\n",
      "train_vars.1 tensor(2.3917)\n",
      "train_vars.2 tensor(1.7716)\n",
      "train_vars.3 tensor(2.2974)\n",
      "train_vars.4 tensor(1.5954)\n",
      "train_vars.5 tensor(2.3727)\n",
      "train_vars.6 tensor(2.0405)\n",
      "train_vars.7 tensor(2.0685)\n",
      "=====================================\n",
      "[68,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3481,  0.3082,  0.3299,  ..., -0.5675, -0.5445, -0.5582],\n",
      "        [-0.3542, -0.3098, -0.3127,  ...,  0.5549,  0.5872,  0.5652]])\n",
      "rho.1.bias tensor([ 0.2113, -0.2113])\n",
      "train_vars.0 tensor(1.5778)\n",
      "train_vars.1 tensor(2.3927)\n",
      "train_vars.2 tensor(1.7727)\n",
      "train_vars.3 tensor(2.2964)\n",
      "train_vars.4 tensor(1.5942)\n",
      "train_vars.5 tensor(2.3740)\n",
      "train_vars.6 tensor(2.0419)\n",
      "train_vars.7 tensor(2.0671)\n",
      "=====================================\n",
      "[68,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3478,  0.3078,  0.3296,  ..., -0.5682, -0.5452, -0.5589],\n",
      "        [-0.3539, -0.3095, -0.3124,  ...,  0.5556,  0.5880,  0.5659]])\n",
      "rho.1.bias tensor([ 0.2106, -0.2106])\n",
      "train_vars.0 tensor(1.5774)\n",
      "train_vars.1 tensor(2.3931)\n",
      "train_vars.2 tensor(1.7732)\n",
      "train_vars.3 tensor(2.2959)\n",
      "train_vars.4 tensor(1.5936)\n",
      "train_vars.5 tensor(2.3746)\n",
      "train_vars.6 tensor(2.0429)\n",
      "train_vars.7 tensor(2.0662)\n",
      "=====================================\n",
      "[68,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3478,  0.3078,  0.3296,  ..., -0.5686, -0.5457, -0.5594],\n",
      "        [-0.3539, -0.3095, -0.3123,  ...,  0.5560,  0.5884,  0.5664]])\n",
      "rho.1.bias tensor([ 0.2103, -0.2103])\n",
      "train_vars.0 tensor(1.5773)\n",
      "train_vars.1 tensor(2.3932)\n",
      "train_vars.2 tensor(1.7731)\n",
      "train_vars.3 tensor(2.2961)\n",
      "train_vars.4 tensor(1.5936)\n",
      "train_vars.5 tensor(2.3747)\n",
      "train_vars.6 tensor(2.0434)\n",
      "train_vars.7 tensor(2.0658)\n",
      "=====================================\n",
      "[68,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3475,  0.3075,  0.3293,  ..., -0.5686, -0.5456, -0.5593],\n",
      "        [-0.3536, -0.3091, -0.3120,  ...,  0.5560,  0.5883,  0.5663]])\n",
      "rho.1.bias tensor([ 0.2095, -0.2095])\n",
      "train_vars.0 tensor(1.5768)\n",
      "train_vars.1 tensor(2.3936)\n",
      "train_vars.2 tensor(1.7733)\n",
      "train_vars.3 tensor(2.2959)\n",
      "train_vars.4 tensor(1.5940)\n",
      "train_vars.5 tensor(2.3743)\n",
      "train_vars.6 tensor(2.0433)\n",
      "train_vars.7 tensor(2.0660)\n",
      "=====================================\n",
      "[69,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3475,  0.3075,  0.3293,  ..., -0.5684, -0.5454, -0.5591],\n",
      "        [-0.3536, -0.3092, -0.3121,  ...,  0.5558,  0.5881,  0.5661]])\n",
      "rho.1.bias tensor([ 0.2094, -0.2094])\n",
      "train_vars.0 tensor(1.5769)\n",
      "train_vars.1 tensor(2.3936)\n",
      "train_vars.2 tensor(1.7729)\n",
      "train_vars.3 tensor(2.2964)\n",
      "train_vars.4 tensor(1.5946)\n",
      "train_vars.5 tensor(2.3736)\n",
      "train_vars.6 tensor(2.0430)\n",
      "train_vars.7 tensor(2.0665)\n",
      "=====================================\n",
      "[69,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3481,  0.3081,  0.3299,  ..., -0.5675, -0.5445, -0.5582],\n",
      "        [-0.3542, -0.3098, -0.3127,  ...,  0.5549,  0.5872,  0.5652]])\n",
      "rho.1.bias tensor([ 0.2100, -0.2100])\n",
      "train_vars.0 tensor(1.5777)\n",
      "train_vars.1 tensor(2.3929)\n",
      "train_vars.2 tensor(1.7718)\n",
      "train_vars.3 tensor(2.2977)\n",
      "train_vars.4 tensor(1.5963)\n",
      "train_vars.5 tensor(2.3718)\n",
      "train_vars.6 tensor(2.0417)\n",
      "train_vars.7 tensor(2.0680)\n",
      "=====================================\n",
      "[69,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3474,  0.3074,  0.3292,  ..., -0.5685, -0.5456, -0.5593],\n",
      "        [-0.3535, -0.3091, -0.3119,  ...,  0.5559,  0.5883,  0.5663]])\n",
      "rho.1.bias tensor([ 0.2088, -0.2089])\n",
      "train_vars.0 tensor(1.5767)\n",
      "train_vars.1 tensor(2.3938)\n",
      "train_vars.2 tensor(1.7728)\n",
      "train_vars.3 tensor(2.2967)\n",
      "train_vars.4 tensor(1.5951)\n",
      "train_vars.5 tensor(2.3731)\n",
      "train_vars.6 tensor(2.0431)\n",
      "train_vars.7 tensor(2.0666)\n",
      "=====================================\n",
      "[69,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3471,  0.3071,  0.3289,  ..., -0.5692, -0.5463, -0.5600],\n",
      "        [-0.3532, -0.3088, -0.3116,  ...,  0.5566,  0.5890,  0.5670]])\n",
      "rho.1.bias tensor([ 0.2082, -0.2082])\n",
      "train_vars.0 tensor(1.5762)\n",
      "train_vars.1 tensor(2.3943)\n",
      "train_vars.2 tensor(1.7733)\n",
      "train_vars.3 tensor(2.2962)\n",
      "train_vars.4 tensor(1.5945)\n",
      "train_vars.5 tensor(2.3737)\n",
      "train_vars.6 tensor(2.0441)\n",
      "train_vars.7 tensor(2.0657)\n",
      "=====================================\n",
      "[69,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3471,  0.3071,  0.3289,  ..., -0.5696, -0.5467, -0.5604],\n",
      "        [-0.3531, -0.3087, -0.3116,  ...,  0.5571,  0.5894,  0.5674]])\n",
      "rho.1.bias tensor([ 0.2079, -0.2079])\n",
      "train_vars.0 tensor(1.5761)\n",
      "train_vars.1 tensor(2.3944)\n",
      "train_vars.2 tensor(1.7732)\n",
      "train_vars.3 tensor(2.2964)\n",
      "train_vars.4 tensor(1.5945)\n",
      "train_vars.5 tensor(2.3738)\n",
      "train_vars.6 tensor(2.0446)\n",
      "train_vars.7 tensor(2.0653)\n",
      "=====================================\n",
      "[69,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3467,  0.3068,  0.3285,  ..., -0.5696, -0.5466, -0.5603],\n",
      "        [-0.3528, -0.3084, -0.3113,  ...,  0.5570,  0.5893,  0.5673]])\n",
      "rho.1.bias tensor([ 0.2071, -0.2072])\n",
      "train_vars.0 tensor(1.5757)\n",
      "train_vars.1 tensor(2.3948)\n",
      "train_vars.2 tensor(1.7735)\n",
      "train_vars.3 tensor(2.2962)\n",
      "train_vars.4 tensor(1.5949)\n",
      "train_vars.5 tensor(2.3734)\n",
      "train_vars.6 tensor(2.0445)\n",
      "train_vars.7 tensor(2.0655)\n",
      "=====================================\n",
      "[70,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3468,  0.3068,  0.3286,  ..., -0.5694, -0.5464, -0.5601],\n",
      "        [-0.3529, -0.3084, -0.3113,  ...,  0.5568,  0.5891,  0.5672]])\n",
      "rho.1.bias tensor([ 0.2069, -0.2071])\n",
      "train_vars.0 tensor(1.5757)\n",
      "train_vars.1 tensor(2.3948)\n",
      "train_vars.2 tensor(1.7730)\n",
      "train_vars.3 tensor(2.2967)\n",
      "train_vars.4 tensor(1.5955)\n",
      "train_vars.5 tensor(2.3727)\n",
      "train_vars.6 tensor(2.0442)\n",
      "train_vars.7 tensor(2.0660)\n",
      "=====================================\n",
      "[70,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3474,  0.3074,  0.3292,  ..., -0.5685, -0.5455, -0.5592],\n",
      "        [-0.3535, -0.3090, -0.3119,  ...,  0.5559,  0.5882,  0.5663]])\n",
      "rho.1.bias tensor([ 0.2076, -0.2077])\n",
      "train_vars.0 tensor(1.5765)\n",
      "train_vars.1 tensor(2.3940)\n",
      "train_vars.2 tensor(1.7719)\n",
      "train_vars.3 tensor(2.2980)\n",
      "train_vars.4 tensor(1.5972)\n",
      "train_vars.5 tensor(2.3709)\n",
      "train_vars.6 tensor(2.0429)\n",
      "train_vars.7 tensor(2.0675)\n",
      "=====================================\n",
      "[70,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3467,  0.3067,  0.3285,  ..., -0.5695, -0.5466, -0.5603],\n",
      "        [-0.3527, -0.3083, -0.3112,  ...,  0.5569,  0.5893,  0.5673]])\n",
      "rho.1.bias tensor([ 0.2064, -0.2065])\n",
      "train_vars.0 tensor(1.5755)\n",
      "train_vars.1 tensor(2.3950)\n",
      "train_vars.2 tensor(1.7729)\n",
      "train_vars.3 tensor(2.2970)\n",
      "train_vars.4 tensor(1.5960)\n",
      "train_vars.5 tensor(2.3722)\n",
      "train_vars.6 tensor(2.0443)\n",
      "train_vars.7 tensor(2.0661)\n",
      "=====================================\n",
      "[70,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3464,  0.3064,  0.3282,  ..., -0.5702, -0.5473, -0.5610],\n",
      "        [-0.3524, -0.3080, -0.3109,  ...,  0.5577,  0.5900,  0.5681]])\n",
      "rho.1.bias tensor([ 0.2058, -0.2059])\n",
      "train_vars.0 tensor(1.5751)\n",
      "train_vars.1 tensor(2.3955)\n",
      "train_vars.2 tensor(1.7734)\n",
      "train_vars.3 tensor(2.2965)\n",
      "train_vars.4 tensor(1.5954)\n",
      "train_vars.5 tensor(2.3729)\n",
      "train_vars.6 tensor(2.0453)\n",
      "train_vars.7 tensor(2.0652)\n",
      "=====================================\n",
      "[70,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3463,  0.3063,  0.3281,  ..., -0.5706, -0.5477, -0.5614],\n",
      "        [-0.3524, -0.3080, -0.3109,  ...,  0.5581,  0.5904,  0.5685]])\n",
      "rho.1.bias tensor([ 0.2054, -0.2056])\n",
      "train_vars.0 tensor(1.5750)\n",
      "train_vars.1 tensor(2.3956)\n",
      "train_vars.2 tensor(1.7733)\n",
      "train_vars.3 tensor(2.2967)\n",
      "train_vars.4 tensor(1.5954)\n",
      "train_vars.5 tensor(2.3729)\n",
      "train_vars.6 tensor(2.0458)\n",
      "train_vars.7 tensor(2.0648)\n",
      "=====================================\n",
      "[70,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3460,  0.3060,  0.3278,  ..., -0.5705, -0.5476, -0.5614],\n",
      "        [-0.3521, -0.3077, -0.3106,  ...,  0.5580,  0.5904,  0.5684]])\n",
      "rho.1.bias tensor([ 0.2047, -0.2048])\n",
      "train_vars.0 tensor(1.5745)\n",
      "train_vars.1 tensor(2.3960)\n",
      "train_vars.2 tensor(1.7736)\n",
      "train_vars.3 tensor(2.2965)\n",
      "train_vars.4 tensor(1.5958)\n",
      "train_vars.5 tensor(2.3725)\n",
      "train_vars.6 tensor(2.0457)\n",
      "train_vars.7 tensor(2.0650)\n",
      "=====================================\n",
      "[71,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3460,  0.3061,  0.3278,  ..., -0.5704, -0.5474, -0.5612],\n",
      "        [-0.3521, -0.3077, -0.3106,  ...,  0.5578,  0.5902,  0.5682]])\n",
      "rho.1.bias tensor([ 0.2045, -0.2047])\n",
      "train_vars.0 tensor(1.5746)\n",
      "train_vars.1 tensor(2.3960)\n",
      "train_vars.2 tensor(1.7732)\n",
      "train_vars.3 tensor(2.2970)\n",
      "train_vars.4 tensor(1.5964)\n",
      "train_vars.5 tensor(2.3718)\n",
      "train_vars.6 tensor(2.0454)\n",
      "train_vars.7 tensor(2.0655)\n",
      "=====================================\n",
      "[71,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3466,  0.3067,  0.3284,  ..., -0.5694, -0.5465, -0.5603],\n",
      "        [-0.3527, -0.3083, -0.3112,  ...,  0.5569,  0.5893,  0.5673]])\n",
      "rho.1.bias tensor([ 0.2052, -0.2053])\n",
      "train_vars.0 tensor(1.5754)\n",
      "train_vars.1 tensor(2.3952)\n",
      "train_vars.2 tensor(1.7720)\n",
      "train_vars.3 tensor(2.2982)\n",
      "train_vars.4 tensor(1.5981)\n",
      "train_vars.5 tensor(2.3701)\n",
      "train_vars.6 tensor(2.0440)\n",
      "train_vars.7 tensor(2.0671)\n",
      "=====================================\n",
      "[71,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3459,  0.3060,  0.3277,  ..., -0.5705, -0.5476, -0.5613],\n",
      "        [-0.3520, -0.3076, -0.3105,  ...,  0.5579,  0.5903,  0.5684]])\n",
      "rho.1.bias tensor([ 0.2040, -0.2042])\n",
      "train_vars.0 tensor(1.5744)\n",
      "train_vars.1 tensor(2.3962)\n",
      "train_vars.2 tensor(1.7730)\n",
      "train_vars.3 tensor(2.2973)\n",
      "train_vars.4 tensor(1.5969)\n",
      "train_vars.5 tensor(2.3714)\n",
      "train_vars.6 tensor(2.0455)\n",
      "train_vars.7 tensor(2.0656)\n",
      "=====================================\n",
      "[71,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3456,  0.3056,  0.3274,  ..., -0.5712, -0.5483, -0.5621],\n",
      "        [-0.3517, -0.3073, -0.3102,  ...,  0.5587,  0.5911,  0.5691]])\n",
      "rho.1.bias tensor([ 0.2034, -0.2035])\n",
      "train_vars.0 tensor(1.5739)\n",
      "train_vars.1 tensor(2.3967)\n",
      "train_vars.2 tensor(1.7736)\n",
      "train_vars.3 tensor(2.2968)\n",
      "train_vars.4 tensor(1.5963)\n",
      "train_vars.5 tensor(2.3720)\n",
      "train_vars.6 tensor(2.0465)\n",
      "train_vars.7 tensor(2.0647)\n",
      "=====================================\n",
      "[71,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3456,  0.3056,  0.3274,  ..., -0.5716, -0.5487, -0.5625],\n",
      "        [-0.3517, -0.3072, -0.3101,  ...,  0.5591,  0.5915,  0.5695]])\n",
      "rho.1.bias tensor([ 0.2030, -0.2032])\n",
      "train_vars.0 tensor(1.5738)\n",
      "train_vars.1 tensor(2.3967)\n",
      "train_vars.2 tensor(1.7734)\n",
      "train_vars.3 tensor(2.2970)\n",
      "train_vars.4 tensor(1.5963)\n",
      "train_vars.5 tensor(2.3721)\n",
      "train_vars.6 tensor(2.0470)\n",
      "train_vars.7 tensor(2.0643)\n",
      "=====================================\n",
      "[71,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3453,  0.3053,  0.3271,  ..., -0.5715, -0.5486, -0.5624],\n",
      "        [-0.3513, -0.3069, -0.3098,  ...,  0.5590,  0.5914,  0.5694]])\n",
      "rho.1.bias tensor([ 0.2022, -0.2025])\n",
      "train_vars.0 tensor(1.5734)\n",
      "train_vars.1 tensor(2.3972)\n",
      "train_vars.2 tensor(1.7737)\n",
      "train_vars.3 tensor(2.2968)\n",
      "train_vars.4 tensor(1.5967)\n",
      "train_vars.5 tensor(2.3717)\n",
      "train_vars.6 tensor(2.0469)\n",
      "train_vars.7 tensor(2.0646)\n",
      "=====================================\n",
      "[72,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3453,  0.3053,  0.3271,  ..., -0.5713, -0.5484, -0.5622],\n",
      "        [-0.3514, -0.3070, -0.3099,  ...,  0.5588,  0.5912,  0.5693]])\n",
      "rho.1.bias tensor([ 0.2021, -0.2024])\n",
      "train_vars.0 tensor(1.5734)\n",
      "train_vars.1 tensor(2.3972)\n",
      "train_vars.2 tensor(1.7733)\n",
      "train_vars.3 tensor(2.2973)\n",
      "train_vars.4 tensor(1.5973)\n",
      "train_vars.5 tensor(2.3710)\n",
      "train_vars.6 tensor(2.0466)\n",
      "train_vars.7 tensor(2.0650)\n",
      "=====================================\n",
      "[72,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3459,  0.3059,  0.3277,  ..., -0.5704, -0.5475, -0.5613],\n",
      "        [-0.3520, -0.3076, -0.3104,  ...,  0.5579,  0.5903,  0.5684]])\n",
      "rho.1.bias tensor([ 0.2027, -0.2030])\n",
      "train_vars.0 tensor(1.5742)\n",
      "train_vars.1 tensor(2.3964)\n",
      "train_vars.2 tensor(1.7721)\n",
      "train_vars.3 tensor(2.2985)\n",
      "train_vars.4 tensor(1.5990)\n",
      "train_vars.5 tensor(2.3692)\n",
      "train_vars.6 tensor(2.0452)\n",
      "train_vars.7 tensor(2.0666)\n",
      "=====================================\n",
      "[72,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3452,  0.3052,  0.3270,  ..., -0.5715, -0.5486, -0.5624],\n",
      "        [-0.3513, -0.3069, -0.3097,  ...,  0.5589,  0.5914,  0.5694]])\n",
      "rho.1.bias tensor([ 0.2016, -0.2018])\n",
      "train_vars.0 tensor(1.5732)\n",
      "train_vars.1 tensor(2.3974)\n",
      "train_vars.2 tensor(1.7731)\n",
      "train_vars.3 tensor(2.2975)\n",
      "train_vars.4 tensor(1.5978)\n",
      "train_vars.5 tensor(2.3705)\n",
      "train_vars.6 tensor(2.0467)\n",
      "train_vars.7 tensor(2.0652)\n",
      "=====================================\n",
      "[72,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3449,  0.3049,  0.3267,  ..., -0.5722, -0.5493, -0.5631],\n",
      "        [-0.3509, -0.3065, -0.3094,  ...,  0.5596,  0.5921,  0.5702]])\n",
      "rho.1.bias tensor([ 0.2009, -0.2012])\n",
      "train_vars.0 tensor(1.5727)\n",
      "train_vars.1 tensor(2.3978)\n",
      "train_vars.2 tensor(1.7737)\n",
      "train_vars.3 tensor(2.2971)\n",
      "train_vars.4 tensor(1.5972)\n",
      "train_vars.5 tensor(2.3712)\n",
      "train_vars.6 tensor(2.0477)\n",
      "train_vars.7 tensor(2.0643)\n",
      "=====================================\n",
      "[72,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3449,  0.3049,  0.3267,  ..., -0.5726, -0.5497, -0.5635],\n",
      "        [-0.3509, -0.3065, -0.3094,  ...,  0.5600,  0.5925,  0.5706]])\n",
      "rho.1.bias tensor([ 0.2006, -0.2009])\n",
      "train_vars.0 tensor(1.5727)\n",
      "train_vars.1 tensor(2.3979)\n",
      "train_vars.2 tensor(1.7735)\n",
      "train_vars.3 tensor(2.2973)\n",
      "train_vars.4 tensor(1.5971)\n",
      "train_vars.5 tensor(2.3712)\n",
      "train_vars.6 tensor(2.0482)\n",
      "train_vars.7 tensor(2.0638)\n",
      "=====================================\n",
      "[72,     6] loss: 0.539\n",
      "rho.1.weight tensor([[ 0.3446,  0.3046,  0.3264,  ..., -0.5725, -0.5496, -0.5634],\n",
      "        [-0.3506, -0.3062, -0.3091,  ...,  0.5600,  0.5924,  0.5705]])\n",
      "rho.1.bias tensor([ 0.1998, -0.2001])\n",
      "train_vars.0 tensor(1.5722)\n",
      "train_vars.1 tensor(2.3984)\n",
      "train_vars.2 tensor(1.7738)\n",
      "train_vars.3 tensor(2.2971)\n",
      "train_vars.4 tensor(1.5975)\n",
      "train_vars.5 tensor(2.3708)\n",
      "train_vars.6 tensor(2.0480)\n",
      "train_vars.7 tensor(2.0641)\n",
      "=====================================\n",
      "[73,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3446,  0.3046,  0.3264,  ..., -0.5723, -0.5494, -0.5632],\n",
      "        [-0.3506, -0.3062, -0.3091,  ...,  0.5598,  0.5922,  0.5703]])\n",
      "rho.1.bias tensor([ 0.1997, -0.2000])\n",
      "train_vars.0 tensor(1.5723)\n",
      "train_vars.1 tensor(2.3984)\n",
      "train_vars.2 tensor(1.7734)\n",
      "train_vars.3 tensor(2.2976)\n",
      "train_vars.4 tensor(1.5982)\n",
      "train_vars.5 tensor(2.3701)\n",
      "train_vars.6 tensor(2.0477)\n",
      "train_vars.7 tensor(2.0646)\n",
      "=====================================\n",
      "[73,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3452,  0.3052,  0.3270,  ..., -0.5714, -0.5485, -0.5623],\n",
      "        [-0.3512, -0.3068, -0.3097,  ...,  0.5588,  0.5913,  0.5694]])\n",
      "rho.1.bias tensor([ 0.2003, -0.2007])\n",
      "train_vars.0 tensor(1.5731)\n",
      "train_vars.1 tensor(2.3976)\n",
      "train_vars.2 tensor(1.7722)\n",
      "train_vars.3 tensor(2.2988)\n",
      "train_vars.4 tensor(1.5999)\n",
      "train_vars.5 tensor(2.3684)\n",
      "train_vars.6 tensor(2.0464)\n",
      "train_vars.7 tensor(2.0661)\n",
      "=====================================\n",
      "[73,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3445,  0.3045,  0.3263,  ..., -0.5725, -0.5496, -0.5634],\n",
      "        [-0.3505, -0.3061, -0.3090,  ...,  0.5599,  0.5924,  0.5705]])\n",
      "rho.1.bias tensor([ 0.1992, -0.1995])\n",
      "train_vars.0 tensor(1.5721)\n",
      "train_vars.1 tensor(2.3986)\n",
      "train_vars.2 tensor(1.7733)\n",
      "train_vars.3 tensor(2.2978)\n",
      "train_vars.4 tensor(1.5987)\n",
      "train_vars.5 tensor(2.3697)\n",
      "train_vars.6 tensor(2.0479)\n",
      "train_vars.7 tensor(2.0647)\n",
      "=====================================\n",
      "[73,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3442,  0.3042,  0.3260,  ..., -0.5732, -0.5503, -0.5641],\n",
      "        [-0.3502, -0.3058, -0.3087,  ...,  0.5606,  0.5931,  0.5712]])\n",
      "rho.1.bias tensor([ 0.1985, -0.1989])\n",
      "train_vars.0 tensor(1.5716)\n",
      "train_vars.1 tensor(2.3990)\n",
      "train_vars.2 tensor(1.7738)\n",
      "train_vars.3 tensor(2.2974)\n",
      "train_vars.4 tensor(1.5981)\n",
      "train_vars.5 tensor(2.3703)\n",
      "train_vars.6 tensor(2.0488)\n",
      "train_vars.7 tensor(2.0638)\n",
      "=====================================\n",
      "[73,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3441,  0.3042,  0.3259,  ..., -0.5736, -0.5507, -0.5645],\n",
      "        [-0.3502, -0.3058, -0.3087,  ...,  0.5610,  0.5935,  0.5716]])\n",
      "rho.1.bias tensor([ 0.1982, -0.1986])\n",
      "train_vars.0 tensor(1.5715)\n",
      "train_vars.1 tensor(2.3991)\n",
      "train_vars.2 tensor(1.7736)\n",
      "train_vars.3 tensor(2.2976)\n",
      "train_vars.4 tensor(1.5980)\n",
      "train_vars.5 tensor(2.3704)\n",
      "train_vars.6 tensor(2.0493)\n",
      "train_vars.7 tensor(2.0634)\n",
      "=====================================\n",
      "[73,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3438,  0.3038,  0.3256,  ..., -0.5735, -0.5506, -0.5644],\n",
      "        [-0.3499, -0.3055, -0.3083,  ...,  0.5609,  0.5934,  0.5715]])\n",
      "rho.1.bias tensor([ 0.1974, -0.1978])\n",
      "train_vars.0 tensor(1.5711)\n",
      "train_vars.1 tensor(2.3995)\n",
      "train_vars.2 tensor(1.7739)\n",
      "train_vars.3 tensor(2.2974)\n",
      "train_vars.4 tensor(1.5984)\n",
      "train_vars.5 tensor(2.3700)\n",
      "train_vars.6 tensor(2.0492)\n",
      "train_vars.7 tensor(2.0637)\n",
      "=====================================\n",
      "[74,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3439,  0.3039,  0.3257,  ..., -0.5733, -0.5504, -0.5643],\n",
      "        [-0.3499, -0.3055, -0.3084,  ...,  0.5607,  0.5932,  0.5713]])\n",
      "rho.1.bias tensor([ 0.1973, -0.1977])\n",
      "train_vars.0 tensor(1.5711)\n",
      "train_vars.1 tensor(2.3995)\n",
      "train_vars.2 tensor(1.7735)\n",
      "train_vars.3 tensor(2.2978)\n",
      "train_vars.4 tensor(1.5991)\n",
      "train_vars.5 tensor(2.3693)\n",
      "train_vars.6 tensor(2.0489)\n",
      "train_vars.7 tensor(2.0641)\n",
      "=====================================\n",
      "[74,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3444,  0.3045,  0.3262,  ..., -0.5724, -0.5495, -0.5634],\n",
      "        [-0.3505, -0.3061, -0.3090,  ...,  0.5598,  0.5923,  0.5704]])\n",
      "rho.1.bias tensor([ 0.1979, -0.1983])\n",
      "train_vars.0 tensor(1.5719)\n",
      "train_vars.1 tensor(2.3988)\n",
      "train_vars.2 tensor(1.7723)\n",
      "train_vars.3 tensor(2.2991)\n",
      "train_vars.4 tensor(1.6007)\n",
      "train_vars.5 tensor(2.3675)\n",
      "train_vars.6 tensor(2.0475)\n",
      "train_vars.7 tensor(2.0657)\n",
      "=====================================\n",
      "[74,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3437,  0.3038,  0.3255,  ..., -0.5734, -0.5506, -0.5644],\n",
      "        [-0.3498, -0.3054, -0.3083,  ...,  0.5609,  0.5934,  0.5715]])\n",
      "rho.1.bias tensor([ 0.1968, -0.1972])\n",
      "train_vars.0 tensor(1.5709)\n",
      "train_vars.1 tensor(2.3997)\n",
      "train_vars.2 tensor(1.7734)\n",
      "train_vars.3 tensor(2.2981)\n",
      "train_vars.4 tensor(1.5995)\n",
      "train_vars.5 tensor(2.3689)\n",
      "train_vars.6 tensor(2.0490)\n",
      "train_vars.7 tensor(2.0642)\n",
      "=====================================\n",
      "[74,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3434,  0.3035,  0.3252,  ..., -0.5741, -0.5513, -0.5651],\n",
      "        [-0.3495, -0.3051, -0.3079,  ...,  0.5616,  0.5941,  0.5722]])\n",
      "rho.1.bias tensor([ 0.1961, -0.1965])\n",
      "train_vars.0 tensor(1.5704)\n",
      "train_vars.1 tensor(2.4002)\n",
      "train_vars.2 tensor(1.7739)\n",
      "train_vars.3 tensor(2.2976)\n",
      "train_vars.4 tensor(1.5989)\n",
      "train_vars.5 tensor(2.3695)\n",
      "train_vars.6 tensor(2.0500)\n",
      "train_vars.7 tensor(2.0633)\n",
      "=====================================\n",
      "[74,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3434,  0.3034,  0.3252,  ..., -0.5745, -0.5517, -0.5655],\n",
      "        [-0.3494, -0.3050, -0.3079,  ...,  0.5620,  0.5945,  0.5726]])\n",
      "rho.1.bias tensor([ 0.1958, -0.1962])\n",
      "train_vars.0 tensor(1.5704)\n",
      "train_vars.1 tensor(2.4002)\n",
      "train_vars.2 tensor(1.7737)\n",
      "train_vars.3 tensor(2.2979)\n",
      "train_vars.4 tensor(1.5989)\n",
      "train_vars.5 tensor(2.3696)\n",
      "train_vars.6 tensor(2.0505)\n",
      "train_vars.7 tensor(2.0629)\n",
      "=====================================\n",
      "[74,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3431,  0.3031,  0.3249,  ..., -0.5744, -0.5516, -0.5655],\n",
      "        [-0.3491, -0.3047, -0.3076,  ...,  0.5619,  0.5944,  0.5725]])\n",
      "rho.1.bias tensor([ 0.1951, -0.1955])\n",
      "train_vars.0 tensor(1.5699)\n",
      "train_vars.1 tensor(2.4007)\n",
      "train_vars.2 tensor(1.7740)\n",
      "train_vars.3 tensor(2.2977)\n",
      "train_vars.4 tensor(1.5993)\n",
      "train_vars.5 tensor(2.3692)\n",
      "train_vars.6 tensor(2.0503)\n",
      "train_vars.7 tensor(2.0632)\n",
      "=====================================\n",
      "[75,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3431,  0.3031,  0.3249,  ..., -0.5742, -0.5514, -0.5653],\n",
      "        [-0.3492, -0.3048, -0.3076,  ...,  0.5617,  0.5942,  0.5724]])\n",
      "rho.1.bias tensor([ 0.1949, -0.1954])\n",
      "train_vars.0 tensor(1.5700)\n",
      "train_vars.1 tensor(2.4007)\n",
      "train_vars.2 tensor(1.7736)\n",
      "train_vars.3 tensor(2.2981)\n",
      "train_vars.4 tensor(1.5999)\n",
      "train_vars.5 tensor(2.3685)\n",
      "train_vars.6 tensor(2.0500)\n",
      "train_vars.7 tensor(2.0637)\n",
      "=====================================\n",
      "[75,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3437,  0.3037,  0.3255,  ..., -0.5733, -0.5505, -0.5644],\n",
      "        [-0.3498, -0.3053, -0.3082,  ...,  0.5608,  0.5933,  0.5715]])\n",
      "rho.1.bias tensor([ 0.1956, -0.1960])\n",
      "train_vars.0 tensor(1.5708)\n",
      "train_vars.1 tensor(2.3999)\n",
      "train_vars.2 tensor(1.7724)\n",
      "train_vars.3 tensor(2.2994)\n",
      "train_vars.4 tensor(1.6016)\n",
      "train_vars.5 tensor(2.3667)\n",
      "train_vars.6 tensor(2.0487)\n",
      "train_vars.7 tensor(2.0652)\n",
      "=====================================\n",
      "[75,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3430,  0.3030,  0.3248,  ..., -0.5744, -0.5516, -0.5654],\n",
      "        [-0.3490, -0.3046, -0.3075,  ...,  0.5619,  0.5944,  0.5725]])\n",
      "rho.1.bias tensor([ 0.1944, -0.1948])\n",
      "train_vars.0 tensor(1.5698)\n",
      "train_vars.1 tensor(2.4009)\n",
      "train_vars.2 tensor(1.7735)\n",
      "train_vars.3 tensor(2.2984)\n",
      "train_vars.4 tensor(1.6004)\n",
      "train_vars.5 tensor(2.3680)\n",
      "train_vars.6 tensor(2.0502)\n",
      "train_vars.7 tensor(2.0638)\n",
      "=====================================\n",
      "[75,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3427,  0.3027,  0.3245,  ..., -0.5751, -0.5523, -0.5662],\n",
      "        [-0.3487, -0.3043, -0.3072,  ...,  0.5626,  0.5951,  0.5733]])\n",
      "rho.1.bias tensor([ 0.1938, -0.1942])\n",
      "train_vars.0 tensor(1.5693)\n",
      "train_vars.1 tensor(2.4014)\n",
      "train_vars.2 tensor(1.7740)\n",
      "train_vars.3 tensor(2.2979)\n",
      "train_vars.4 tensor(1.5998)\n",
      "train_vars.5 tensor(2.3687)\n",
      "train_vars.6 tensor(2.0511)\n",
      "train_vars.7 tensor(2.0629)\n",
      "=====================================\n",
      "[75,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3427,  0.3027,  0.3245,  ..., -0.5755, -0.5527, -0.5666],\n",
      "        [-0.3487, -0.3043, -0.3072,  ...,  0.5630,  0.5955,  0.5737]])\n",
      "rho.1.bias tensor([ 0.1935, -0.1939])\n",
      "train_vars.0 tensor(1.5693)\n",
      "train_vars.1 tensor(2.4014)\n",
      "train_vars.2 tensor(1.7738)\n",
      "train_vars.3 tensor(2.2982)\n",
      "train_vars.4 tensor(1.5997)\n",
      "train_vars.5 tensor(2.3687)\n",
      "train_vars.6 tensor(2.0516)\n",
      "train_vars.7 tensor(2.0625)\n",
      "=====================================\n",
      "[75,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3424,  0.3024,  0.3242,  ..., -0.5754, -0.5526, -0.5665],\n",
      "        [-0.3484, -0.3040, -0.3069,  ...,  0.5629,  0.5954,  0.5736]])\n",
      "rho.1.bias tensor([ 0.1927, -0.1931])\n",
      "train_vars.0 tensor(1.5688)\n",
      "train_vars.1 tensor(2.4019)\n",
      "train_vars.2 tensor(1.7741)\n",
      "train_vars.3 tensor(2.2980)\n",
      "train_vars.4 tensor(1.6001)\n",
      "train_vars.5 tensor(2.3683)\n",
      "train_vars.6 tensor(2.0515)\n",
      "train_vars.7 tensor(2.0628)\n",
      "=====================================\n",
      "[76,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3424,  0.3024,  0.3242,  ..., -0.5752, -0.5524, -0.5663],\n",
      "        [-0.3484, -0.3040, -0.3069,  ...,  0.5627,  0.5952,  0.5734]])\n",
      "rho.1.bias tensor([ 0.1925, -0.1930])\n",
      "train_vars.0 tensor(1.5688)\n",
      "train_vars.1 tensor(2.4019)\n",
      "train_vars.2 tensor(1.7737)\n",
      "train_vars.3 tensor(2.2984)\n",
      "train_vars.4 tensor(1.6008)\n",
      "train_vars.5 tensor(2.3677)\n",
      "train_vars.6 tensor(2.0512)\n",
      "train_vars.7 tensor(2.0632)\n",
      "=====================================\n",
      "[76,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3430,  0.3030,  0.3248,  ..., -0.5743, -0.5515, -0.5654],\n",
      "        [-0.3490, -0.3046, -0.3075,  ...,  0.5618,  0.5943,  0.5725]])\n",
      "rho.1.bias tensor([ 0.1932, -0.1937])\n",
      "train_vars.0 tensor(1.5696)\n",
      "train_vars.1 tensor(2.4011)\n",
      "train_vars.2 tensor(1.7725)\n",
      "train_vars.3 tensor(2.2997)\n",
      "train_vars.4 tensor(1.6025)\n",
      "train_vars.5 tensor(2.3659)\n",
      "train_vars.6 tensor(2.0498)\n",
      "train_vars.7 tensor(2.0648)\n",
      "=====================================\n",
      "[76,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3423,  0.3023,  0.3241,  ..., -0.5753, -0.5526, -0.5665],\n",
      "        [-0.3483, -0.3039, -0.3068,  ...,  0.5629,  0.5954,  0.5736]])\n",
      "rho.1.bias tensor([ 0.1920, -0.1925])\n",
      "train_vars.0 tensor(1.5686)\n",
      "train_vars.1 tensor(2.4021)\n",
      "train_vars.2 tensor(1.7736)\n",
      "train_vars.3 tensor(2.2987)\n",
      "train_vars.4 tensor(1.6012)\n",
      "train_vars.5 tensor(2.3672)\n",
      "train_vars.6 tensor(2.0513)\n",
      "train_vars.7 tensor(2.0633)\n",
      "=====================================\n",
      "[76,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3420,  0.3020,  0.3238,  ..., -0.5760, -0.5533, -0.5672],\n",
      "        [-0.3480, -0.3036, -0.3065,  ...,  0.5636,  0.5961,  0.5743]])\n",
      "rho.1.bias tensor([ 0.1914, -0.1919])\n",
      "train_vars.0 tensor(1.5682)\n",
      "train_vars.1 tensor(2.4025)\n",
      "train_vars.2 tensor(1.7741)\n",
      "train_vars.3 tensor(2.2982)\n",
      "train_vars.4 tensor(1.6006)\n",
      "train_vars.5 tensor(2.3679)\n",
      "train_vars.6 tensor(2.0523)\n",
      "train_vars.7 tensor(2.0625)\n",
      "=====================================\n",
      "[76,     5] loss: 0.559\n",
      "rho.1.weight tensor([[ 0.3420,  0.3020,  0.3238,  ..., -0.5764, -0.5537, -0.5676],\n",
      "        [-0.3480, -0.3036, -0.3064,  ...,  0.5639,  0.5965,  0.5747]])\n",
      "rho.1.bias tensor([ 0.1911, -0.1916])\n",
      "train_vars.0 tensor(1.5681)\n",
      "train_vars.1 tensor(2.4026)\n",
      "train_vars.2 tensor(1.7739)\n",
      "train_vars.3 tensor(2.2985)\n",
      "train_vars.4 tensor(1.6006)\n",
      "train_vars.5 tensor(2.3679)\n",
      "train_vars.6 tensor(2.0528)\n",
      "train_vars.7 tensor(2.0621)\n",
      "=====================================\n",
      "[76,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3416,  0.3017,  0.3234,  ..., -0.5763, -0.5536, -0.5675],\n",
      "        [-0.3477, -0.3033, -0.3061,  ...,  0.5639,  0.5964,  0.5746]])\n",
      "rho.1.bias tensor([ 0.1903, -0.1908])\n",
      "train_vars.0 tensor(1.5677)\n",
      "train_vars.1 tensor(2.4030)\n",
      "train_vars.2 tensor(1.7742)\n",
      "train_vars.3 tensor(2.2982)\n",
      "train_vars.4 tensor(1.6010)\n",
      "train_vars.5 tensor(2.3675)\n",
      "train_vars.6 tensor(2.0526)\n",
      "train_vars.7 tensor(2.0623)\n",
      "=====================================\n",
      "[77,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3417,  0.3017,  0.3235,  ..., -0.5761, -0.5534, -0.5673],\n",
      "        [-0.3477, -0.3033, -0.3062,  ...,  0.5636,  0.5962,  0.5744]])\n",
      "rho.1.bias tensor([ 0.1902, -0.1907])\n",
      "train_vars.0 tensor(1.5677)\n",
      "train_vars.1 tensor(2.4030)\n",
      "train_vars.2 tensor(1.7738)\n",
      "train_vars.3 tensor(2.2987)\n",
      "train_vars.4 tensor(1.6016)\n",
      "train_vars.5 tensor(2.3669)\n",
      "train_vars.6 tensor(2.0523)\n",
      "train_vars.7 tensor(2.0628)\n",
      "=====================================\n",
      "[77,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3422,  0.3023,  0.3240,  ..., -0.5752, -0.5525, -0.5664],\n",
      "        [-0.3483, -0.3039, -0.3067,  ...,  0.5627,  0.5953,  0.5735]])\n",
      "rho.1.bias tensor([ 0.1908, -0.1914])\n",
      "train_vars.0 tensor(1.5685)\n",
      "train_vars.1 tensor(2.4023)\n",
      "train_vars.2 tensor(1.7726)\n",
      "train_vars.3 tensor(2.3000)\n",
      "train_vars.4 tensor(1.6033)\n",
      "train_vars.5 tensor(2.3651)\n",
      "train_vars.6 tensor(2.0510)\n",
      "train_vars.7 tensor(2.0643)\n",
      "=====================================\n",
      "[77,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3415,  0.3016,  0.3233,  ..., -0.5763, -0.5535, -0.5675],\n",
      "        [-0.3476, -0.3032, -0.3060,  ...,  0.5638,  0.5964,  0.5746]])\n",
      "rho.1.bias tensor([ 0.1896, -0.1902])\n",
      "train_vars.0 tensor(1.5675)\n",
      "train_vars.1 tensor(2.4032)\n",
      "train_vars.2 tensor(1.7737)\n",
      "train_vars.3 tensor(2.2990)\n",
      "train_vars.4 tensor(1.6021)\n",
      "train_vars.5 tensor(2.3664)\n",
      "train_vars.6 tensor(2.0524)\n",
      "train_vars.7 tensor(2.0629)\n",
      "=====================================\n",
      "[77,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3412,  0.3013,  0.3230,  ..., -0.5770, -0.5543, -0.5682],\n",
      "        [-0.3473, -0.3028, -0.3057,  ...,  0.5645,  0.5971,  0.5753]])\n",
      "rho.1.bias tensor([ 0.1890, -0.1896])\n",
      "train_vars.0 tensor(1.5670)\n",
      "train_vars.1 tensor(2.4037)\n",
      "train_vars.2 tensor(1.7742)\n",
      "train_vars.3 tensor(2.2985)\n",
      "train_vars.4 tensor(1.6015)\n",
      "train_vars.5 tensor(2.3671)\n",
      "train_vars.6 tensor(2.0534)\n",
      "train_vars.7 tensor(2.0620)\n",
      "=====================================\n",
      "[77,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3412,  0.3012,  0.3230,  ..., -0.5774, -0.5546, -0.5686],\n",
      "        [-0.3472, -0.3028, -0.3057,  ...,  0.5649,  0.5975,  0.5757]])\n",
      "rho.1.bias tensor([ 0.1887, -0.1893])\n",
      "train_vars.0 tensor(1.5670)\n",
      "train_vars.1 tensor(2.4037)\n",
      "train_vars.2 tensor(1.7740)\n",
      "train_vars.3 tensor(2.2988)\n",
      "train_vars.4 tensor(1.6014)\n",
      "train_vars.5 tensor(2.3671)\n",
      "train_vars.6 tensor(2.0539)\n",
      "train_vars.7 tensor(2.0616)\n",
      "=====================================\n",
      "[77,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3409,  0.3009,  0.3227,  ..., -0.5773, -0.5545, -0.5685],\n",
      "        [-0.3469, -0.3025, -0.3054,  ...,  0.5648,  0.5974,  0.5756]])\n",
      "rho.1.bias tensor([ 0.1879, -0.1885])\n",
      "train_vars.0 tensor(1.5665)\n",
      "train_vars.1 tensor(2.4042)\n",
      "train_vars.2 tensor(1.7743)\n",
      "train_vars.3 tensor(2.2985)\n",
      "train_vars.4 tensor(1.6018)\n",
      "train_vars.5 tensor(2.3667)\n",
      "train_vars.6 tensor(2.0537)\n",
      "train_vars.7 tensor(2.0619)\n",
      "=====================================\n",
      "[78,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3409,  0.3010,  0.3227,  ..., -0.5771, -0.5544, -0.5683],\n",
      "        [-0.3470, -0.3026, -0.3054,  ...,  0.5646,  0.5972,  0.5754]])\n",
      "rho.1.bias tensor([ 0.1878, -0.1884])\n",
      "train_vars.0 tensor(1.5665)\n",
      "train_vars.1 tensor(2.4042)\n",
      "train_vars.2 tensor(1.7739)\n",
      "train_vars.3 tensor(2.2990)\n",
      "train_vars.4 tensor(1.6025)\n",
      "train_vars.5 tensor(2.3660)\n",
      "train_vars.6 tensor(2.0534)\n",
      "train_vars.7 tensor(2.0624)\n",
      "=====================================\n",
      "[78,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3415,  0.3015,  0.3233,  ..., -0.5762, -0.5535, -0.5674],\n",
      "        [-0.3475, -0.3031, -0.3060,  ...,  0.5637,  0.5963,  0.5745]])\n",
      "rho.1.bias tensor([ 0.1884, -0.1891])\n",
      "train_vars.0 tensor(1.5673)\n",
      "train_vars.1 tensor(2.4034)\n",
      "train_vars.2 tensor(1.7728)\n",
      "train_vars.3 tensor(2.3002)\n",
      "train_vars.4 tensor(1.6041)\n",
      "train_vars.5 tensor(2.3643)\n",
      "train_vars.6 tensor(2.0521)\n",
      "train_vars.7 tensor(2.0639)\n",
      "=====================================\n",
      "[78,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3408,  0.3008,  0.3226,  ..., -0.5772, -0.5545, -0.5685],\n",
      "        [-0.3468, -0.3024, -0.3053,  ...,  0.5648,  0.5974,  0.5756]])\n",
      "rho.1.bias tensor([ 0.1873, -0.1879])\n",
      "train_vars.0 tensor(1.5663)\n",
      "train_vars.1 tensor(2.4044)\n",
      "train_vars.2 tensor(1.7738)\n",
      "train_vars.3 tensor(2.2992)\n",
      "train_vars.4 tensor(1.6029)\n",
      "train_vars.5 tensor(2.3656)\n",
      "train_vars.6 tensor(2.0536)\n",
      "train_vars.7 tensor(2.0625)\n",
      "=====================================\n",
      "[78,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3405,  0.3005,  0.3223,  ..., -0.5779, -0.5552, -0.5692],\n",
      "        [-0.3465, -0.3021, -0.3050,  ...,  0.5655,  0.5981,  0.5763]])\n",
      "rho.1.bias tensor([ 0.1866, -0.1873])\n",
      "train_vars.0 tensor(1.5659)\n",
      "train_vars.1 tensor(2.4048)\n",
      "train_vars.2 tensor(1.7743)\n",
      "train_vars.3 tensor(2.2988)\n",
      "train_vars.4 tensor(1.6023)\n",
      "train_vars.5 tensor(2.3663)\n",
      "train_vars.6 tensor(2.0545)\n",
      "train_vars.7 tensor(2.0616)\n",
      "=====================================\n",
      "[78,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3405,  0.3005,  0.3223,  ..., -0.5783, -0.5556, -0.5696],\n",
      "        [-0.3465, -0.3021, -0.3050,  ...,  0.5659,  0.5985,  0.5767]])\n",
      "rho.1.bias tensor([ 0.1863, -0.1870])\n",
      "train_vars.0 tensor(1.5658)\n",
      "train_vars.1 tensor(2.4049)\n",
      "train_vars.2 tensor(1.7741)\n",
      "train_vars.3 tensor(2.2990)\n",
      "train_vars.4 tensor(1.6023)\n",
      "train_vars.5 tensor(2.3663)\n",
      "train_vars.6 tensor(2.0550)\n",
      "train_vars.7 tensor(2.0612)\n",
      "=====================================\n",
      "[78,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3402,  0.3002,  0.3220,  ..., -0.5782, -0.5555, -0.5695],\n",
      "        [-0.3462, -0.3018, -0.3047,  ...,  0.5658,  0.5984,  0.5766]])\n",
      "rho.1.bias tensor([ 0.1855, -0.1862])\n",
      "train_vars.0 tensor(1.5654)\n",
      "train_vars.1 tensor(2.4053)\n",
      "train_vars.2 tensor(1.7744)\n",
      "train_vars.3 tensor(2.2988)\n",
      "train_vars.4 tensor(1.6026)\n",
      "train_vars.5 tensor(2.3659)\n",
      "train_vars.6 tensor(2.0549)\n",
      "train_vars.7 tensor(2.0615)\n",
      "=====================================\n",
      "[79,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3402,  0.3002,  0.3220,  ..., -0.5780, -0.5553, -0.5693],\n",
      "        [-0.3462, -0.3018, -0.3047,  ...,  0.5656,  0.5982,  0.5764]])\n",
      "rho.1.bias tensor([ 0.1854, -0.1861])\n",
      "train_vars.0 tensor(1.5654)\n",
      "train_vars.1 tensor(2.4053)\n",
      "train_vars.2 tensor(1.7740)\n",
      "train_vars.3 tensor(2.2993)\n",
      "train_vars.4 tensor(1.6033)\n",
      "train_vars.5 tensor(2.3653)\n",
      "train_vars.6 tensor(2.0545)\n",
      "train_vars.7 tensor(2.0620)\n",
      "=====================================\n",
      "[79,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3408,  0.3008,  0.3226,  ..., -0.5771, -0.5544, -0.5684],\n",
      "        [-0.3468, -0.3024, -0.3053,  ...,  0.5647,  0.5973,  0.5755]])\n",
      "rho.1.bias tensor([ 0.1861, -0.1868])\n",
      "train_vars.0 tensor(1.5662)\n",
      "train_vars.1 tensor(2.4046)\n",
      "train_vars.2 tensor(1.7729)\n",
      "train_vars.3 tensor(2.3005)\n",
      "train_vars.4 tensor(1.6049)\n",
      "train_vars.5 tensor(2.3635)\n",
      "train_vars.6 tensor(2.0532)\n",
      "train_vars.7 tensor(2.0635)\n",
      "=====================================\n",
      "[79,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3401,  0.3001,  0.3219,  ..., -0.5782, -0.5555, -0.5695],\n",
      "        [-0.3461, -0.3017, -0.3046,  ...,  0.5657,  0.5983,  0.5766]])\n",
      "rho.1.bias tensor([ 0.1849, -0.1856])\n",
      "train_vars.0 tensor(1.5652)\n",
      "train_vars.1 tensor(2.4056)\n",
      "train_vars.2 tensor(1.7739)\n",
      "train_vars.3 tensor(2.2995)\n",
      "train_vars.4 tensor(1.6037)\n",
      "train_vars.5 tensor(2.3648)\n",
      "train_vars.6 tensor(2.0547)\n",
      "train_vars.7 tensor(2.0621)\n",
      "=====================================\n",
      "[79,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3398,  0.2998,  0.3216,  ..., -0.5789, -0.5562, -0.5702],\n",
      "        [-0.3458, -0.3014, -0.3042,  ...,  0.5664,  0.5991,  0.5773]])\n",
      "rho.1.bias tensor([ 0.1843, -0.1850])\n",
      "train_vars.0 tensor(1.5647)\n",
      "train_vars.1 tensor(2.4060)\n",
      "train_vars.2 tensor(1.7744)\n",
      "train_vars.3 tensor(2.2991)\n",
      "train_vars.4 tensor(1.6031)\n",
      "train_vars.5 tensor(2.3655)\n",
      "train_vars.6 tensor(2.0556)\n",
      "train_vars.7 tensor(2.0612)\n",
      "=====================================\n",
      "[79,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3398,  0.2998,  0.3216,  ..., -0.5793, -0.5566, -0.5705],\n",
      "        [-0.3458, -0.3014, -0.3042,  ...,  0.5668,  0.5994,  0.5777]])\n",
      "rho.1.bias tensor([ 0.1840, -0.1847])\n",
      "train_vars.0 tensor(1.5647)\n",
      "train_vars.1 tensor(2.4060)\n",
      "train_vars.2 tensor(1.7742)\n",
      "train_vars.3 tensor(2.2993)\n",
      "train_vars.4 tensor(1.6031)\n",
      "train_vars.5 tensor(2.3655)\n",
      "train_vars.6 tensor(2.0561)\n",
      "train_vars.7 tensor(2.0608)\n",
      "=====================================\n",
      "[79,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3395,  0.2995,  0.3212,  ..., -0.5792, -0.5565, -0.5705],\n",
      "        [-0.3455, -0.3010, -0.3039,  ...,  0.5667,  0.5993,  0.5776]])\n",
      "rho.1.bias tensor([ 0.1832, -0.1839])\n",
      "train_vars.0 tensor(1.5642)\n",
      "train_vars.1 tensor(2.4065)\n",
      "train_vars.2 tensor(1.7745)\n",
      "train_vars.3 tensor(2.2991)\n",
      "train_vars.4 tensor(1.6035)\n",
      "train_vars.5 tensor(2.3651)\n",
      "train_vars.6 tensor(2.0560)\n",
      "train_vars.7 tensor(2.0611)\n",
      "=====================================\n",
      "[80,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3395,  0.2995,  0.3213,  ..., -0.5790, -0.5563, -0.5703],\n",
      "        [-0.3455, -0.3011, -0.3040,  ...,  0.5665,  0.5991,  0.5774]])\n",
      "rho.1.bias tensor([ 0.1831, -0.1838])\n",
      "train_vars.0 tensor(1.5643)\n",
      "train_vars.1 tensor(2.4065)\n",
      "train_vars.2 tensor(1.7741)\n",
      "train_vars.3 tensor(2.2996)\n",
      "train_vars.4 tensor(1.6041)\n",
      "train_vars.5 tensor(2.3645)\n",
      "train_vars.6 tensor(2.0556)\n",
      "train_vars.7 tensor(2.0616)\n",
      "=====================================\n",
      "[80,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3401,  0.3001,  0.3219,  ..., -0.5781, -0.5554, -0.5694],\n",
      "        [-0.3461, -0.3017, -0.3045,  ...,  0.5656,  0.5982,  0.5765]])\n",
      "rho.1.bias tensor([ 0.1837, -0.1845])\n",
      "train_vars.0 tensor(1.5650)\n",
      "train_vars.1 tensor(2.4058)\n",
      "train_vars.2 tensor(1.7730)\n",
      "train_vars.3 tensor(2.3008)\n",
      "train_vars.4 tensor(1.6058)\n",
      "train_vars.5 tensor(2.3627)\n",
      "train_vars.6 tensor(2.0543)\n",
      "train_vars.7 tensor(2.0631)\n",
      "=====================================\n",
      "[80,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3393,  0.2994,  0.3211,  ..., -0.5791, -0.5565, -0.5704],\n",
      "        [-0.3454, -0.3009, -0.3038,  ...,  0.5667,  0.5993,  0.5776]])\n",
      "rho.1.bias tensor([ 0.1825, -0.1833])\n",
      "train_vars.0 tensor(1.5640)\n",
      "train_vars.1 tensor(2.4067)\n",
      "train_vars.2 tensor(1.7740)\n",
      "train_vars.3 tensor(2.2998)\n",
      "train_vars.4 tensor(1.6045)\n",
      "train_vars.5 tensor(2.3641)\n",
      "train_vars.6 tensor(2.0558)\n",
      "train_vars.7 tensor(2.0617)\n",
      "=====================================\n",
      "[80,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3390,  0.2991,  0.3208,  ..., -0.5798, -0.5572, -0.5712],\n",
      "        [-0.3450, -0.3006, -0.3035,  ...,  0.5674,  0.6000,  0.5783]])\n",
      "rho.1.bias tensor([ 0.1819, -0.1827])\n",
      "train_vars.0 tensor(1.5636)\n",
      "train_vars.1 tensor(2.4072)\n",
      "train_vars.2 tensor(1.7745)\n",
      "train_vars.3 tensor(2.2994)\n",
      "train_vars.4 tensor(1.6039)\n",
      "train_vars.5 tensor(2.3647)\n",
      "train_vars.6 tensor(2.0568)\n",
      "train_vars.7 tensor(2.0608)\n",
      "=====================================\n",
      "[80,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3390,  0.2991,  0.3208,  ..., -0.5802, -0.5575, -0.5715],\n",
      "        [-0.3450, -0.3006, -0.3035,  ...,  0.5677,  0.6004,  0.5787]])\n",
      "rho.1.bias tensor([ 0.1816, -0.1824])\n",
      "train_vars.0 tensor(1.5636)\n",
      "train_vars.1 tensor(2.4072)\n",
      "train_vars.2 tensor(1.7743)\n",
      "train_vars.3 tensor(2.2996)\n",
      "train_vars.4 tensor(1.6039)\n",
      "train_vars.5 tensor(2.3647)\n",
      "train_vars.6 tensor(2.0572)\n",
      "train_vars.7 tensor(2.0604)\n",
      "=====================================\n",
      "[80,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3387,  0.2987,  0.3205,  ..., -0.5801, -0.5574, -0.5714],\n",
      "        [-0.3447, -0.3003, -0.3032,  ...,  0.5677,  0.6003,  0.5786]])\n",
      "rho.1.bias tensor([ 0.1808, -0.1816])\n",
      "train_vars.0 tensor(1.5631)\n",
      "train_vars.1 tensor(2.4076)\n",
      "train_vars.2 tensor(1.7746)\n",
      "train_vars.3 tensor(2.2994)\n",
      "train_vars.4 tensor(1.6043)\n",
      "train_vars.5 tensor(2.3644)\n",
      "train_vars.6 tensor(2.0571)\n",
      "train_vars.7 tensor(2.0607)\n",
      "=====================================\n",
      "[81,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3387,  0.2988,  0.3205,  ..., -0.5799, -0.5572, -0.5712],\n",
      "        [-0.3448, -0.3003, -0.3032,  ...,  0.5674,  0.6001,  0.5784]])\n",
      "rho.1.bias tensor([ 0.1807, -0.1816])\n",
      "train_vars.0 tensor(1.5631)\n",
      "train_vars.1 tensor(2.4076)\n",
      "train_vars.2 tensor(1.7742)\n",
      "train_vars.3 tensor(2.2999)\n",
      "train_vars.4 tensor(1.6049)\n",
      "train_vars.5 tensor(2.3637)\n",
      "train_vars.6 tensor(2.0567)\n",
      "train_vars.7 tensor(2.0612)\n",
      "=====================================\n",
      "[81,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3393,  0.2993,  0.3211,  ..., -0.5790, -0.5563, -0.5704],\n",
      "        [-0.3453, -0.3009, -0.3038,  ...,  0.5665,  0.5992,  0.5775]])\n",
      "rho.1.bias tensor([ 0.1813, -0.1822])\n",
      "train_vars.0 tensor(1.5639)\n",
      "train_vars.1 tensor(2.4069)\n",
      "train_vars.2 tensor(1.7731)\n",
      "train_vars.3 tensor(2.3011)\n",
      "train_vars.4 tensor(1.6066)\n",
      "train_vars.5 tensor(2.3619)\n",
      "train_vars.6 tensor(2.0554)\n",
      "train_vars.7 tensor(2.0627)\n",
      "=====================================\n",
      "[81,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3386,  0.2986,  0.3204,  ..., -0.5801, -0.5574, -0.5714],\n",
      "        [-0.3446, -0.3002, -0.3031,  ...,  0.5676,  0.6003,  0.5786]])\n",
      "rho.1.bias tensor([ 0.1802, -0.1810])\n",
      "train_vars.0 tensor(1.5629)\n",
      "train_vars.1 tensor(2.4079)\n",
      "train_vars.2 tensor(1.7741)\n",
      "train_vars.3 tensor(2.3001)\n",
      "train_vars.4 tensor(1.6053)\n",
      "train_vars.5 tensor(2.3633)\n",
      "train_vars.6 tensor(2.0569)\n",
      "train_vars.7 tensor(2.0613)\n",
      "=====================================\n",
      "[81,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3383,  0.2983,  0.3201,  ..., -0.5808, -0.5581, -0.5721],\n",
      "        [-0.3443, -0.2999, -0.3028,  ...,  0.5683,  0.6010,  0.5793]])\n",
      "rho.1.bias tensor([ 0.1795, -0.1804])\n",
      "train_vars.0 tensor(1.5625)\n",
      "train_vars.1 tensor(2.4083)\n",
      "train_vars.2 tensor(1.7746)\n",
      "train_vars.3 tensor(2.2996)\n",
      "train_vars.4 tensor(1.6047)\n",
      "train_vars.5 tensor(2.3639)\n",
      "train_vars.6 tensor(2.0579)\n",
      "train_vars.7 tensor(2.0604)\n",
      "=====================================\n",
      "[81,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3383,  0.2983,  0.3201,  ..., -0.5811, -0.5585, -0.5725],\n",
      "        [-0.3443, -0.2999, -0.3028,  ...,  0.5687,  0.6014,  0.5797]])\n",
      "rho.1.bias tensor([ 0.1793, -0.1801])\n",
      "train_vars.0 tensor(1.5624)\n",
      "train_vars.1 tensor(2.4083)\n",
      "train_vars.2 tensor(1.7744)\n",
      "train_vars.3 tensor(2.2999)\n",
      "train_vars.4 tensor(1.6047)\n",
      "train_vars.5 tensor(2.3640)\n",
      "train_vars.6 tensor(2.0583)\n",
      "train_vars.7 tensor(2.0600)\n",
      "=====================================\n",
      "[81,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3380,  0.2980,  0.3198,  ..., -0.5810, -0.5584, -0.5724],\n",
      "        [-0.3440, -0.2996, -0.3025,  ...,  0.5686,  0.6013,  0.5796]])\n",
      "rho.1.bias tensor([ 0.1785, -0.1794])\n",
      "train_vars.0 tensor(1.5620)\n",
      "train_vars.1 tensor(2.4088)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.2997)\n",
      "train_vars.4 tensor(1.6051)\n",
      "train_vars.5 tensor(2.3636)\n",
      "train_vars.6 tensor(2.0582)\n",
      "train_vars.7 tensor(2.0603)\n",
      "=====================================\n",
      "[82,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3380,  0.2980,  0.3198,  ..., -0.5808, -0.5582, -0.5722],\n",
      "        [-0.3440, -0.2996, -0.3025,  ...,  0.5684,  0.6011,  0.5794]])\n",
      "rho.1.bias tensor([ 0.1784, -0.1793])\n",
      "train_vars.0 tensor(1.5620)\n",
      "train_vars.1 tensor(2.4088)\n",
      "train_vars.2 tensor(1.7743)\n",
      "train_vars.3 tensor(2.3001)\n",
      "train_vars.4 tensor(1.6057)\n",
      "train_vars.5 tensor(2.3629)\n",
      "train_vars.6 tensor(2.0578)\n",
      "train_vars.7 tensor(2.0608)\n",
      "=====================================\n",
      "[82,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3386,  0.2986,  0.3204,  ..., -0.5799, -0.5573, -0.5713],\n",
      "        [-0.3446, -0.3002, -0.3031,  ...,  0.5675,  0.6002,  0.5785]])\n",
      "rho.1.bias tensor([ 0.1790, -0.1799])\n",
      "train_vars.0 tensor(1.5628)\n",
      "train_vars.1 tensor(2.4081)\n",
      "train_vars.2 tensor(1.7732)\n",
      "train_vars.3 tensor(2.3014)\n",
      "train_vars.4 tensor(1.6074)\n",
      "train_vars.5 tensor(2.3612)\n",
      "train_vars.6 tensor(2.0565)\n",
      "train_vars.7 tensor(2.0623)\n",
      "=====================================\n",
      "[82,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3379,  0.2979,  0.3197,  ..., -0.5810, -0.5584, -0.5724],\n",
      "        [-0.3439, -0.2995, -0.3023,  ...,  0.5686,  0.6013,  0.5796]])\n",
      "rho.1.bias tensor([ 0.1778, -0.1787])\n",
      "train_vars.0 tensor(1.5618)\n",
      "train_vars.1 tensor(2.4090)\n",
      "train_vars.2 tensor(1.7742)\n",
      "train_vars.3 tensor(2.3004)\n",
      "train_vars.4 tensor(1.6061)\n",
      "train_vars.5 tensor(2.3625)\n",
      "train_vars.6 tensor(2.0580)\n",
      "train_vars.7 tensor(2.0609)\n",
      "=====================================\n",
      "[82,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3376,  0.2976,  0.3194,  ..., -0.5817, -0.5591, -0.5731],\n",
      "        [-0.3436, -0.2992, -0.3020,  ...,  0.5693,  0.6020,  0.5803]])\n",
      "rho.1.bias tensor([ 0.1772, -0.1781])\n",
      "train_vars.0 tensor(1.5613)\n",
      "train_vars.1 tensor(2.4094)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.2999)\n",
      "train_vars.4 tensor(1.6055)\n",
      "train_vars.5 tensor(2.3632)\n",
      "train_vars.6 tensor(2.0589)\n",
      "train_vars.7 tensor(2.0600)\n",
      "=====================================\n",
      "[82,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3376,  0.2976,  0.3194,  ..., -0.5820, -0.5594, -0.5735],\n",
      "        [-0.3436, -0.2992, -0.3020,  ...,  0.5696,  0.6023,  0.5807]])\n",
      "rho.1.bias tensor([ 0.1769, -0.1778])\n",
      "train_vars.0 tensor(1.5613)\n",
      "train_vars.1 tensor(2.4095)\n",
      "train_vars.2 tensor(1.7745)\n",
      "train_vars.3 tensor(2.3002)\n",
      "train_vars.4 tensor(1.6055)\n",
      "train_vars.5 tensor(2.3632)\n",
      "train_vars.6 tensor(2.0594)\n",
      "train_vars.7 tensor(2.0596)\n",
      "=====================================\n",
      "[82,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3373,  0.2973,  0.3191,  ..., -0.5819, -0.5593, -0.5734],\n",
      "        [-0.3433, -0.2988, -0.3017,  ...,  0.5695,  0.6022,  0.5806]])\n",
      "rho.1.bias tensor([ 0.1761, -0.1771])\n",
      "train_vars.0 tensor(1.5609)\n",
      "train_vars.1 tensor(2.4099)\n",
      "train_vars.2 tensor(1.7748)\n",
      "train_vars.3 tensor(2.3000)\n",
      "train_vars.4 tensor(1.6059)\n",
      "train_vars.5 tensor(2.3628)\n",
      "train_vars.6 tensor(2.0592)\n",
      "train_vars.7 tensor(2.0599)\n",
      "=====================================\n",
      "[83,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3373,  0.2973,  0.3191,  ..., -0.5817, -0.5591, -0.5732],\n",
      "        [-0.3433, -0.2989, -0.3018,  ...,  0.5693,  0.6020,  0.5804]])\n",
      "rho.1.bias tensor([ 0.1760, -0.1770])\n",
      "train_vars.0 tensor(1.5609)\n",
      "train_vars.1 tensor(2.4099)\n",
      "train_vars.2 tensor(1.7744)\n",
      "train_vars.3 tensor(2.3004)\n",
      "train_vars.4 tensor(1.6065)\n",
      "train_vars.5 tensor(2.3622)\n",
      "train_vars.6 tensor(2.0589)\n",
      "train_vars.7 tensor(2.0604)\n",
      "=====================================\n",
      "[83,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3379,  0.2979,  0.3197,  ..., -0.5808, -0.5582, -0.5723],\n",
      "        [-0.3439, -0.2994, -0.3023,  ...,  0.5684,  0.6011,  0.5795]])\n",
      "rho.1.bias tensor([ 0.1766, -0.1776])\n",
      "train_vars.0 tensor(1.5616)\n",
      "train_vars.1 tensor(2.4092)\n",
      "train_vars.2 tensor(1.7733)\n",
      "train_vars.3 tensor(2.3016)\n",
      "train_vars.4 tensor(1.6082)\n",
      "train_vars.5 tensor(2.3604)\n",
      "train_vars.6 tensor(2.0576)\n",
      "train_vars.7 tensor(2.0619)\n",
      "=====================================\n",
      "[83,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3372,  0.2972,  0.3190,  ..., -0.5819, -0.5593, -0.5734],\n",
      "        [-0.3431, -0.2987, -0.3016,  ...,  0.5695,  0.6022,  0.5806]])\n",
      "rho.1.bias tensor([ 0.1755, -0.1765])\n",
      "train_vars.0 tensor(1.5606)\n",
      "train_vars.1 tensor(2.4102)\n",
      "train_vars.2 tensor(1.7743)\n",
      "train_vars.3 tensor(2.3007)\n",
      "train_vars.4 tensor(1.6069)\n",
      "train_vars.5 tensor(2.3618)\n",
      "train_vars.6 tensor(2.0591)\n",
      "train_vars.7 tensor(2.0605)\n",
      "=====================================\n",
      "[83,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3369,  0.2969,  0.3187,  ..., -0.5826, -0.5600, -0.5741],\n",
      "        [-0.3428, -0.2984, -0.3013,  ...,  0.5702,  0.6029,  0.5813]])\n",
      "rho.1.bias tensor([ 0.1748, -0.1758])\n",
      "train_vars.0 tensor(1.5602)\n",
      "train_vars.1 tensor(2.4106)\n",
      "train_vars.2 tensor(1.7748)\n",
      "train_vars.3 tensor(2.3002)\n",
      "train_vars.4 tensor(1.6063)\n",
      "train_vars.5 tensor(2.3624)\n",
      "train_vars.6 tensor(2.0600)\n",
      "train_vars.7 tensor(2.0596)\n",
      "=====================================\n",
      "[83,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3369,  0.2969,  0.3186,  ..., -0.5829, -0.5604, -0.5744],\n",
      "        [-0.3428, -0.2984, -0.3013,  ...,  0.5705,  0.6033,  0.5816]])\n",
      "rho.1.bias tensor([ 0.1746, -0.1756])\n",
      "train_vars.0 tensor(1.5602)\n",
      "train_vars.1 tensor(2.4106)\n",
      "train_vars.2 tensor(1.7746)\n",
      "train_vars.3 tensor(2.3005)\n",
      "train_vars.4 tensor(1.6063)\n",
      "train_vars.5 tensor(2.3624)\n",
      "train_vars.6 tensor(2.0605)\n",
      "train_vars.7 tensor(2.0592)\n",
      "=====================================\n",
      "[83,     6] loss: 0.538\n",
      "rho.1.weight tensor([[ 0.3365,  0.2966,  0.3183,  ..., -0.5829, -0.5603, -0.5744],\n",
      "        [-0.3425, -0.2981, -0.3010,  ...,  0.5704,  0.6032,  0.5815]])\n",
      "rho.1.bias tensor([ 0.1738, -0.1748])\n",
      "train_vars.0 tensor(1.5597)\n",
      "train_vars.1 tensor(2.4111)\n",
      "train_vars.2 tensor(1.7749)\n",
      "train_vars.3 tensor(2.3003)\n",
      "train_vars.4 tensor(1.6067)\n",
      "train_vars.5 tensor(2.3621)\n",
      "train_vars.6 tensor(2.0603)\n",
      "train_vars.7 tensor(2.0595)\n",
      "=====================================\n",
      "[84,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3366,  0.2966,  0.3184,  ..., -0.5826, -0.5601, -0.5742],\n",
      "        [-0.3426, -0.2981, -0.3010,  ...,  0.5702,  0.6030,  0.5813]])\n",
      "rho.1.bias tensor([ 0.1737, -0.1747])\n",
      "train_vars.0 tensor(1.5597)\n",
      "train_vars.1 tensor(2.4111)\n",
      "train_vars.2 tensor(1.7745)\n",
      "train_vars.3 tensor(2.3007)\n",
      "train_vars.4 tensor(1.6073)\n",
      "train_vars.5 tensor(2.3614)\n",
      "train_vars.6 tensor(2.0600)\n",
      "train_vars.7 tensor(2.0600)\n",
      "=====================================\n",
      "[84,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3371,  0.2971,  0.3189,  ..., -0.5817, -0.5592, -0.5733],\n",
      "        [-0.3431, -0.2987, -0.3016,  ...,  0.5693,  0.6021,  0.5805]])\n",
      "rho.1.bias tensor([ 0.1743, -0.1754])\n",
      "train_vars.0 tensor(1.5605)\n",
      "train_vars.1 tensor(2.4103)\n",
      "train_vars.2 tensor(1.7734)\n",
      "train_vars.3 tensor(2.3019)\n",
      "train_vars.4 tensor(1.6090)\n",
      "train_vars.5 tensor(2.3597)\n",
      "train_vars.6 tensor(2.0587)\n",
      "train_vars.7 tensor(2.0615)\n",
      "=====================================\n",
      "[84,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3364,  0.2964,  0.3182,  ..., -0.5828, -0.5602, -0.5743],\n",
      "        [-0.3424, -0.2980, -0.3009,  ...,  0.5704,  0.6032,  0.5815]])\n",
      "rho.1.bias tensor([ 0.1731, -0.1742])\n",
      "train_vars.0 tensor(1.5595)\n",
      "train_vars.1 tensor(2.4113)\n",
      "train_vars.2 tensor(1.7744)\n",
      "train_vars.3 tensor(2.3009)\n",
      "train_vars.4 tensor(1.6077)\n",
      "train_vars.5 tensor(2.3610)\n",
      "train_vars.6 tensor(2.0601)\n",
      "train_vars.7 tensor(2.0601)\n",
      "=====================================\n",
      "[84,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3361,  0.2961,  0.3179,  ..., -0.5835, -0.5609, -0.5750],\n",
      "        [-0.3421, -0.2977, -0.3006,  ...,  0.5711,  0.6039,  0.5823]])\n",
      "rho.1.bias tensor([ 0.1725, -0.1736])\n",
      "train_vars.0 tensor(1.5591)\n",
      "train_vars.1 tensor(2.4117)\n",
      "train_vars.2 tensor(1.7749)\n",
      "train_vars.3 tensor(2.3005)\n",
      "train_vars.4 tensor(1.6071)\n",
      "train_vars.5 tensor(2.3617)\n",
      "train_vars.6 tensor(2.0611)\n",
      "train_vars.7 tensor(2.0592)\n",
      "=====================================\n",
      "[84,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3361,  0.2961,  0.3179,  ..., -0.5839, -0.5613, -0.5754],\n",
      "        [-0.3421, -0.2977, -0.3006,  ...,  0.5715,  0.6042,  0.5826]])\n",
      "rho.1.bias tensor([ 0.1722, -0.1733])\n",
      "train_vars.0 tensor(1.5590)\n",
      "train_vars.1 tensor(2.4118)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.3008)\n",
      "train_vars.4 tensor(1.6071)\n",
      "train_vars.5 tensor(2.3617)\n",
      "train_vars.6 tensor(2.0615)\n",
      "train_vars.7 tensor(2.0589)\n",
      "=====================================\n",
      "[84,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3358,  0.2958,  0.3176,  ..., -0.5838, -0.5612, -0.5753],\n",
      "        [-0.3418, -0.2974, -0.3003,  ...,  0.5714,  0.6041,  0.5825]])\n",
      "rho.1.bias tensor([ 0.1715, -0.1725])\n",
      "train_vars.0 tensor(1.5586)\n",
      "train_vars.1 tensor(2.4122)\n",
      "train_vars.2 tensor(1.7750)\n",
      "train_vars.3 tensor(2.3005)\n",
      "train_vars.4 tensor(1.6075)\n",
      "train_vars.5 tensor(2.3613)\n",
      "train_vars.6 tensor(2.0614)\n",
      "train_vars.7 tensor(2.0591)\n",
      "=====================================\n",
      "[85,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3358,  0.2959,  0.3176,  ..., -0.5836, -0.5610, -0.5751],\n",
      "        [-0.3418, -0.2974, -0.3003,  ...,  0.5711,  0.6039,  0.5823]])\n",
      "rho.1.bias tensor([ 0.1713, -0.1725])\n",
      "train_vars.0 tensor(1.5586)\n",
      "train_vars.1 tensor(2.4122)\n",
      "train_vars.2 tensor(1.7746)\n",
      "train_vars.3 tensor(2.3010)\n",
      "train_vars.4 tensor(1.6081)\n",
      "train_vars.5 tensor(2.3607)\n",
      "train_vars.6 tensor(2.0610)\n",
      "train_vars.7 tensor(2.0596)\n",
      "=====================================\n",
      "[85,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3364,  0.2964,  0.3182,  ..., -0.5827, -0.5601, -0.5742],\n",
      "        [-0.3424, -0.2980, -0.3009,  ...,  0.5702,  0.6030,  0.5814]])\n",
      "rho.1.bias tensor([ 0.1720, -0.1731])\n",
      "train_vars.0 tensor(1.5594)\n",
      "train_vars.1 tensor(2.4115)\n",
      "train_vars.2 tensor(1.7734)\n",
      "train_vars.3 tensor(2.3022)\n",
      "train_vars.4 tensor(1.6097)\n",
      "train_vars.5 tensor(2.3589)\n",
      "train_vars.6 tensor(2.0597)\n",
      "train_vars.7 tensor(2.0611)\n",
      "=====================================\n",
      "[85,     3] loss: 0.464\n",
      "rho.1.weight tensor([[ 0.3357,  0.2957,  0.3175,  ..., -0.5837, -0.5612, -0.5753],\n",
      "        [-0.3417, -0.2973, -0.3001,  ...,  0.5713,  0.6041,  0.5825]])\n",
      "rho.1.bias tensor([ 0.1708, -0.1719])\n",
      "train_vars.0 tensor(1.5584)\n",
      "train_vars.1 tensor(2.4124)\n",
      "train_vars.2 tensor(1.7745)\n",
      "train_vars.3 tensor(2.3012)\n",
      "train_vars.4 tensor(1.6085)\n",
      "train_vars.5 tensor(2.3603)\n",
      "train_vars.6 tensor(2.0612)\n",
      "train_vars.7 tensor(2.0597)\n",
      "=====================================\n",
      "[85,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3354,  0.2954,  0.3172,  ..., -0.5844, -0.5619, -0.5760],\n",
      "        [-0.3414, -0.2970, -0.2998,  ...,  0.5720,  0.6048,  0.5832]])\n",
      "rho.1.bias tensor([ 0.1702, -0.1713])\n",
      "train_vars.0 tensor(1.5579)\n",
      "train_vars.1 tensor(2.4129)\n",
      "train_vars.2 tensor(1.7750)\n",
      "train_vars.3 tensor(2.3008)\n",
      "train_vars.4 tensor(1.6079)\n",
      "train_vars.5 tensor(2.3610)\n",
      "train_vars.6 tensor(2.0622)\n",
      "train_vars.7 tensor(2.0588)\n",
      "=====================================\n",
      "[85,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3354,  0.2954,  0.3172,  ..., -0.5848, -0.5622, -0.5764],\n",
      "        [-0.3414, -0.2970, -0.2998,  ...,  0.5724,  0.6052,  0.5836]])\n",
      "rho.1.bias tensor([ 0.1699, -0.1711])\n",
      "train_vars.0 tensor(1.5579)\n",
      "train_vars.1 tensor(2.4129)\n",
      "train_vars.2 tensor(1.7748)\n",
      "train_vars.3 tensor(2.3011)\n",
      "train_vars.4 tensor(1.6079)\n",
      "train_vars.5 tensor(2.3610)\n",
      "train_vars.6 tensor(2.0626)\n",
      "train_vars.7 tensor(2.0585)\n",
      "=====================================\n",
      "[85,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3351,  0.2951,  0.3169,  ..., -0.5847, -0.5621, -0.5763],\n",
      "        [-0.3411, -0.2966, -0.2995,  ...,  0.5723,  0.6051,  0.5835]])\n",
      "rho.1.bias tensor([ 0.1691, -0.1703])\n",
      "train_vars.0 tensor(1.5575)\n",
      "train_vars.1 tensor(2.4133)\n",
      "train_vars.2 tensor(1.7750)\n",
      "train_vars.3 tensor(2.3008)\n",
      "train_vars.4 tensor(1.6082)\n",
      "train_vars.5 tensor(2.3606)\n",
      "train_vars.6 tensor(2.0624)\n",
      "train_vars.7 tensor(2.0588)\n",
      "=====================================\n",
      "[86,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3351,  0.2951,  0.3169,  ..., -0.5845, -0.5619, -0.5761],\n",
      "        [-0.3411, -0.2967, -0.2996,  ...,  0.5721,  0.6049,  0.5833]])\n",
      "rho.1.bias tensor([ 0.1690, -0.1702])\n",
      "train_vars.0 tensor(1.5575)\n",
      "train_vars.1 tensor(2.4133)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.3013)\n",
      "train_vars.4 tensor(1.6089)\n",
      "train_vars.5 tensor(2.3599)\n",
      "train_vars.6 tensor(2.0621)\n",
      "train_vars.7 tensor(2.0593)\n",
      "=====================================\n",
      "[86,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3357,  0.2957,  0.3175,  ..., -0.5836, -0.5610, -0.5752],\n",
      "        [-0.3417, -0.2972, -0.3001,  ...,  0.5712,  0.6040,  0.5824]])\n",
      "rho.1.bias tensor([ 0.1696, -0.1708])\n",
      "train_vars.0 tensor(1.5582)\n",
      "train_vars.1 tensor(2.4126)\n",
      "train_vars.2 tensor(1.7735)\n",
      "train_vars.3 tensor(2.3025)\n",
      "train_vars.4 tensor(1.6105)\n",
      "train_vars.5 tensor(2.3582)\n",
      "train_vars.6 tensor(2.0608)\n",
      "train_vars.7 tensor(2.0608)\n",
      "=====================================\n",
      "[86,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3350,  0.2950,  0.3168,  ..., -0.5846, -0.5621, -0.5763],\n",
      "        [-0.3409, -0.2965, -0.2994,  ...,  0.5722,  0.6050,  0.5835]])\n",
      "rho.1.bias tensor([ 0.1685, -0.1697])\n",
      "train_vars.0 tensor(1.5572)\n",
      "train_vars.1 tensor(2.4136)\n",
      "train_vars.2 tensor(1.7746)\n",
      "train_vars.3 tensor(2.3015)\n",
      "train_vars.4 tensor(1.6092)\n",
      "train_vars.5 tensor(2.3596)\n",
      "train_vars.6 tensor(2.0623)\n",
      "train_vars.7 tensor(2.0594)\n",
      "=====================================\n",
      "[86,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3347,  0.2947,  0.3165,  ..., -0.5853, -0.5628, -0.5770],\n",
      "        [-0.3406, -0.2962, -0.2991,  ...,  0.5729,  0.6058,  0.5842]])\n",
      "rho.1.bias tensor([ 0.1678, -0.1690])\n",
      "train_vars.0 tensor(1.5568)\n",
      "train_vars.1 tensor(2.4140)\n",
      "train_vars.2 tensor(1.7751)\n",
      "train_vars.3 tensor(2.3010)\n",
      "train_vars.4 tensor(1.6086)\n",
      "train_vars.5 tensor(2.3602)\n",
      "train_vars.6 tensor(2.0632)\n",
      "train_vars.7 tensor(2.0585)\n",
      "=====================================\n",
      "[86,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3347,  0.2947,  0.3165,  ..., -0.5857, -0.5632, -0.5773],\n",
      "        [-0.3406, -0.2962, -0.2991,  ...,  0.5733,  0.6061,  0.5845]])\n",
      "rho.1.bias tensor([ 0.1676, -0.1688])\n",
      "train_vars.0 tensor(1.5568)\n",
      "train_vars.1 tensor(2.4140)\n",
      "train_vars.2 tensor(1.7748)\n",
      "train_vars.3 tensor(2.3013)\n",
      "train_vars.4 tensor(1.6086)\n",
      "train_vars.5 tensor(2.3602)\n",
      "train_vars.6 tensor(2.0637)\n",
      "train_vars.7 tensor(2.0581)\n",
      "=====================================\n",
      "[86,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3344,  0.2944,  0.3162,  ..., -0.5856, -0.5631, -0.5772],\n",
      "        [-0.3403, -0.2959, -0.2988,  ...,  0.5732,  0.6060,  0.5844]])\n",
      "rho.1.bias tensor([ 0.1668, -0.1680])\n",
      "train_vars.0 tensor(1.5564)\n",
      "train_vars.1 tensor(2.4144)\n",
      "train_vars.2 tensor(1.7751)\n",
      "train_vars.3 tensor(2.3011)\n",
      "train_vars.4 tensor(1.6090)\n",
      "train_vars.5 tensor(2.3599)\n",
      "train_vars.6 tensor(2.0635)\n",
      "train_vars.7 tensor(2.0584)\n",
      "=====================================\n",
      "[87,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3344,  0.2944,  0.3162,  ..., -0.5854, -0.5629, -0.5770],\n",
      "        [-0.3404, -0.2959, -0.2988,  ...,  0.5730,  0.6058,  0.5842]])\n",
      "rho.1.bias tensor([ 0.1667, -0.1680])\n",
      "train_vars.0 tensor(1.5564)\n",
      "train_vars.1 tensor(2.4144)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.3016)\n",
      "train_vars.4 tensor(1.6096)\n",
      "train_vars.5 tensor(2.3592)\n",
      "train_vars.6 tensor(2.0632)\n",
      "train_vars.7 tensor(2.0589)\n",
      "=====================================\n",
      "[87,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3349,  0.2950,  0.3167,  ..., -0.5845, -0.5620, -0.5761],\n",
      "        [-0.3409, -0.2965, -0.2994,  ...,  0.5721,  0.6049,  0.5834]])\n",
      "rho.1.bias tensor([ 0.1673, -0.1686])\n",
      "train_vars.0 tensor(1.5571)\n",
      "train_vars.1 tensor(2.4137)\n",
      "train_vars.2 tensor(1.7736)\n",
      "train_vars.3 tensor(2.3028)\n",
      "train_vars.4 tensor(1.6113)\n",
      "train_vars.5 tensor(2.3575)\n",
      "train_vars.6 tensor(2.0618)\n",
      "train_vars.7 tensor(2.0604)\n",
      "=====================================\n",
      "[87,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3342,  0.2943,  0.3160,  ..., -0.5855, -0.5630, -0.5772],\n",
      "        [-0.3402, -0.2958, -0.2987,  ...,  0.5732,  0.6060,  0.5844]])\n",
      "rho.1.bias tensor([ 0.1662, -0.1674])\n",
      "train_vars.0 tensor(1.5561)\n",
      "train_vars.1 tensor(2.4147)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.3018)\n",
      "train_vars.4 tensor(1.6100)\n",
      "train_vars.5 tensor(2.3588)\n",
      "train_vars.6 tensor(2.0633)\n",
      "train_vars.7 tensor(2.0590)\n",
      "=====================================\n",
      "[87,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3339,  0.2940,  0.3157,  ..., -0.5862, -0.5637, -0.5779],\n",
      "        [-0.3399, -0.2955, -0.2984,  ...,  0.5739,  0.6067,  0.5852]])\n",
      "rho.1.bias tensor([ 0.1655, -0.1668])\n",
      "train_vars.0 tensor(1.5557)\n",
      "train_vars.1 tensor(2.4151)\n",
      "train_vars.2 tensor(1.7752)\n",
      "train_vars.3 tensor(2.3013)\n",
      "train_vars.4 tensor(1.6094)\n",
      "train_vars.5 tensor(2.3595)\n",
      "train_vars.6 tensor(2.0643)\n",
      "train_vars.7 tensor(2.0581)\n",
      "=====================================\n",
      "[87,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3339,  0.2940,  0.3157,  ..., -0.5866, -0.5641, -0.5783],\n",
      "        [-0.3399, -0.2955, -0.2984,  ...,  0.5742,  0.6070,  0.5855]])\n",
      "rho.1.bias tensor([ 0.1653, -0.1666])\n",
      "train_vars.0 tensor(1.5557)\n",
      "train_vars.1 tensor(2.4151)\n",
      "train_vars.2 tensor(1.7749)\n",
      "train_vars.3 tensor(2.3016)\n",
      "train_vars.4 tensor(1.6094)\n",
      "train_vars.5 tensor(2.3595)\n",
      "train_vars.6 tensor(2.0647)\n",
      "train_vars.7 tensor(2.0578)\n",
      "=====================================\n",
      "[87,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3336,  0.2936,  0.3154,  ..., -0.5865, -0.5640, -0.5782],\n",
      "        [-0.3396, -0.2952, -0.2981,  ...,  0.5741,  0.6069,  0.5854]])\n",
      "rho.1.bias tensor([ 0.1645, -0.1658])\n",
      "train_vars.0 tensor(1.5552)\n",
      "train_vars.1 tensor(2.4156)\n",
      "train_vars.2 tensor(1.7752)\n",
      "train_vars.3 tensor(2.3014)\n",
      "train_vars.4 tensor(1.6098)\n",
      "train_vars.5 tensor(2.3591)\n",
      "train_vars.6 tensor(2.0645)\n",
      "train_vars.7 tensor(2.0581)\n",
      "=====================================\n",
      "[88,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3337,  0.2937,  0.3155,  ..., -0.5862, -0.5638, -0.5780],\n",
      "        [-0.3396, -0.2952, -0.2981,  ...,  0.5739,  0.6067,  0.5852]])\n",
      "rho.1.bias tensor([ 0.1644, -0.1657])\n",
      "train_vars.0 tensor(1.5552)\n",
      "train_vars.1 tensor(2.4156)\n",
      "train_vars.2 tensor(1.7748)\n",
      "train_vars.3 tensor(2.3018)\n",
      "train_vars.4 tensor(1.6104)\n",
      "train_vars.5 tensor(2.3585)\n",
      "train_vars.6 tensor(2.0642)\n",
      "train_vars.7 tensor(2.0586)\n",
      "=====================================\n",
      "[88,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3342,  0.2942,  0.3160,  ..., -0.5853, -0.5629, -0.5771],\n",
      "        [-0.3402, -0.2958, -0.2987,  ...,  0.5730,  0.6058,  0.5843]])\n",
      "rho.1.bias tensor([ 0.1650, -0.1663])\n",
      "train_vars.0 tensor(1.5560)\n",
      "train_vars.1 tensor(2.4149)\n",
      "train_vars.2 tensor(1.7737)\n",
      "train_vars.3 tensor(2.3030)\n",
      "train_vars.4 tensor(1.6120)\n",
      "train_vars.5 tensor(2.3568)\n",
      "train_vars.6 tensor(2.0629)\n",
      "train_vars.7 tensor(2.0601)\n",
      "=====================================\n",
      "[88,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3335,  0.2935,  0.3153,  ..., -0.5864, -0.5640, -0.5782],\n",
      "        [-0.3395, -0.2951, -0.2979,  ...,  0.5741,  0.6069,  0.5854]])\n",
      "rho.1.bias tensor([ 0.1638, -0.1652])\n",
      "train_vars.0 tensor(1.5550)\n",
      "train_vars.1 tensor(2.4158)\n",
      "train_vars.2 tensor(1.7748)\n",
      "train_vars.3 tensor(2.3020)\n",
      "train_vars.4 tensor(1.6108)\n",
      "train_vars.5 tensor(2.3581)\n",
      "train_vars.6 tensor(2.0644)\n",
      "train_vars.7 tensor(2.0586)\n",
      "=====================================\n",
      "[88,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3332,  0.2932,  0.3150,  ..., -0.5871, -0.5647, -0.5789],\n",
      "        [-0.3392, -0.2948, -0.2976,  ...,  0.5748,  0.6076,  0.5861]])\n",
      "rho.1.bias tensor([ 0.1632, -0.1645])\n",
      "train_vars.0 tensor(1.5546)\n",
      "train_vars.1 tensor(2.4162)\n",
      "train_vars.2 tensor(1.7753)\n",
      "train_vars.3 tensor(2.3016)\n",
      "train_vars.4 tensor(1.6101)\n",
      "train_vars.5 tensor(2.3588)\n",
      "train_vars.6 tensor(2.0653)\n",
      "train_vars.7 tensor(2.0578)\n",
      "=====================================\n",
      "[88,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3332,  0.2932,  0.3150,  ..., -0.5874, -0.5650, -0.5792],\n",
      "        [-0.3392, -0.2948, -0.2976,  ...,  0.5751,  0.6079,  0.5864]])\n",
      "rho.1.bias tensor([ 0.1630, -0.1643])\n",
      "train_vars.0 tensor(1.5546)\n",
      "train_vars.1 tensor(2.4163)\n",
      "train_vars.2 tensor(1.7750)\n",
      "train_vars.3 tensor(2.3019)\n",
      "train_vars.4 tensor(1.6102)\n",
      "train_vars.5 tensor(2.3588)\n",
      "train_vars.6 tensor(2.0657)\n",
      "train_vars.7 tensor(2.0574)\n",
      "=====================================\n",
      "[88,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3329,  0.2929,  0.3147,  ..., -0.5873, -0.5649, -0.5791],\n",
      "        [-0.3389, -0.2945, -0.2973,  ...,  0.5750,  0.6079,  0.5864]])\n",
      "rho.1.bias tensor([ 0.1622, -0.1636])\n",
      "train_vars.0 tensor(1.5541)\n",
      "train_vars.1 tensor(2.4167)\n",
      "train_vars.2 tensor(1.7753)\n",
      "train_vars.3 tensor(2.3017)\n",
      "train_vars.4 tensor(1.6105)\n",
      "train_vars.5 tensor(2.3584)\n",
      "train_vars.6 tensor(2.0656)\n",
      "train_vars.7 tensor(2.0577)\n",
      "=====================================\n",
      "[89,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3329,  0.2929,  0.3147,  ..., -0.5871, -0.5647, -0.5789],\n",
      "        [-0.3389, -0.2945, -0.2974,  ...,  0.5748,  0.6076,  0.5861]])\n",
      "rho.1.bias tensor([ 0.1621, -0.1635])\n",
      "train_vars.0 tensor(1.5541)\n",
      "train_vars.1 tensor(2.4167)\n",
      "train_vars.2 tensor(1.7749)\n",
      "train_vars.3 tensor(2.3021)\n",
      "train_vars.4 tensor(1.6112)\n",
      "train_vars.5 tensor(2.3578)\n",
      "train_vars.6 tensor(2.0652)\n",
      "train_vars.7 tensor(2.0582)\n",
      "=====================================\n",
      "[89,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3335,  0.2935,  0.3153,  ..., -0.5862, -0.5638, -0.5780],\n",
      "        [-0.3395, -0.2950, -0.2979,  ...,  0.5739,  0.6067,  0.5853]])\n",
      "rho.1.bias tensor([ 0.1627, -0.1641])\n",
      "train_vars.0 tensor(1.5549)\n",
      "train_vars.1 tensor(2.4160)\n",
      "train_vars.2 tensor(1.7738)\n",
      "train_vars.3 tensor(2.3033)\n",
      "train_vars.4 tensor(1.6128)\n",
      "train_vars.5 tensor(2.3561)\n",
      "train_vars.6 tensor(2.0639)\n",
      "train_vars.7 tensor(2.0597)\n",
      "=====================================\n",
      "[89,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3328,  0.2928,  0.3146,  ..., -0.5873, -0.5649, -0.5791],\n",
      "        [-0.3388, -0.2943, -0.2972,  ...,  0.5750,  0.6078,  0.5864]])\n",
      "rho.1.bias tensor([ 0.1615, -0.1629])\n",
      "train_vars.0 tensor(1.5539)\n",
      "train_vars.1 tensor(2.4169)\n",
      "train_vars.2 tensor(1.7749)\n",
      "train_vars.3 tensor(2.3023)\n",
      "train_vars.4 tensor(1.6115)\n",
      "train_vars.5 tensor(2.3574)\n",
      "train_vars.6 tensor(2.0654)\n",
      "train_vars.7 tensor(2.0583)\n",
      "=====================================\n",
      "[89,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3325,  0.2925,  0.3143,  ..., -0.5880, -0.5656, -0.5798],\n",
      "        [-0.3384, -0.2940, -0.2969,  ...,  0.5757,  0.6085,  0.5871]])\n",
      "rho.1.bias tensor([ 0.1609, -0.1623])\n",
      "train_vars.0 tensor(1.5534)\n",
      "train_vars.1 tensor(2.4174)\n",
      "train_vars.2 tensor(1.7754)\n",
      "train_vars.3 tensor(2.3019)\n",
      "train_vars.4 tensor(1.6109)\n",
      "train_vars.5 tensor(2.3581)\n",
      "train_vars.6 tensor(2.0663)\n",
      "train_vars.7 tensor(2.0574)\n",
      "=====================================\n",
      "[89,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3325,  0.2925,  0.3143,  ..., -0.5883, -0.5659, -0.5801],\n",
      "        [-0.3385, -0.2940, -0.2969,  ...,  0.5760,  0.6089,  0.5874]])\n",
      "rho.1.bias tensor([ 0.1607, -0.1621])\n",
      "train_vars.0 tensor(1.5534)\n",
      "train_vars.1 tensor(2.4174)\n",
      "train_vars.2 tensor(1.7751)\n",
      "train_vars.3 tensor(2.3022)\n",
      "train_vars.4 tensor(1.6109)\n",
      "train_vars.5 tensor(2.3581)\n",
      "train_vars.6 tensor(2.0668)\n",
      "train_vars.7 tensor(2.0571)\n",
      "=====================================\n",
      "[89,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3322,  0.2922,  0.3140,  ..., -0.5882, -0.5658, -0.5800],\n",
      "        [-0.3381, -0.2937, -0.2966,  ...,  0.5759,  0.6088,  0.5873]])\n",
      "rho.1.bias tensor([ 0.1599, -0.1613])\n",
      "train_vars.0 tensor(1.5530)\n",
      "train_vars.1 tensor(2.4178)\n",
      "train_vars.2 tensor(1.7754)\n",
      "train_vars.3 tensor(2.3020)\n",
      "train_vars.4 tensor(1.6113)\n",
      "train_vars.5 tensor(2.3577)\n",
      "train_vars.6 tensor(2.0666)\n",
      "train_vars.7 tensor(2.0574)\n",
      "=====================================\n",
      "[90,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3322,  0.2922,  0.3140,  ..., -0.5880, -0.5656, -0.5798],\n",
      "        [-0.3382, -0.2938, -0.2966,  ...,  0.5757,  0.6086,  0.5871]])\n",
      "rho.1.bias tensor([ 0.1598, -0.1612])\n",
      "train_vars.0 tensor(1.5530)\n",
      "train_vars.1 tensor(2.4178)\n",
      "train_vars.2 tensor(1.7750)\n",
      "train_vars.3 tensor(2.3024)\n",
      "train_vars.4 tensor(1.6119)\n",
      "train_vars.5 tensor(2.3570)\n",
      "train_vars.6 tensor(2.0663)\n",
      "train_vars.7 tensor(2.0579)\n",
      "=====================================\n",
      "[90,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3328,  0.2928,  0.3146,  ..., -0.5871, -0.5647, -0.5790],\n",
      "        [-0.3387, -0.2943, -0.2972,  ...,  0.5748,  0.6077,  0.5862]])\n",
      "rho.1.bias tensor([ 0.1604, -0.1619])\n",
      "train_vars.0 tensor(1.5538)\n",
      "train_vars.1 tensor(2.4171)\n",
      "train_vars.2 tensor(1.7739)\n",
      "train_vars.3 tensor(2.3036)\n",
      "train_vars.4 tensor(1.6135)\n",
      "train_vars.5 tensor(2.3554)\n",
      "train_vars.6 tensor(2.0650)\n",
      "train_vars.7 tensor(2.0594)\n",
      "=====================================\n",
      "[90,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3321,  0.2921,  0.3139,  ..., -0.5882, -0.5658, -0.5800],\n",
      "        [-0.3380, -0.2936, -0.2965,  ...,  0.5758,  0.6088,  0.5873]])\n",
      "rho.1.bias tensor([ 0.1592, -0.1607])\n",
      "train_vars.0 tensor(1.5528)\n",
      "train_vars.1 tensor(2.4181)\n",
      "train_vars.2 tensor(1.7749)\n",
      "train_vars.3 tensor(2.3026)\n",
      "train_vars.4 tensor(1.6122)\n",
      "train_vars.5 tensor(2.3567)\n",
      "train_vars.6 tensor(2.0664)\n",
      "train_vars.7 tensor(2.0580)\n",
      "=====================================\n",
      "[90,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3318,  0.2918,  0.3136,  ..., -0.5889, -0.5665, -0.5807],\n",
      "        [-0.3377, -0.2933, -0.2962,  ...,  0.5765,  0.6095,  0.5880]])\n",
      "rho.1.bias tensor([ 0.1586, -0.1601])\n",
      "train_vars.0 tensor(1.5523)\n",
      "train_vars.1 tensor(2.4185)\n",
      "train_vars.2 tensor(1.7754)\n",
      "train_vars.3 tensor(2.3022)\n",
      "train_vars.4 tensor(1.6116)\n",
      "train_vars.5 tensor(2.3574)\n",
      "train_vars.6 tensor(2.0674)\n",
      "train_vars.7 tensor(2.0571)\n",
      "=====================================\n",
      "[90,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3318,  0.2918,  0.3136,  ..., -0.5892, -0.5668, -0.5811],\n",
      "        [-0.3377, -0.2933, -0.2962,  ...,  0.5769,  0.6098,  0.5883]])\n",
      "rho.1.bias tensor([ 0.1584, -0.1599])\n",
      "train_vars.0 tensor(1.5523)\n",
      "train_vars.1 tensor(2.4185)\n",
      "train_vars.2 tensor(1.7752)\n",
      "train_vars.3 tensor(2.3025)\n",
      "train_vars.4 tensor(1.6117)\n",
      "train_vars.5 tensor(2.3574)\n",
      "train_vars.6 tensor(2.0678)\n",
      "train_vars.7 tensor(2.0568)\n",
      "=====================================\n",
      "[90,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3315,  0.2915,  0.3133,  ..., -0.5891, -0.5667, -0.5810],\n",
      "        [-0.3374, -0.2930, -0.2959,  ...,  0.5768,  0.6097,  0.5882]])\n",
      "rho.1.bias tensor([ 0.1576, -0.1591])\n",
      "train_vars.0 tensor(1.5519)\n",
      "train_vars.1 tensor(2.4189)\n",
      "train_vars.2 tensor(1.7755)\n",
      "train_vars.3 tensor(2.3022)\n",
      "train_vars.4 tensor(1.6120)\n",
      "train_vars.5 tensor(2.3570)\n",
      "train_vars.6 tensor(2.0676)\n",
      "train_vars.7 tensor(2.0571)\n",
      "=====================================\n",
      "[91,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3315,  0.2915,  0.3133,  ..., -0.5889, -0.5665, -0.5808],\n",
      "        [-0.3375, -0.2930, -0.2959,  ...,  0.5765,  0.6095,  0.5880]])\n",
      "rho.1.bias tensor([ 0.1575, -0.1590])\n",
      "train_vars.0 tensor(1.5519)\n",
      "train_vars.1 tensor(2.4189)\n",
      "train_vars.2 tensor(1.7751)\n",
      "train_vars.3 tensor(2.3027)\n",
      "train_vars.4 tensor(1.6126)\n",
      "train_vars.5 tensor(2.3563)\n",
      "train_vars.6 tensor(2.0673)\n",
      "train_vars.7 tensor(2.0576)\n",
      "=====================================\n",
      "[91,     2] loss: 0.531\n",
      "rho.1.weight tensor([[ 0.3320,  0.2920,  0.3138,  ..., -0.5880, -0.5656, -0.5799],\n",
      "        [-0.3380, -0.2936, -0.2965,  ...,  0.5756,  0.6086,  0.5871]])\n",
      "rho.1.bias tensor([ 0.1581, -0.1596])\n",
      "train_vars.0 tensor(1.5526)\n",
      "train_vars.1 tensor(2.4182)\n",
      "train_vars.2 tensor(1.7740)\n",
      "train_vars.3 tensor(2.3039)\n",
      "train_vars.4 tensor(1.6142)\n",
      "train_vars.5 tensor(2.3547)\n",
      "train_vars.6 tensor(2.0660)\n",
      "train_vars.7 tensor(2.0591)\n",
      "=====================================\n",
      "[91,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3313,  0.2913,  0.3131,  ..., -0.5891, -0.5667, -0.5810],\n",
      "        [-0.3373, -0.2929, -0.2957,  ...,  0.5767,  0.6097,  0.5882]])\n",
      "rho.1.bias tensor([ 0.1569, -0.1585])\n",
      "train_vars.0 tensor(1.5517)\n",
      "train_vars.1 tensor(2.4192)\n",
      "train_vars.2 tensor(1.7750)\n",
      "train_vars.3 tensor(2.3029)\n",
      "train_vars.4 tensor(1.6130)\n",
      "train_vars.5 tensor(2.3560)\n",
      "train_vars.6 tensor(2.0674)\n",
      "train_vars.7 tensor(2.0576)\n",
      "=====================================\n",
      "[91,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3310,  0.2910,  0.3128,  ..., -0.5898, -0.5674, -0.5817],\n",
      "        [-0.3370, -0.2926, -0.2954,  ...,  0.5774,  0.6104,  0.5889]])\n",
      "rho.1.bias tensor([ 0.1563, -0.1579])\n",
      "train_vars.0 tensor(1.5512)\n",
      "train_vars.1 tensor(2.4196)\n",
      "train_vars.2 tensor(1.7755)\n",
      "train_vars.3 tensor(2.3024)\n",
      "train_vars.4 tensor(1.6124)\n",
      "train_vars.5 tensor(2.3567)\n",
      "train_vars.6 tensor(2.0684)\n",
      "train_vars.7 tensor(2.0568)\n",
      "=====================================\n",
      "[91,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3310,  0.2911,  0.3128,  ..., -0.5901, -0.5677, -0.5820],\n",
      "        [-0.3370, -0.2926, -0.2955,  ...,  0.5778,  0.6107,  0.5893]])\n",
      "rho.1.bias tensor([ 0.1561, -0.1576])\n",
      "train_vars.0 tensor(1.5512)\n",
      "train_vars.1 tensor(2.4196)\n",
      "train_vars.2 tensor(1.7753)\n",
      "train_vars.3 tensor(2.3028)\n",
      "train_vars.4 tensor(1.6124)\n",
      "train_vars.5 tensor(2.3567)\n",
      "train_vars.6 tensor(2.0688)\n",
      "train_vars.7 tensor(2.0565)\n",
      "=====================================\n",
      "[91,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3307,  0.2907,  0.3125,  ..., -0.5900, -0.5676, -0.5819],\n",
      "        [-0.3367, -0.2923, -0.2952,  ...,  0.5776,  0.6106,  0.5892]])\n",
      "rho.1.bias tensor([ 0.1553, -0.1569])\n",
      "train_vars.0 tensor(1.5508)\n",
      "train_vars.1 tensor(2.4200)\n",
      "train_vars.2 tensor(1.7756)\n",
      "train_vars.3 tensor(2.3025)\n",
      "train_vars.4 tensor(1.6127)\n",
      "train_vars.5 tensor(2.3563)\n",
      "train_vars.6 tensor(2.0686)\n",
      "train_vars.7 tensor(2.0567)\n",
      "=====================================\n",
      "[92,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3308,  0.2908,  0.3126,  ..., -0.5898, -0.5674, -0.5817],\n",
      "        [-0.3367, -0.2923, -0.2952,  ...,  0.5774,  0.6104,  0.5890]])\n",
      "rho.1.bias tensor([ 0.1552, -0.1568])\n",
      "train_vars.0 tensor(1.5508)\n",
      "train_vars.1 tensor(2.4200)\n",
      "train_vars.2 tensor(1.7752)\n",
      "train_vars.3 tensor(2.3030)\n",
      "train_vars.4 tensor(1.6134)\n",
      "train_vars.5 tensor(2.3557)\n",
      "train_vars.6 tensor(2.0683)\n",
      "train_vars.7 tensor(2.0572)\n",
      "=====================================\n",
      "[92,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3313,  0.2913,  0.3131,  ..., -0.5889, -0.5665, -0.5808],\n",
      "        [-0.3373, -0.2929, -0.2957,  ...,  0.5765,  0.6095,  0.5881]])\n",
      "rho.1.bias tensor([ 0.1558, -0.1574])\n",
      "train_vars.0 tensor(1.5515)\n",
      "train_vars.1 tensor(2.4193)\n",
      "train_vars.2 tensor(1.7741)\n",
      "train_vars.3 tensor(2.3041)\n",
      "train_vars.4 tensor(1.6150)\n",
      "train_vars.5 tensor(2.3540)\n",
      "train_vars.6 tensor(2.0670)\n",
      "train_vars.7 tensor(2.0587)\n",
      "=====================================\n",
      "[92,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3306,  0.2906,  0.3124,  ..., -0.5899, -0.5676, -0.5819],\n",
      "        [-0.3366, -0.2921, -0.2950,  ...,  0.5776,  0.6106,  0.5892]])\n",
      "rho.1.bias tensor([ 0.1546, -0.1563])\n",
      "train_vars.0 tensor(1.5505)\n",
      "train_vars.1 tensor(2.4203)\n",
      "train_vars.2 tensor(1.7751)\n",
      "train_vars.3 tensor(2.3031)\n",
      "train_vars.4 tensor(1.6137)\n",
      "train_vars.5 tensor(2.3553)\n",
      "train_vars.6 tensor(2.0685)\n",
      "train_vars.7 tensor(2.0573)\n",
      "=====================================\n",
      "[92,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3303,  0.2903,  0.3121,  ..., -0.5906, -0.5683, -0.5826],\n",
      "        [-0.3363, -0.2918, -0.2947,  ...,  0.5783,  0.6113,  0.5899]])\n",
      "rho.1.bias tensor([ 0.1540, -0.1556])\n",
      "train_vars.0 tensor(1.5501)\n",
      "train_vars.1 tensor(2.4207)\n",
      "train_vars.2 tensor(1.7756)\n",
      "train_vars.3 tensor(2.3027)\n",
      "train_vars.4 tensor(1.6131)\n",
      "train_vars.5 tensor(2.3560)\n",
      "train_vars.6 tensor(2.0694)\n",
      "train_vars.7 tensor(2.0564)\n",
      "=====================================\n",
      "[92,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3303,  0.2903,  0.3121,  ..., -0.5910, -0.5686, -0.5829],\n",
      "        [-0.3363, -0.2919, -0.2947,  ...,  0.5786,  0.6116,  0.5902]])\n",
      "rho.1.bias tensor([ 0.1538, -0.1554])\n",
      "train_vars.0 tensor(1.5501)\n",
      "train_vars.1 tensor(2.4207)\n",
      "train_vars.2 tensor(1.7753)\n",
      "train_vars.3 tensor(2.3030)\n",
      "train_vars.4 tensor(1.6131)\n",
      "train_vars.5 tensor(2.3560)\n",
      "train_vars.6 tensor(2.0698)\n",
      "train_vars.7 tensor(2.0561)\n",
      "=====================================\n",
      "[92,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3300,  0.2900,  0.3118,  ..., -0.5908, -0.5685, -0.5828],\n",
      "        [-0.3360, -0.2916, -0.2944,  ...,  0.5785,  0.6115,  0.5901]])\n",
      "rho.1.bias tensor([ 0.1530, -0.1547])\n",
      "train_vars.0 tensor(1.5497)\n",
      "train_vars.1 tensor(2.4211)\n",
      "train_vars.2 tensor(1.7756)\n",
      "train_vars.3 tensor(2.3028)\n",
      "train_vars.4 tensor(1.6135)\n",
      "train_vars.5 tensor(2.3556)\n",
      "train_vars.6 tensor(2.0696)\n",
      "train_vars.7 tensor(2.0564)\n",
      "=====================================\n",
      "[93,     1] loss: 0.508\n",
      "rho.1.weight tensor([[ 0.3300,  0.2900,  0.3118,  ..., -0.5906, -0.5683, -0.5826],\n",
      "        [-0.3360, -0.2916, -0.2945,  ...,  0.5783,  0.6113,  0.5899]])\n",
      "rho.1.bias tensor([ 0.1529, -0.1546])\n",
      "train_vars.0 tensor(1.5497)\n",
      "train_vars.1 tensor(2.4211)\n",
      "train_vars.2 tensor(1.7753)\n",
      "train_vars.3 tensor(2.3032)\n",
      "train_vars.4 tensor(1.6141)\n",
      "train_vars.5 tensor(2.3550)\n",
      "train_vars.6 tensor(2.0693)\n",
      "train_vars.7 tensor(2.0569)\n",
      "=====================================\n",
      "[93,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3306,  0.2906,  0.3124,  ..., -0.5897, -0.5674, -0.5817],\n",
      "        [-0.3365, -0.2921, -0.2950,  ...,  0.5774,  0.6104,  0.5890]])\n",
      "rho.1.bias tensor([ 0.1535, -0.1552])\n",
      "train_vars.0 tensor(1.5504)\n",
      "train_vars.1 tensor(2.4204)\n",
      "train_vars.2 tensor(1.7742)\n",
      "train_vars.3 tensor(2.3044)\n",
      "train_vars.4 tensor(1.6157)\n",
      "train_vars.5 tensor(2.3533)\n",
      "train_vars.6 tensor(2.0680)\n",
      "train_vars.7 tensor(2.0584)\n",
      "=====================================\n",
      "[93,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3299,  0.2899,  0.3117,  ..., -0.5908, -0.5685, -0.5828],\n",
      "        [-0.3358, -0.2914, -0.2943,  ...,  0.5785,  0.6115,  0.5901]])\n",
      "rho.1.bias tensor([ 0.1523, -0.1540])\n",
      "train_vars.0 tensor(1.5494)\n",
      "train_vars.1 tensor(2.4214)\n",
      "train_vars.2 tensor(1.7752)\n",
      "train_vars.3 tensor(2.3034)\n",
      "train_vars.4 tensor(1.6144)\n",
      "train_vars.5 tensor(2.3547)\n",
      "train_vars.6 tensor(2.0695)\n",
      "train_vars.7 tensor(2.0570)\n",
      "=====================================\n",
      "[93,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3296,  0.2896,  0.3114,  ..., -0.5915, -0.5692, -0.5835],\n",
      "        [-0.3355, -0.2911, -0.2940,  ...,  0.5792,  0.6122,  0.5908]])\n",
      "rho.1.bias tensor([ 0.1517, -0.1534])\n",
      "train_vars.0 tensor(1.5490)\n",
      "train_vars.1 tensor(2.4218)\n",
      "train_vars.2 tensor(1.7757)\n",
      "train_vars.3 tensor(2.3030)\n",
      "train_vars.4 tensor(1.6138)\n",
      "train_vars.5 tensor(2.3553)\n",
      "train_vars.6 tensor(2.0704)\n",
      "train_vars.7 tensor(2.0561)\n",
      "=====================================\n",
      "[93,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3296,  0.2896,  0.3114,  ..., -0.5918, -0.5695, -0.5838],\n",
      "        [-0.3356, -0.2911, -0.2940,  ...,  0.5795,  0.6125,  0.5911]])\n",
      "rho.1.bias tensor([ 0.1515, -0.1532])\n",
      "train_vars.0 tensor(1.5490)\n",
      "train_vars.1 tensor(2.4218)\n",
      "train_vars.2 tensor(1.7754)\n",
      "train_vars.3 tensor(2.3033)\n",
      "train_vars.4 tensor(1.6138)\n",
      "train_vars.5 tensor(2.3553)\n",
      "train_vars.6 tensor(2.0708)\n",
      "train_vars.7 tensor(2.0558)\n",
      "=====================================\n",
      "[93,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3293,  0.2893,  0.3111,  ..., -0.5917, -0.5694, -0.5837],\n",
      "        [-0.3352, -0.2908, -0.2937,  ...,  0.5794,  0.6124,  0.5910]])\n",
      "rho.1.bias tensor([ 0.1507, -0.1524])\n",
      "train_vars.0 tensor(1.5486)\n",
      "train_vars.1 tensor(2.4222)\n",
      "train_vars.2 tensor(1.7757)\n",
      "train_vars.3 tensor(2.3031)\n",
      "train_vars.4 tensor(1.6142)\n",
      "train_vars.5 tensor(2.3549)\n",
      "train_vars.6 tensor(2.0706)\n",
      "train_vars.7 tensor(2.0561)\n",
      "=====================================\n",
      "[94,     1] loss: 0.509\n",
      "rho.1.weight tensor([[ 0.3293,  0.2893,  0.3111,  ..., -0.5915, -0.5692, -0.5835],\n",
      "        [-0.3353, -0.2909, -0.2937,  ...,  0.5792,  0.6122,  0.5908]])\n",
      "rho.1.bias tensor([ 0.1506, -0.1524])\n",
      "train_vars.0 tensor(1.5486)\n",
      "train_vars.1 tensor(2.4222)\n",
      "train_vars.2 tensor(1.7753)\n",
      "train_vars.3 tensor(2.3035)\n",
      "train_vars.4 tensor(1.6148)\n",
      "train_vars.5 tensor(2.3543)\n",
      "train_vars.6 tensor(2.0703)\n",
      "train_vars.7 tensor(2.0566)\n",
      "=====================================\n",
      "[94,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3299,  0.2899,  0.3117,  ..., -0.5906, -0.5683, -0.5826],\n",
      "        [-0.3358, -0.2914, -0.2943,  ...,  0.5783,  0.6113,  0.5899]])\n",
      "rho.1.bias tensor([ 0.1512, -0.1530])\n",
      "train_vars.0 tensor(1.5493)\n",
      "train_vars.1 tensor(2.4216)\n",
      "train_vars.2 tensor(1.7742)\n",
      "train_vars.3 tensor(2.3047)\n",
      "train_vars.4 tensor(1.6164)\n",
      "train_vars.5 tensor(2.3526)\n",
      "train_vars.6 tensor(2.0690)\n",
      "train_vars.7 tensor(2.0581)\n",
      "=====================================\n",
      "[94,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3292,  0.2892,  0.3110,  ..., -0.5917, -0.5694, -0.5837],\n",
      "        [-0.3351, -0.2907, -0.2936,  ...,  0.5794,  0.6124,  0.5910]])\n",
      "rho.1.bias tensor([ 0.1501, -0.1518])\n",
      "train_vars.0 tensor(1.5483)\n",
      "train_vars.1 tensor(2.4225)\n",
      "train_vars.2 tensor(1.7753)\n",
      "train_vars.3 tensor(2.3037)\n",
      "train_vars.4 tensor(1.6151)\n",
      "train_vars.5 tensor(2.3540)\n",
      "train_vars.6 tensor(2.0705)\n",
      "train_vars.7 tensor(2.0567)\n",
      "=====================================\n",
      "[94,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3289,  0.2889,  0.3107,  ..., -0.5924, -0.5701, -0.5844],\n",
      "        [-0.3348, -0.2904, -0.2933,  ...,  0.5801,  0.6131,  0.5917]])\n",
      "rho.1.bias tensor([ 0.1494, -0.1512])\n",
      "train_vars.0 tensor(1.5479)\n",
      "train_vars.1 tensor(2.4229)\n",
      "train_vars.2 tensor(1.7758)\n",
      "train_vars.3 tensor(2.3033)\n",
      "train_vars.4 tensor(1.6145)\n",
      "train_vars.5 tensor(2.3547)\n",
      "train_vars.6 tensor(2.0714)\n",
      "train_vars.7 tensor(2.0558)\n",
      "=====================================\n",
      "[94,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3289,  0.2889,  0.3107,  ..., -0.5927, -0.5704, -0.5847],\n",
      "        [-0.3348, -0.2904, -0.2933,  ...,  0.5804,  0.6134,  0.5920]])\n",
      "rho.1.bias tensor([ 0.1492, -0.1510])\n",
      "train_vars.0 tensor(1.5479)\n",
      "train_vars.1 tensor(2.4229)\n",
      "train_vars.2 tensor(1.7755)\n",
      "train_vars.3 tensor(2.3036)\n",
      "train_vars.4 tensor(1.6146)\n",
      "train_vars.5 tensor(2.3546)\n",
      "train_vars.6 tensor(2.0718)\n",
      "train_vars.7 tensor(2.0555)\n",
      "=====================================\n",
      "[94,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3286,  0.2886,  0.3104,  ..., -0.5926, -0.5703, -0.5846],\n",
      "        [-0.3345, -0.2901, -0.2930,  ...,  0.5803,  0.6133,  0.5919]])\n",
      "rho.1.bias tensor([ 0.1484, -0.1502])\n",
      "train_vars.0 tensor(1.5475)\n",
      "train_vars.1 tensor(2.4233)\n",
      "train_vars.2 tensor(1.7758)\n",
      "train_vars.3 tensor(2.3034)\n",
      "train_vars.4 tensor(1.6149)\n",
      "train_vars.5 tensor(2.3543)\n",
      "train_vars.6 tensor(2.0716)\n",
      "train_vars.7 tensor(2.0558)\n",
      "=====================================\n",
      "[95,     1] loss: 0.509\n",
      "rho.1.weight tensor([[ 0.3286,  0.2886,  0.3104,  ..., -0.5923, -0.5701, -0.5844],\n",
      "        [-0.3346, -0.2901, -0.2930,  ...,  0.5800,  0.6131,  0.5917]])\n",
      "rho.1.bias tensor([ 0.1483, -0.1502])\n",
      "train_vars.0 tensor(1.5475)\n",
      "train_vars.1 tensor(2.4233)\n",
      "train_vars.2 tensor(1.7754)\n",
      "train_vars.3 tensor(2.3038)\n",
      "train_vars.4 tensor(1.6155)\n",
      "train_vars.5 tensor(2.3536)\n",
      "train_vars.6 tensor(2.0713)\n",
      "train_vars.7 tensor(2.0563)\n",
      "=====================================\n",
      "[95,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3291,  0.2892,  0.3109,  ..., -0.5915, -0.5692, -0.5836],\n",
      "        [-0.3351, -0.2907, -0.2936,  ...,  0.5791,  0.6122,  0.5908]])\n",
      "rho.1.bias tensor([ 0.1489, -0.1508])\n",
      "train_vars.0 tensor(1.5482)\n",
      "train_vars.1 tensor(2.4226)\n",
      "train_vars.2 tensor(1.7743)\n",
      "train_vars.3 tensor(2.3050)\n",
      "train_vars.4 tensor(1.6171)\n",
      "train_vars.5 tensor(2.3520)\n",
      "train_vars.6 tensor(2.0700)\n",
      "train_vars.7 tensor(2.0578)\n",
      "=====================================\n",
      "[95,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3284,  0.2884,  0.3102,  ..., -0.5925, -0.5702, -0.5846],\n",
      "        [-0.3344, -0.2900, -0.2928,  ...,  0.5802,  0.6133,  0.5919]])\n",
      "rho.1.bias tensor([ 0.1478, -0.1496])\n",
      "train_vars.0 tensor(1.5472)\n",
      "train_vars.1 tensor(2.4236)\n",
      "train_vars.2 tensor(1.7754)\n",
      "train_vars.3 tensor(2.3040)\n",
      "train_vars.4 tensor(1.6158)\n",
      "train_vars.5 tensor(2.3533)\n",
      "train_vars.6 tensor(2.0714)\n",
      "train_vars.7 tensor(2.0564)\n",
      "=====================================\n",
      "[95,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3281,  0.2882,  0.3099,  ..., -0.5932, -0.5709, -0.5853],\n",
      "        [-0.3341, -0.2897, -0.2925,  ...,  0.5809,  0.6140,  0.5926]])\n",
      "rho.1.bias tensor([ 0.1472, -0.1490])\n",
      "train_vars.0 tensor(1.5468)\n",
      "train_vars.1 tensor(2.4240)\n",
      "train_vars.2 tensor(1.7759)\n",
      "train_vars.3 tensor(2.3035)\n",
      "train_vars.4 tensor(1.6152)\n",
      "train_vars.5 tensor(2.3540)\n",
      "train_vars.6 tensor(2.0724)\n",
      "train_vars.7 tensor(2.0555)\n",
      "=====================================\n",
      "[95,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3282,  0.2882,  0.3100,  ..., -0.5935, -0.5713, -0.5857],\n",
      "        [-0.3341, -0.2897, -0.2926,  ...,  0.5812,  0.6143,  0.5930]])\n",
      "rho.1.bias tensor([ 0.1469, -0.1488])\n",
      "train_vars.0 tensor(1.5468)\n",
      "train_vars.1 tensor(2.4240)\n",
      "train_vars.2 tensor(1.7756)\n",
      "train_vars.3 tensor(2.3039)\n",
      "train_vars.4 tensor(1.6153)\n",
      "train_vars.5 tensor(2.3539)\n",
      "train_vars.6 tensor(2.0728)\n",
      "train_vars.7 tensor(2.0552)\n",
      "=====================================\n",
      "[95,     6] loss: 0.537\n",
      "rho.1.weight tensor([[ 0.3278,  0.2879,  0.3096,  ..., -0.5934, -0.5711, -0.5855],\n",
      "        [-0.3338, -0.2894, -0.2923,  ...,  0.5811,  0.6142,  0.5929]])\n",
      "rho.1.bias tensor([ 0.1462, -0.1480])\n",
      "train_vars.0 tensor(1.5464)\n",
      "train_vars.1 tensor(2.4244)\n",
      "train_vars.2 tensor(1.7759)\n",
      "train_vars.3 tensor(2.3036)\n",
      "train_vars.4 tensor(1.6156)\n",
      "train_vars.5 tensor(2.3536)\n",
      "train_vars.6 tensor(2.0726)\n",
      "train_vars.7 tensor(2.0555)\n",
      "=====================================\n",
      "[96,     1] loss: 0.509\n",
      "rho.1.weight tensor([[ 0.3279,  0.2879,  0.3097,  ..., -0.5932, -0.5709, -0.5853],\n",
      "        [-0.3338, -0.2894, -0.2923,  ...,  0.5809,  0.6139,  0.5926]])\n",
      "rho.1.bias tensor([ 0.1461, -0.1480])\n",
      "train_vars.0 tensor(1.5464)\n",
      "train_vars.1 tensor(2.4244)\n",
      "train_vars.2 tensor(1.7755)\n",
      "train_vars.3 tensor(2.3041)\n",
      "train_vars.4 tensor(1.6162)\n",
      "train_vars.5 tensor(2.3530)\n",
      "train_vars.6 tensor(2.0722)\n",
      "train_vars.7 tensor(2.0560)\n",
      "=====================================\n",
      "[96,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3284,  0.2884,  0.3102,  ..., -0.5923, -0.5700, -0.5845],\n",
      "        [-0.3344, -0.2900, -0.2928,  ...,  0.5800,  0.6131,  0.5918]])\n",
      "rho.1.bias tensor([ 0.1467, -0.1486])\n",
      "train_vars.0 tensor(1.5471)\n",
      "train_vars.1 tensor(2.4237)\n",
      "train_vars.2 tensor(1.7744)\n",
      "train_vars.3 tensor(2.3052)\n",
      "train_vars.4 tensor(1.6178)\n",
      "train_vars.5 tensor(2.3513)\n",
      "train_vars.6 tensor(2.0710)\n",
      "train_vars.7 tensor(2.0575)\n",
      "=====================================\n",
      "[96,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3277,  0.2877,  0.3095,  ..., -0.5934, -0.5711, -0.5855],\n",
      "        [-0.3337, -0.2892, -0.2921,  ...,  0.5811,  0.6142,  0.5929]])\n",
      "rho.1.bias tensor([ 0.1455, -0.1474])\n",
      "train_vars.0 tensor(1.5461)\n",
      "train_vars.1 tensor(2.4247)\n",
      "train_vars.2 tensor(1.7755)\n",
      "train_vars.3 tensor(2.3042)\n",
      "train_vars.4 tensor(1.6165)\n",
      "train_vars.5 tensor(2.3527)\n",
      "train_vars.6 tensor(2.0724)\n",
      "train_vars.7 tensor(2.0561)\n",
      "=====================================\n",
      "[96,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3274,  0.2874,  0.3092,  ..., -0.5941, -0.5718, -0.5862],\n",
      "        [-0.3334, -0.2889, -0.2918,  ...,  0.5818,  0.6149,  0.5936]])\n",
      "rho.1.bias tensor([ 0.1449, -0.1468])\n",
      "train_vars.0 tensor(1.5457)\n",
      "train_vars.1 tensor(2.4251)\n",
      "train_vars.2 tensor(1.7759)\n",
      "train_vars.3 tensor(2.3038)\n",
      "train_vars.4 tensor(1.6159)\n",
      "train_vars.5 tensor(2.3533)\n",
      "train_vars.6 tensor(2.0734)\n",
      "train_vars.7 tensor(2.0552)\n",
      "=====================================\n",
      "[96,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3274,  0.2875,  0.3092,  ..., -0.5944, -0.5721, -0.5866],\n",
      "        [-0.3334, -0.2890, -0.2918,  ...,  0.5821,  0.6152,  0.5939]])\n",
      "rho.1.bias tensor([ 0.1447, -0.1466])\n",
      "train_vars.0 tensor(1.5457)\n",
      "train_vars.1 tensor(2.4251)\n",
      "train_vars.2 tensor(1.7756)\n",
      "train_vars.3 tensor(2.3042)\n",
      "train_vars.4 tensor(1.6160)\n",
      "train_vars.5 tensor(2.3533)\n",
      "train_vars.6 tensor(2.0737)\n",
      "train_vars.7 tensor(2.0549)\n",
      "=====================================\n",
      "[96,     6] loss: 0.536\n",
      "rho.1.weight tensor([[ 0.3271,  0.2871,  0.3089,  ..., -0.5943, -0.5720, -0.5864],\n",
      "        [-0.3331, -0.2887, -0.2915,  ...,  0.5820,  0.6151,  0.5938]])\n",
      "rho.1.bias tensor([ 0.1439, -0.1459])\n",
      "train_vars.0 tensor(1.5453)\n",
      "train_vars.1 tensor(2.4255)\n",
      "train_vars.2 tensor(1.7759)\n",
      "train_vars.3 tensor(2.3039)\n",
      "train_vars.4 tensor(1.6163)\n",
      "train_vars.5 tensor(2.3529)\n",
      "train_vars.6 tensor(2.0736)\n",
      "train_vars.7 tensor(2.0552)\n",
      "=====================================\n",
      "[97,     1] loss: 0.509\n",
      "rho.1.weight tensor([[ 0.3271,  0.2872,  0.3089,  ..., -0.5940, -0.5718, -0.5862],\n",
      "        [-0.3331, -0.2887, -0.2916,  ...,  0.5818,  0.6148,  0.5935]])\n",
      "rho.1.bias tensor([ 0.1438, -0.1458])\n",
      "train_vars.0 tensor(1.5453)\n",
      "train_vars.1 tensor(2.4255)\n",
      "train_vars.2 tensor(1.7756)\n",
      "train_vars.3 tensor(2.3043)\n",
      "train_vars.4 tensor(1.6169)\n",
      "train_vars.5 tensor(2.3523)\n",
      "train_vars.6 tensor(2.0732)\n",
      "train_vars.7 tensor(2.0557)\n",
      "=====================================\n",
      "[97,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3277,  0.2877,  0.3095,  ..., -0.5932, -0.5709, -0.5854],\n",
      "        [-0.3337, -0.2892, -0.2921,  ...,  0.5809,  0.6139,  0.5927]])\n",
      "rho.1.bias tensor([ 0.1444, -0.1464])\n",
      "train_vars.0 tensor(1.5460)\n",
      "train_vars.1 tensor(2.4248)\n",
      "train_vars.2 tensor(1.7745)\n",
      "train_vars.3 tensor(2.3055)\n",
      "train_vars.4 tensor(1.6185)\n",
      "train_vars.5 tensor(2.3506)\n",
      "train_vars.6 tensor(2.0719)\n",
      "train_vars.7 tensor(2.0572)\n",
      "=====================================\n",
      "[97,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3270,  0.2870,  0.3088,  ..., -0.5942, -0.5720, -0.5864],\n",
      "        [-0.3329, -0.2885, -0.2914,  ...,  0.5820,  0.6150,  0.5938]])\n",
      "rho.1.bias tensor([ 0.1432, -0.1452])\n",
      "train_vars.0 tensor(1.5450)\n",
      "train_vars.1 tensor(2.4258)\n",
      "train_vars.2 tensor(1.7755)\n",
      "train_vars.3 tensor(2.3045)\n",
      "train_vars.4 tensor(1.6172)\n",
      "train_vars.5 tensor(2.3520)\n",
      "train_vars.6 tensor(2.0734)\n",
      "train_vars.7 tensor(2.0558)\n",
      "=====================================\n",
      "[97,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3267,  0.2867,  0.3085,  ..., -0.5949, -0.5727, -0.5871],\n",
      "        [-0.3326, -0.2882, -0.2911,  ...,  0.5826,  0.6157,  0.5945]])\n",
      "rho.1.bias tensor([ 0.1426, -0.1446])\n",
      "train_vars.0 tensor(1.5446)\n",
      "train_vars.1 tensor(2.4262)\n",
      "train_vars.2 tensor(1.7760)\n",
      "train_vars.3 tensor(2.3041)\n",
      "train_vars.4 tensor(1.6166)\n",
      "train_vars.5 tensor(2.3527)\n",
      "train_vars.6 tensor(2.0743)\n",
      "train_vars.7 tensor(2.0549)\n",
      "=====================================\n",
      "[97,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3267,  0.2867,  0.3085,  ..., -0.5952, -0.5730, -0.5874],\n",
      "        [-0.3327, -0.2883, -0.2911,  ...,  0.5829,  0.6160,  0.5948]])\n",
      "rho.1.bias tensor([ 0.1424, -0.1444])\n",
      "train_vars.0 tensor(1.5446)\n",
      "train_vars.1 tensor(2.4262)\n",
      "train_vars.2 tensor(1.7757)\n",
      "train_vars.3 tensor(2.3044)\n",
      "train_vars.4 tensor(1.6167)\n",
      "train_vars.5 tensor(2.3526)\n",
      "train_vars.6 tensor(2.0747)\n",
      "train_vars.7 tensor(2.0546)\n",
      "=====================================\n",
      "[97,     6] loss: 0.536\n",
      "rho.1.weight tensor([[ 0.3264,  0.2864,  0.3082,  ..., -0.5951, -0.5729, -0.5873],\n",
      "        [-0.3324, -0.2879, -0.2908,  ...,  0.5828,  0.6159,  0.5947]])\n",
      "rho.1.bias tensor([ 0.1416, -0.1437])\n",
      "train_vars.0 tensor(1.5442)\n",
      "train_vars.1 tensor(2.4266)\n",
      "train_vars.2 tensor(1.7760)\n",
      "train_vars.3 tensor(2.3042)\n",
      "train_vars.4 tensor(1.6170)\n",
      "train_vars.5 tensor(2.3523)\n",
      "train_vars.6 tensor(2.0745)\n",
      "train_vars.7 tensor(2.0549)\n",
      "=====================================\n",
      "[98,     1] loss: 0.509\n",
      "rho.1.weight tensor([[ 0.3264,  0.2864,  0.3082,  ..., -0.5949, -0.5727, -0.5871],\n",
      "        [-0.3324, -0.2880, -0.2908,  ...,  0.5826,  0.6157,  0.5944]])\n",
      "rho.1.bias tensor([ 0.1415, -0.1436])\n",
      "train_vars.0 tensor(1.5442)\n",
      "train_vars.1 tensor(2.4266)\n",
      "train_vars.2 tensor(1.7757)\n",
      "train_vars.3 tensor(2.3046)\n",
      "train_vars.4 tensor(1.6176)\n",
      "train_vars.5 tensor(2.3516)\n",
      "train_vars.6 tensor(2.0742)\n",
      "train_vars.7 tensor(2.0554)\n",
      "=====================================\n",
      "[98,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3270,  0.2870,  0.3088,  ..., -0.5940, -0.5718, -0.5862],\n",
      "        [-0.3329, -0.2885, -0.2914,  ...,  0.5817,  0.6148,  0.5936]])\n",
      "rho.1.bias tensor([ 0.1421, -0.1442])\n",
      "train_vars.0 tensor(1.5449)\n",
      "train_vars.1 tensor(2.4259)\n",
      "train_vars.2 tensor(1.7746)\n",
      "train_vars.3 tensor(2.3058)\n",
      "train_vars.4 tensor(1.6192)\n",
      "train_vars.5 tensor(2.3500)\n",
      "train_vars.6 tensor(2.0729)\n",
      "train_vars.7 tensor(2.0569)\n",
      "=====================================\n",
      "[98,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3263,  0.2863,  0.3081,  ..., -0.5951, -0.5729, -0.5873],\n",
      "        [-0.3322, -0.2878, -0.2907,  ...,  0.5828,  0.6159,  0.5947]])\n",
      "rho.1.bias tensor([ 0.1410, -0.1431])\n",
      "train_vars.0 tensor(1.5439)\n",
      "train_vars.1 tensor(2.4268)\n",
      "train_vars.2 tensor(1.7756)\n",
      "train_vars.3 tensor(2.3048)\n",
      "train_vars.4 tensor(1.6179)\n",
      "train_vars.5 tensor(2.3514)\n",
      "train_vars.6 tensor(2.0744)\n",
      "train_vars.7 tensor(2.0555)\n",
      "=====================================\n",
      "[98,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3260,  0.2860,  0.3078,  ..., -0.5958, -0.5736, -0.5880],\n",
      "        [-0.3319, -0.2875, -0.2904,  ...,  0.5835,  0.6166,  0.5954]])\n",
      "rho.1.bias tensor([ 0.1404, -0.1424])\n",
      "train_vars.0 tensor(1.5435)\n",
      "train_vars.1 tensor(2.4272)\n",
      "train_vars.2 tensor(1.7761)\n",
      "train_vars.3 tensor(2.3044)\n",
      "train_vars.4 tensor(1.6173)\n",
      "train_vars.5 tensor(2.3520)\n",
      "train_vars.6 tensor(2.0753)\n",
      "train_vars.7 tensor(2.0546)\n",
      "=====================================\n",
      "[98,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3260,  0.2860,  0.3078,  ..., -0.5961, -0.5739, -0.5883],\n",
      "        [-0.3320, -0.2875, -0.2904,  ...,  0.5838,  0.6169,  0.5957]])\n",
      "rho.1.bias tensor([ 0.1401, -0.1422])\n",
      "train_vars.0 tensor(1.5435)\n",
      "train_vars.1 tensor(2.4272)\n",
      "train_vars.2 tensor(1.7758)\n",
      "train_vars.3 tensor(2.3047)\n",
      "train_vars.4 tensor(1.6173)\n",
      "train_vars.5 tensor(2.3520)\n",
      "train_vars.6 tensor(2.0757)\n",
      "train_vars.7 tensor(2.0544)\n",
      "=====================================\n",
      "[98,     6] loss: 0.536\n",
      "rho.1.weight tensor([[ 0.3257,  0.2857,  0.3075,  ..., -0.5960, -0.5738, -0.5882],\n",
      "        [-0.3316, -0.2872, -0.2901,  ...,  0.5837,  0.6168,  0.5956]])\n",
      "rho.1.bias tensor([ 0.1394, -0.1415])\n",
      "train_vars.0 tensor(1.5431)\n",
      "train_vars.1 tensor(2.4277)\n",
      "train_vars.2 tensor(1.7761)\n",
      "train_vars.3 tensor(2.3045)\n",
      "train_vars.4 tensor(1.6177)\n",
      "train_vars.5 tensor(2.3516)\n",
      "train_vars.6 tensor(2.0755)\n",
      "train_vars.7 tensor(2.0547)\n",
      "=====================================\n",
      "[99,     1] loss: 0.509\n",
      "rho.1.weight tensor([[ 0.3257,  0.2857,  0.3075,  ..., -0.5957, -0.5735, -0.5880],\n",
      "        [-0.3317, -0.2873, -0.2901,  ...,  0.5834,  0.6166,  0.5953]])\n",
      "rho.1.bias tensor([ 0.1393, -0.1414])\n",
      "train_vars.0 tensor(1.5431)\n",
      "train_vars.1 tensor(2.4277)\n",
      "train_vars.2 tensor(1.7757)\n",
      "train_vars.3 tensor(2.3049)\n",
      "train_vars.4 tensor(1.6183)\n",
      "train_vars.5 tensor(2.3510)\n",
      "train_vars.6 tensor(2.0751)\n",
      "train_vars.7 tensor(2.0552)\n",
      "=====================================\n",
      "[99,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3263,  0.2863,  0.3080,  ..., -0.5948, -0.5727, -0.5871],\n",
      "        [-0.3322, -0.2878, -0.2907,  ...,  0.5826,  0.6157,  0.5945]])\n",
      "rho.1.bias tensor([ 0.1399, -0.1420])\n",
      "train_vars.0 tensor(1.5438)\n",
      "train_vars.1 tensor(2.4270)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.3061)\n",
      "train_vars.4 tensor(1.6199)\n",
      "train_vars.5 tensor(2.3494)\n",
      "train_vars.6 tensor(2.0739)\n",
      "train_vars.7 tensor(2.0566)\n",
      "=====================================\n",
      "[99,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3255,  0.2856,  0.3073,  ..., -0.5959, -0.5737, -0.5882],\n",
      "        [-0.3315, -0.2871, -0.2899,  ...,  0.5836,  0.6168,  0.5956]])\n",
      "rho.1.bias tensor([ 0.1387, -0.1409])\n",
      "train_vars.0 tensor(1.5428)\n",
      "train_vars.1 tensor(2.4279)\n",
      "train_vars.2 tensor(1.7757)\n",
      "train_vars.3 tensor(2.3051)\n",
      "train_vars.4 tensor(1.6186)\n",
      "train_vars.5 tensor(2.3507)\n",
      "train_vars.6 tensor(2.0753)\n",
      "train_vars.7 tensor(2.0552)\n",
      "=====================================\n",
      "[99,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3253,  0.2853,  0.3071,  ..., -0.5966, -0.5744, -0.5889],\n",
      "        [-0.3312, -0.2868, -0.2896,  ...,  0.5843,  0.6175,  0.5963]])\n",
      "rho.1.bias tensor([ 0.1381, -0.1403])\n",
      "train_vars.0 tensor(1.5424)\n",
      "train_vars.1 tensor(2.4283)\n",
      "train_vars.2 tensor(1.7762)\n",
      "train_vars.3 tensor(2.3046)\n",
      "train_vars.4 tensor(1.6180)\n",
      "train_vars.5 tensor(2.3514)\n",
      "train_vars.6 tensor(2.0763)\n",
      "train_vars.7 tensor(2.0544)\n",
      "=====================================\n",
      "[99,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3253,  0.2853,  0.3071,  ..., -0.5969, -0.5747, -0.5892],\n",
      "        [-0.3312, -0.2868, -0.2897,  ...,  0.5846,  0.6178,  0.5966]])\n",
      "rho.1.bias tensor([ 0.1379, -0.1401])\n",
      "train_vars.0 tensor(1.5424)\n",
      "train_vars.1 tensor(2.4283)\n",
      "train_vars.2 tensor(1.7759)\n",
      "train_vars.3 tensor(2.3050)\n",
      "train_vars.4 tensor(1.6180)\n",
      "train_vars.5 tensor(2.3513)\n",
      "train_vars.6 tensor(2.0766)\n",
      "train_vars.7 tensor(2.0541)\n",
      "=====================================\n",
      "[99,     6] loss: 0.536\n",
      "rho.1.weight tensor([[ 0.3250,  0.2850,  0.3068,  ..., -0.5968, -0.5746, -0.5891],\n",
      "        [-0.3309, -0.2865, -0.2894,  ...,  0.5845,  0.6177,  0.5965]])\n",
      "rho.1.bias tensor([ 0.1371, -0.1393])\n",
      "train_vars.0 tensor(1.5420)\n",
      "train_vars.1 tensor(2.4287)\n",
      "train_vars.2 tensor(1.7762)\n",
      "train_vars.3 tensor(2.3047)\n",
      "train_vars.4 tensor(1.6184)\n",
      "train_vars.5 tensor(2.3510)\n",
      "train_vars.6 tensor(2.0764)\n",
      "train_vars.7 tensor(2.0544)\n",
      "=====================================\n",
      "[100,     1] loss: 0.509\n",
      "rho.1.weight tensor([[ 0.3250,  0.2850,  0.3068,  ..., -0.5966, -0.5744, -0.5889],\n",
      "        [-0.3310, -0.2865, -0.2894,  ...,  0.5843,  0.6174,  0.5962]])\n",
      "rho.1.bias tensor([ 0.1370, -0.1392])\n",
      "train_vars.0 tensor(1.5420)\n",
      "train_vars.1 tensor(2.4287)\n",
      "train_vars.2 tensor(1.7758)\n",
      "train_vars.3 tensor(2.3052)\n",
      "train_vars.4 tensor(1.6190)\n",
      "train_vars.5 tensor(2.3504)\n",
      "train_vars.6 tensor(2.0761)\n",
      "train_vars.7 tensor(2.0549)\n",
      "=====================================\n",
      "[100,     2] loss: 0.532\n",
      "rho.1.weight tensor([[ 0.3255,  0.2855,  0.3073,  ..., -0.5957, -0.5735, -0.5880],\n",
      "        [-0.3315, -0.2871, -0.2899,  ...,  0.5834,  0.6166,  0.5954]])\n",
      "rho.1.bias tensor([ 0.1376, -0.1399])\n",
      "train_vars.0 tensor(1.5427)\n",
      "train_vars.1 tensor(2.4281)\n",
      "train_vars.2 tensor(1.7747)\n",
      "train_vars.3 tensor(2.3063)\n",
      "train_vars.4 tensor(1.6205)\n",
      "train_vars.5 tensor(2.3487)\n",
      "train_vars.6 tensor(2.0748)\n",
      "train_vars.7 tensor(2.0564)\n",
      "=====================================\n",
      "[100,     3] loss: 0.463\n",
      "rho.1.weight tensor([[ 0.3248,  0.2848,  0.3066,  ..., -0.5967, -0.5746, -0.5891],\n",
      "        [-0.3308, -0.2864, -0.2892,  ...,  0.5845,  0.6177,  0.5965]])\n",
      "rho.1.bias tensor([ 0.1365, -0.1387])\n",
      "train_vars.0 tensor(1.5417)\n",
      "train_vars.1 tensor(2.4290)\n",
      "train_vars.2 tensor(1.7758)\n",
      "train_vars.3 tensor(2.3053)\n",
      "train_vars.4 tensor(1.6192)\n",
      "train_vars.5 tensor(2.3501)\n",
      "train_vars.6 tensor(2.0763)\n",
      "train_vars.7 tensor(2.0549)\n",
      "=====================================\n",
      "[100,     4] loss: 0.479\n",
      "rho.1.weight tensor([[ 0.3245,  0.2846,  0.3063,  ..., -0.5974, -0.5753, -0.5898],\n",
      "        [-0.3305, -0.2861, -0.2889,  ...,  0.5852,  0.6184,  0.5972]])\n",
      "rho.1.bias tensor([ 0.1359, -0.1381])\n",
      "train_vars.0 tensor(1.5413)\n",
      "train_vars.1 tensor(2.4294)\n",
      "train_vars.2 tensor(1.7763)\n",
      "train_vars.3 tensor(2.3049)\n",
      "train_vars.4 tensor(1.6186)\n",
      "train_vars.5 tensor(2.3508)\n",
      "train_vars.6 tensor(2.0772)\n",
      "train_vars.7 tensor(2.0541)\n",
      "=====================================\n",
      "[100,     5] loss: 0.558\n",
      "rho.1.weight tensor([[ 0.3246,  0.2846,  0.3064,  ..., -0.5977, -0.5756, -0.5901],\n",
      "        [-0.3305, -0.2861, -0.2890,  ...,  0.5855,  0.6186,  0.5975]])\n",
      "rho.1.bias tensor([ 0.1356, -0.1379])\n",
      "train_vars.0 tensor(1.5414)\n",
      "train_vars.1 tensor(2.4294)\n",
      "train_vars.2 tensor(1.7759)\n",
      "train_vars.3 tensor(2.3053)\n",
      "train_vars.4 tensor(1.6187)\n",
      "train_vars.5 tensor(2.3507)\n",
      "train_vars.6 tensor(2.0776)\n",
      "train_vars.7 tensor(2.0538)\n",
      "=====================================\n",
      "[100,     6] loss: 0.536\n",
      "rho.1.weight tensor([[ 0.3243,  0.2843,  0.3061,  ..., -0.5976, -0.5755, -0.5900],\n",
      "        [-0.3302, -0.2858, -0.2887,  ...,  0.5854,  0.6185,  0.5973]])\n",
      "rho.1.bias tensor([ 0.1349, -0.1371])\n",
      "train_vars.0 tensor(1.5409)\n",
      "train_vars.1 tensor(2.4298)\n",
      "train_vars.2 tensor(1.7762)\n",
      "train_vars.3 tensor(2.3050)\n",
      "train_vars.4 tensor(1.6190)\n",
      "train_vars.5 tensor(2.3504)\n",
      "train_vars.6 tensor(2.0774)\n",
      "train_vars.7 tensor(2.0541)\n",
      "=====================================\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_model_pytorch(L,F,D,train,test,model,optimizer,loss,num_epochs=epochs, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Bibliography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[1] _PersLay: A Simple and Versatile Neural Network Layer for Persistence Diagrams._\n",
    "Mathieu Carrière, Frederic Chazal, Yuichi Ike, Théo Lacombe, Martin Royer, Yuhei Umeda.\n",
    "\n",
    "[2] _Deep Sets._\n",
    "Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan Salakhutdinov, Alexander Smola.\n",
    "_Advances in Neural Information Processing Systems 30 (NIPS 2017)_\n",
    "\n",
    "[3] _Learning Representations of Persistence Barcodes._\n",
    "Christoph Hofer, Roland Kwitt, Marc Niethammer.\n",
    "_JMLR (2019)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
